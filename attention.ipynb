{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "attention.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shreyasrajesh0308/NNDL-proj/blob/main/attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Paper: "
      ],
      "metadata": {
        "id": "Wy-ORg0nyKtV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Data \n",
        "\n",
        "Load preprocessed data"
      ],
      "metadata": {
        "id": "5Fl4uJtrAqU0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Scu17GL9A7i5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e094663b-a432-4823-f861-c2904d1685dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "2gXQ7pXTIqqT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_test = np.load(\"/content/drive/MyDrive/eeg_project/X_test.npy\")\n",
        "y_test = np.load(\"/content/drive/MyDrive/eeg_project/y_test.npy\")\n",
        "person_train_valid = np.load(\"/content/drive/MyDrive/eeg_project/person_train_valid.npy\")\n",
        "X_train_valid = np.load(\"/content/drive/MyDrive/eeg_project/X_train_valid.npy\")\n",
        "y_train_valid = np.load(\"/content/drive/MyDrive/eeg_project/y_train_valid.npy\")\n",
        "person_test = np.load(\"/content/drive/MyDrive/eeg_project/person_test.npy\")\n"
      ],
      "metadata": {
        "id": "foTd2q3JIreb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print ('Training/Valid data shape: {}'.format(X_train_valid.shape))\n",
        "print ('Test data shape: {}'.format(X_test.shape))\n",
        "print ('Training/Valid target shape: {}'.format(y_train_valid.shape))\n",
        "print ('Test target shape: {}'.format(y_test.shape))\n",
        "print ('Person train/valid shape: {}'.format(person_train_valid.shape))\n",
        "print ('Person test shape: {}'.format(person_test.shape))\n"
      ],
      "metadata": {
        "id": "g6VAQSVEUtIW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c32a9c11-5fee-47dc-af39-b7543e3987ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training/Valid data shape: (2115, 22, 1000)\n",
            "Test data shape: (443, 22, 1000)\n",
            "Training/Valid target shape: (2115,)\n",
            "Test target shape: (443,)\n",
            "Person train/valid shape: (2115, 1)\n",
            "Person test shape: (443, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.unique(y_train_valid))\n",
        "print(np.unique(y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhxR60r5IzuR",
        "outputId": "3a98fa56-11cb-4c36-d944-30f5ff9df2a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[769 770 771 772]\n",
            "[769 770 771 772]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 4\n",
        "y_train_valid = y_train_valid-769\n",
        "y_test = y_test-769"
      ],
      "metadata": {
        "id": "U4K1wzmfI4Rb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_prep(X,y,sub_sample,average,noise):\n",
        "    \n",
        "    total_X = None\n",
        "    total_y = None\n",
        "    \n",
        "    # Trimming the data (sample,22,1000) -> (sample,22,500)\n",
        "    X = X[:,:,0:500]\n",
        "    print('Shape of X after trimming:',X.shape)\n",
        "    \n",
        "    # Maxpooling the data (sample,22,1000) -> (sample,22,500/sub_sample)\n",
        "    X_max = np.max(X.reshape(X.shape[0], X.shape[1], -1, sub_sample), axis=3)\n",
        "    \n",
        "    \n",
        "    total_X = X_max\n",
        "    total_y = y\n",
        "    print('Shape of X after maxpooling:',total_X.shape)\n",
        "    \n",
        "    # Averaging + noise \n",
        "    X_average = np.mean(X.reshape(X.shape[0], X.shape[1], -1, average),axis=3)\n",
        "    X_average = X_average + np.random.normal(0.0, 0.5, X_average.shape)\n",
        "    \n",
        "    total_X = np.vstack((total_X, X_average))\n",
        "    total_y = np.hstack((total_y, y))\n",
        "    print('Shape of X after averaging+noise and concatenating:',total_X.shape)\n",
        "    \n",
        "    # Subsampling\n",
        "    \n",
        "    for i in range(sub_sample):\n",
        "        \n",
        "        X_subsample = X[:, :, i::sub_sample] + \\\n",
        "                            (np.random.normal(0.0, 0.5, X[:, :,i::sub_sample].shape) if noise else 0.0)\n",
        "            \n",
        "        total_X = np.vstack((total_X, X_subsample))\n",
        "        total_y = np.hstack((total_y, y))\n",
        "        \n",
        "    \n",
        "    print('Shape of X after subsampling and concatenating:',total_X.shape)\n",
        "    return total_X,total_y\n",
        "\n",
        "\n",
        "X_train_valid_prep,y_train_valid_prep = data_prep(X_train_valid,y_train_valid,2,2,True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-ubjiWDpR_W",
        "outputId": "19031ca8-b636-426c-ddfb-dbc9e7731dab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X after trimming: (2115, 22, 500)\n",
            "Shape of X after maxpooling: (2115, 22, 250)\n",
            "Shape of X after averaging+noise and concatenating: (4230, 22, 250)\n",
            "Shape of X after subsampling and concatenating: (8460, 22, 250)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def data_prep_test(X,y, sub_sample=2):\n",
        "    \n",
        "    total_X = None\n",
        "    total_y = None\n",
        "    \n",
        "    # Trimming the data (sample,22,1000) -> (sample,22,500)\n",
        "    X = X[:,:,0:500]\n",
        "    print('Shape of X after trimming:',X.shape)\n",
        "    \n",
        "    # Maxpooling the data (sample,22,1000) -> (sample,22,500/sub_sample)\n",
        "    X_max = np.max(X.reshape(X.shape[0], X.shape[1], -1, sub_sample), axis=3)\n",
        "    \n",
        "    \n",
        "    total_X = X_max\n",
        "    total_y = y\n",
        "    print('Shape of X after maxpooling:',total_X.shape)\n",
        "    return total_X,total_y\n",
        "\n",
        "\n",
        "X_test,y_test = data_prep_test(X_test, y_test,2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhtalewhtI6R",
        "outputId": "11813eb3-33a1-473c-ae71-4a3bfb4f5005"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X after trimming: (443, 22, 500)\n",
            "Shape of X after maxpooling: (443, 22, 250)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "y_train_valid_prep = keras.utils.to_categorical(y_train_valid_prep, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "metadata": {
        "id": "NZWq7ZCFq5z9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train_valid_prep.shape,y_train_valid_prep.shape)\n",
        "print(X_test.shape, y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFZfw6CuqeBs",
        "outputId": "3ba717c6-3a00-4f13-d574-e8e550eb6921"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8460, 22, 250) (8460,)\n",
            "(443, 22, 250) (443,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_valid_prep = np.swapaxes(X_train_valid_prep, 1, 2)\n",
        "X_test = np.swapaxes(X_test, 1, 2)"
      ],
      "metadata": {
        "id": "L4MojHQU12YB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train_valid_prep.shape,y_train_valid_prep.shape)\n",
        "print(X_test.shape, y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVGBRD5O1-78",
        "outputId": "078f3066-245e-4855-fd98-a68de7b262d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8460, 250, 22) (8460,)\n",
            "(443, 250, 22) (443,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformer model with all subjects"
      ],
      "metadata": {
        "id": "IxgOEM-3WIPG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Conv2D, BatchNormalization, Activation, Flatten, Dense, Dropout, LSTM, Input, TimeDistributed, Permute, Reshape, MaxPooling2D, GRU\n",
        "from keras import initializers, Model, optimizers, callbacks\n",
        "from keras import Sequential\n",
        "from keras import backend as K\n",
        "from keras.models import load_model\n",
        "from keras.callbacks import Callback\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n"
      ],
      "metadata": {
        "id": "GswnoLTxWgFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
        "    # Normalization and Attention\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
        "    x = layers.MultiHeadAttention(\n",
        "        key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
        "    )(x, x)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    res = x + inputs\n",
        "\n",
        "    # Feed Forward Part\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(res)\n",
        "    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(x)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
        "    return x + res\n"
      ],
      "metadata": {
        "id": "wYFHPdrb0i52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(\n",
        "    input_shape,\n",
        "    head_size,\n",
        "    num_heads,\n",
        "    ff_dim,\n",
        "    num_transformer_blocks,\n",
        "    mlp_units,\n",
        "    dropout=0,\n",
        "    mlp_dropout=0,\n",
        "):\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    x = inputs\n",
        "    for _ in range(num_transformer_blocks):\n",
        "        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
        "\n",
        "    x = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n",
        "    for dim in mlp_units:\n",
        "        x = layers.Dense(dim, activation=\"relu\")(x)\n",
        "        x = layers.Dropout(mlp_dropout)(x)\n",
        "    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "    return keras.Model(inputs, outputs)\n"
      ],
      "metadata": {
        "id": "BSm44W_mWdxt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = X_train_valid_prep.shape[1:]\n",
        "\n",
        "model = build_model(\n",
        "    input_shape,\n",
        "    head_size=256,\n",
        "    num_heads=4,\n",
        "    ff_dim=4,\n",
        "    num_transformer_blocks=4,\n",
        "    mlp_units=[128],\n",
        "    mlp_dropout=0.4,\n",
        "    dropout=0.25,\n",
        ")\n",
        "\n",
        "model.compile(\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
        "    metrics=[\"sparse_categorical_accuracy\"],\n",
        ")\n",
        "model.summary()\n",
        "\n",
        "# callbacks = [keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)]\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dIk5e9Ze0vEe",
        "outputId": "ee99d209-a43e-45f9-c38d-a67b70adf7fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_6 (InputLayer)           [(None, 250, 22)]    0           []                               \n",
            "                                                                                                  \n",
            " layer_normalization_40 (LayerN  (None, 250, 22)     44          ['input_6[0][0]']                \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " multi_head_attention_20 (Multi  (None, 250, 22)     93206       ['layer_normalization_40[0][0]', \n",
            " HeadAttention)                                                   'layer_normalization_40[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_45 (Dropout)           (None, 250, 22)      0           ['multi_head_attention_20[0][0]']\n",
            "                                                                                                  \n",
            " tf.__operators__.add_40 (TFOpL  (None, 250, 22)     0           ['dropout_45[0][0]',             \n",
            " ambda)                                                           'input_6[0][0]']                \n",
            "                                                                                                  \n",
            " layer_normalization_41 (LayerN  (None, 250, 22)     44          ['tf.__operators__.add_40[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv1d_40 (Conv1D)             (None, 250, 4)       92          ['layer_normalization_41[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_46 (Dropout)           (None, 250, 4)       0           ['conv1d_40[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_41 (Conv1D)             (None, 250, 22)      110         ['dropout_46[0][0]']             \n",
            "                                                                                                  \n",
            " tf.__operators__.add_41 (TFOpL  (None, 250, 22)     0           ['conv1d_41[0][0]',              \n",
            " ambda)                                                           'tf.__operators__.add_40[0][0]']\n",
            "                                                                                                  \n",
            " layer_normalization_42 (LayerN  (None, 250, 22)     44          ['tf.__operators__.add_41[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " multi_head_attention_21 (Multi  (None, 250, 22)     93206       ['layer_normalization_42[0][0]', \n",
            " HeadAttention)                                                   'layer_normalization_42[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_47 (Dropout)           (None, 250, 22)      0           ['multi_head_attention_21[0][0]']\n",
            "                                                                                                  \n",
            " tf.__operators__.add_42 (TFOpL  (None, 250, 22)     0           ['dropout_47[0][0]',             \n",
            " ambda)                                                           'tf.__operators__.add_41[0][0]']\n",
            "                                                                                                  \n",
            " layer_normalization_43 (LayerN  (None, 250, 22)     44          ['tf.__operators__.add_42[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv1d_42 (Conv1D)             (None, 250, 4)       92          ['layer_normalization_43[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_48 (Dropout)           (None, 250, 4)       0           ['conv1d_42[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_43 (Conv1D)             (None, 250, 22)      110         ['dropout_48[0][0]']             \n",
            "                                                                                                  \n",
            " tf.__operators__.add_43 (TFOpL  (None, 250, 22)     0           ['conv1d_43[0][0]',              \n",
            " ambda)                                                           'tf.__operators__.add_42[0][0]']\n",
            "                                                                                                  \n",
            " layer_normalization_44 (LayerN  (None, 250, 22)     44          ['tf.__operators__.add_43[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " multi_head_attention_22 (Multi  (None, 250, 22)     93206       ['layer_normalization_44[0][0]', \n",
            " HeadAttention)                                                   'layer_normalization_44[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_49 (Dropout)           (None, 250, 22)      0           ['multi_head_attention_22[0][0]']\n",
            "                                                                                                  \n",
            " tf.__operators__.add_44 (TFOpL  (None, 250, 22)     0           ['dropout_49[0][0]',             \n",
            " ambda)                                                           'tf.__operators__.add_43[0][0]']\n",
            "                                                                                                  \n",
            " layer_normalization_45 (LayerN  (None, 250, 22)     44          ['tf.__operators__.add_44[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv1d_44 (Conv1D)             (None, 250, 4)       92          ['layer_normalization_45[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_50 (Dropout)           (None, 250, 4)       0           ['conv1d_44[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_45 (Conv1D)             (None, 250, 22)      110         ['dropout_50[0][0]']             \n",
            "                                                                                                  \n",
            " tf.__operators__.add_45 (TFOpL  (None, 250, 22)     0           ['conv1d_45[0][0]',              \n",
            " ambda)                                                           'tf.__operators__.add_44[0][0]']\n",
            "                                                                                                  \n",
            " layer_normalization_46 (LayerN  (None, 250, 22)     44          ['tf.__operators__.add_45[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " multi_head_attention_23 (Multi  (None, 250, 22)     93206       ['layer_normalization_46[0][0]', \n",
            " HeadAttention)                                                   'layer_normalization_46[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_51 (Dropout)           (None, 250, 22)      0           ['multi_head_attention_23[0][0]']\n",
            "                                                                                                  \n",
            " tf.__operators__.add_46 (TFOpL  (None, 250, 22)     0           ['dropout_51[0][0]',             \n",
            " ambda)                                                           'tf.__operators__.add_45[0][0]']\n",
            "                                                                                                  \n",
            " layer_normalization_47 (LayerN  (None, 250, 22)     44          ['tf.__operators__.add_46[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv1d_46 (Conv1D)             (None, 250, 4)       92          ['layer_normalization_47[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_52 (Dropout)           (None, 250, 4)       0           ['conv1d_46[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_47 (Conv1D)             (None, 250, 22)      110         ['dropout_52[0][0]']             \n",
            "                                                                                                  \n",
            " tf.__operators__.add_47 (TFOpL  (None, 250, 22)     0           ['conv1d_47[0][0]',              \n",
            " ambda)                                                           'tf.__operators__.add_46[0][0]']\n",
            "                                                                                                  \n",
            " global_average_pooling1d_5 (Gl  (None, 250)         0           ['tf.__operators__.add_47[0][0]']\n",
            " obalAveragePooling1D)                                                                            \n",
            "                                                                                                  \n",
            " dense_10 (Dense)               (None, 128)          32128       ['global_average_pooling1d_5[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " dropout_53 (Dropout)           (None, 128)          0           ['dense_10[0][0]']               \n",
            "                                                                                                  \n",
            " dense_11 (Dense)               (None, 4)            516         ['dropout_53[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 406,628\n",
            "Trainable params: 406,628\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.fit(\n",
        "    X_train_valid_prep,\n",
        "    y_train_valid_prep,\n",
        "    validation_split=0.2,\n",
        "    epochs=200,\n",
        "    batch_size=64\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQNJ4-8OXRB0",
        "outputId": "4f8c2df0-d017-45ff-efc8-18d419040900"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "106/106 [==============================] - 64s 473ms/step - loss: 11.5033 - sparse_categorical_accuracy: 0.2648 - val_loss: 6.8582 - val_sparse_categorical_accuracy: 0.2884\n",
            "Epoch 2/200\n",
            "106/106 [==============================] - 49s 463ms/step - loss: 8.6392 - sparse_categorical_accuracy: 0.2841 - val_loss: 5.1527 - val_sparse_categorical_accuracy: 0.3085\n",
            "Epoch 3/200\n",
            "106/106 [==============================] - 50s 469ms/step - loss: 7.1914 - sparse_categorical_accuracy: 0.2884 - val_loss: 4.3068 - val_sparse_categorical_accuracy: 0.3227\n",
            "Epoch 4/200\n",
            "106/106 [==============================] - 50s 470ms/step - loss: 5.8424 - sparse_categorical_accuracy: 0.3053 - val_loss: 3.4222 - val_sparse_categorical_accuracy: 0.3168\n",
            "Epoch 5/200\n",
            "106/106 [==============================] - 50s 470ms/step - loss: 3.7788 - sparse_categorical_accuracy: 0.2937 - val_loss: 1.7776 - val_sparse_categorical_accuracy: 0.2908\n",
            "Epoch 6/200\n",
            "106/106 [==============================] - 49s 459ms/step - loss: 1.5209 - sparse_categorical_accuracy: 0.2773 - val_loss: 1.3856 - val_sparse_categorical_accuracy: 0.2778\n",
            "Epoch 7/200\n",
            "106/106 [==============================] - 48s 454ms/step - loss: 1.3937 - sparse_categorical_accuracy: 0.2691 - val_loss: 1.3796 - val_sparse_categorical_accuracy: 0.2671\n",
            "Epoch 8/200\n",
            "106/106 [==============================] - 48s 454ms/step - loss: 1.3846 - sparse_categorical_accuracy: 0.2652 - val_loss: 1.3755 - val_sparse_categorical_accuracy: 0.2766\n",
            "Epoch 9/200\n",
            "106/106 [==============================] - 48s 454ms/step - loss: 1.3831 - sparse_categorical_accuracy: 0.2605 - val_loss: 1.3753 - val_sparse_categorical_accuracy: 0.2713\n",
            "Epoch 10/200\n",
            "106/106 [==============================] - 48s 455ms/step - loss: 1.3825 - sparse_categorical_accuracy: 0.2648 - val_loss: 1.3754 - val_sparse_categorical_accuracy: 0.2671\n",
            "Epoch 11/200\n",
            "106/106 [==============================] - 48s 454ms/step - loss: 1.3794 - sparse_categorical_accuracy: 0.2691 - val_loss: 1.3719 - val_sparse_categorical_accuracy: 0.2908\n",
            "Epoch 12/200\n",
            "106/106 [==============================] - 48s 455ms/step - loss: 1.3778 - sparse_categorical_accuracy: 0.2697 - val_loss: 1.3725 - val_sparse_categorical_accuracy: 0.2784\n",
            "Epoch 13/200\n",
            "106/106 [==============================] - 48s 455ms/step - loss: 1.3765 - sparse_categorical_accuracy: 0.2670 - val_loss: 1.3669 - val_sparse_categorical_accuracy: 0.2914\n",
            "Epoch 14/200\n",
            "106/106 [==============================] - 48s 455ms/step - loss: 1.3773 - sparse_categorical_accuracy: 0.2782 - val_loss: 1.3668 - val_sparse_categorical_accuracy: 0.2961\n",
            "Epoch 15/200\n",
            "106/106 [==============================] - 48s 455ms/step - loss: 1.3688 - sparse_categorical_accuracy: 0.2822 - val_loss: 1.3625 - val_sparse_categorical_accuracy: 0.2955\n",
            "Epoch 16/200\n",
            "106/106 [==============================] - 49s 465ms/step - loss: 1.3766 - sparse_categorical_accuracy: 0.2756 - val_loss: 1.3615 - val_sparse_categorical_accuracy: 0.2937\n",
            "Epoch 17/200\n",
            "106/106 [==============================] - 48s 456ms/step - loss: 1.3666 - sparse_categorical_accuracy: 0.2832 - val_loss: 1.3590 - val_sparse_categorical_accuracy: 0.2991\n",
            "Epoch 18/200\n",
            "106/106 [==============================] - 48s 454ms/step - loss: 1.3628 - sparse_categorical_accuracy: 0.2924 - val_loss: 1.3560 - val_sparse_categorical_accuracy: 0.3174\n",
            "Epoch 19/200\n",
            "106/106 [==============================] - 48s 454ms/step - loss: 1.3708 - sparse_categorical_accuracy: 0.2782 - val_loss: 1.3596 - val_sparse_categorical_accuracy: 0.2890\n",
            "Epoch 20/200\n",
            "106/106 [==============================] - 48s 455ms/step - loss: 1.3669 - sparse_categorical_accuracy: 0.2849 - val_loss: 1.3555 - val_sparse_categorical_accuracy: 0.3056\n",
            "Epoch 21/200\n",
            "106/106 [==============================] - 48s 454ms/step - loss: 1.3645 - sparse_categorical_accuracy: 0.2902 - val_loss: 1.3507 - val_sparse_categorical_accuracy: 0.3091\n",
            "Epoch 22/200\n",
            "106/106 [==============================] - 48s 454ms/step - loss: 1.3615 - sparse_categorical_accuracy: 0.2928 - val_loss: 1.3509 - val_sparse_categorical_accuracy: 0.3215\n",
            "Epoch 23/200\n",
            "106/106 [==============================] - 48s 457ms/step - loss: 1.3563 - sparse_categorical_accuracy: 0.3002 - val_loss: 1.3397 - val_sparse_categorical_accuracy: 0.3197\n",
            "Epoch 24/200\n",
            "106/106 [==============================] - 48s 456ms/step - loss: 1.3578 - sparse_categorical_accuracy: 0.2923 - val_loss: 1.3421 - val_sparse_categorical_accuracy: 0.3115\n",
            "Epoch 25/200\n",
            "106/106 [==============================] - 48s 458ms/step - loss: 1.3529 - sparse_categorical_accuracy: 0.3066 - val_loss: 1.3403 - val_sparse_categorical_accuracy: 0.3197\n",
            "Epoch 26/200\n",
            "106/106 [==============================] - 48s 457ms/step - loss: 1.3442 - sparse_categorical_accuracy: 0.3048 - val_loss: 1.3344 - val_sparse_categorical_accuracy: 0.3245\n",
            "Epoch 27/200\n",
            "106/106 [==============================] - 48s 457ms/step - loss: 1.3481 - sparse_categorical_accuracy: 0.3005 - val_loss: 1.3335 - val_sparse_categorical_accuracy: 0.3316\n",
            "Epoch 28/200\n",
            "106/106 [==============================] - 50s 468ms/step - loss: 1.3405 - sparse_categorical_accuracy: 0.3094 - val_loss: 1.3274 - val_sparse_categorical_accuracy: 0.3322\n",
            "Epoch 29/200\n",
            "106/106 [==============================] - 48s 456ms/step - loss: 1.3402 - sparse_categorical_accuracy: 0.3171 - val_loss: 1.3212 - val_sparse_categorical_accuracy: 0.3511\n",
            "Epoch 30/200\n",
            "106/106 [==============================] - 48s 457ms/step - loss: 1.3333 - sparse_categorical_accuracy: 0.3189 - val_loss: 1.3201 - val_sparse_categorical_accuracy: 0.3534\n",
            "Epoch 31/200\n",
            "106/106 [==============================] - 48s 456ms/step - loss: 1.3317 - sparse_categorical_accuracy: 0.3254 - val_loss: 1.3068 - val_sparse_categorical_accuracy: 0.3582\n",
            "Epoch 32/200\n",
            "106/106 [==============================] - 48s 458ms/step - loss: 1.3325 - sparse_categorical_accuracy: 0.3237 - val_loss: 1.3082 - val_sparse_categorical_accuracy: 0.3682\n",
            "Epoch 33/200\n",
            "106/106 [==============================] - 49s 459ms/step - loss: 1.3259 - sparse_categorical_accuracy: 0.3279 - val_loss: 1.3123 - val_sparse_categorical_accuracy: 0.3652\n",
            "Epoch 34/200\n",
            "106/106 [==============================] - 49s 459ms/step - loss: 1.3204 - sparse_categorical_accuracy: 0.3267 - val_loss: 1.2959 - val_sparse_categorical_accuracy: 0.3647\n",
            "Epoch 35/200\n",
            "106/106 [==============================] - 49s 460ms/step - loss: 1.3135 - sparse_categorical_accuracy: 0.3375 - val_loss: 1.2926 - val_sparse_categorical_accuracy: 0.3682\n",
            "Epoch 36/200\n",
            "106/106 [==============================] - 49s 458ms/step - loss: 1.3158 - sparse_categorical_accuracy: 0.3330 - val_loss: 1.2923 - val_sparse_categorical_accuracy: 0.3629\n",
            "Epoch 37/200\n",
            "106/106 [==============================] - 49s 459ms/step - loss: 1.3043 - sparse_categorical_accuracy: 0.3401 - val_loss: 1.2757 - val_sparse_categorical_accuracy: 0.3788\n",
            "Epoch 38/200\n",
            "106/106 [==============================] - 49s 460ms/step - loss: 1.3034 - sparse_categorical_accuracy: 0.3463 - val_loss: 1.2706 - val_sparse_categorical_accuracy: 0.3788\n",
            "Epoch 39/200\n",
            "106/106 [==============================] - 49s 460ms/step - loss: 1.2974 - sparse_categorical_accuracy: 0.3483 - val_loss: 1.2732 - val_sparse_categorical_accuracy: 0.3942\n",
            "Epoch 40/200\n",
            "106/106 [==============================] - 49s 460ms/step - loss: 1.2940 - sparse_categorical_accuracy: 0.3502 - val_loss: 1.2649 - val_sparse_categorical_accuracy: 0.4037\n",
            "Epoch 41/200\n",
            "106/106 [==============================] - 49s 460ms/step - loss: 1.2818 - sparse_categorical_accuracy: 0.3599 - val_loss: 1.2528 - val_sparse_categorical_accuracy: 0.3877\n",
            "Epoch 42/200\n",
            "106/106 [==============================] - 49s 461ms/step - loss: 1.2858 - sparse_categorical_accuracy: 0.3540 - val_loss: 1.2488 - val_sparse_categorical_accuracy: 0.4007\n",
            "Epoch 43/200\n",
            "106/106 [==============================] - 49s 460ms/step - loss: 1.2739 - sparse_categorical_accuracy: 0.3579 - val_loss: 1.2357 - val_sparse_categorical_accuracy: 0.3907\n",
            "Epoch 44/200\n",
            "106/106 [==============================] - 49s 461ms/step - loss: 1.2716 - sparse_categorical_accuracy: 0.3638 - val_loss: 1.2334 - val_sparse_categorical_accuracy: 0.4043\n",
            "Epoch 45/200\n",
            "106/106 [==============================] - 49s 461ms/step - loss: 1.2745 - sparse_categorical_accuracy: 0.3682 - val_loss: 1.2291 - val_sparse_categorical_accuracy: 0.4196\n",
            "Epoch 46/200\n",
            "106/106 [==============================] - 49s 462ms/step - loss: 1.2569 - sparse_categorical_accuracy: 0.3756 - val_loss: 1.2158 - val_sparse_categorical_accuracy: 0.4196\n",
            "Epoch 47/200\n",
            "106/106 [==============================] - 49s 462ms/step - loss: 1.2520 - sparse_categorical_accuracy: 0.3819 - val_loss: 1.2080 - val_sparse_categorical_accuracy: 0.4279\n",
            "Epoch 48/200\n",
            "106/106 [==============================] - 49s 462ms/step - loss: 1.2512 - sparse_categorical_accuracy: 0.3757 - val_loss: 1.2009 - val_sparse_categorical_accuracy: 0.4243\n",
            "Epoch 49/200\n",
            "106/106 [==============================] - 49s 463ms/step - loss: 1.2467 - sparse_categorical_accuracy: 0.3774 - val_loss: 1.1970 - val_sparse_categorical_accuracy: 0.4314\n",
            "Epoch 50/200\n",
            "106/106 [==============================] - 49s 463ms/step - loss: 1.2350 - sparse_categorical_accuracy: 0.3868 - val_loss: 1.1873 - val_sparse_categorical_accuracy: 0.4303\n",
            "Epoch 51/200\n",
            "106/106 [==============================] - 49s 463ms/step - loss: 1.2337 - sparse_categorical_accuracy: 0.3775 - val_loss: 1.1873 - val_sparse_categorical_accuracy: 0.4439\n",
            "Epoch 52/200\n",
            "106/106 [==============================] - 49s 464ms/step - loss: 1.2222 - sparse_categorical_accuracy: 0.3989 - val_loss: 1.1765 - val_sparse_categorical_accuracy: 0.4480\n",
            "Epoch 53/200\n",
            "106/106 [==============================] - 49s 463ms/step - loss: 1.2166 - sparse_categorical_accuracy: 0.3986 - val_loss: 1.1758 - val_sparse_categorical_accuracy: 0.4574\n",
            "Epoch 54/200\n",
            "106/106 [==============================] - 49s 463ms/step - loss: 1.2060 - sparse_categorical_accuracy: 0.4105 - val_loss: 1.1606 - val_sparse_categorical_accuracy: 0.4474\n",
            "Epoch 55/200\n",
            "106/106 [==============================] - 49s 464ms/step - loss: 1.2028 - sparse_categorical_accuracy: 0.4109 - val_loss: 1.1522 - val_sparse_categorical_accuracy: 0.4580\n",
            "Epoch 56/200\n",
            "106/106 [==============================] - 49s 464ms/step - loss: 1.2034 - sparse_categorical_accuracy: 0.4056 - val_loss: 1.1540 - val_sparse_categorical_accuracy: 0.4569\n",
            "Epoch 57/200\n",
            "106/106 [==============================] - 49s 464ms/step - loss: 1.1904 - sparse_categorical_accuracy: 0.4176 - val_loss: 1.1438 - val_sparse_categorical_accuracy: 0.4681\n",
            "Epoch 58/200\n",
            "106/106 [==============================] - 49s 464ms/step - loss: 1.1828 - sparse_categorical_accuracy: 0.4303 - val_loss: 1.1425 - val_sparse_categorical_accuracy: 0.4675\n",
            "Epoch 59/200\n",
            "106/106 [==============================] - 49s 464ms/step - loss: 1.1721 - sparse_categorical_accuracy: 0.4199 - val_loss: 1.1253 - val_sparse_categorical_accuracy: 0.4775\n",
            "Epoch 60/200\n",
            "106/106 [==============================] - 49s 465ms/step - loss: 1.1750 - sparse_categorical_accuracy: 0.4215 - val_loss: 1.1232 - val_sparse_categorical_accuracy: 0.4722\n",
            "Epoch 61/200\n",
            "106/106 [==============================] - 49s 464ms/step - loss: 1.1697 - sparse_categorical_accuracy: 0.4224 - val_loss: 1.1182 - val_sparse_categorical_accuracy: 0.4734\n",
            "Epoch 62/200\n",
            "106/106 [==============================] - 49s 464ms/step - loss: 1.1613 - sparse_categorical_accuracy: 0.4291 - val_loss: 1.1070 - val_sparse_categorical_accuracy: 0.4793\n",
            "Epoch 63/200\n",
            "106/106 [==============================] - 49s 465ms/step - loss: 1.1518 - sparse_categorical_accuracy: 0.4381 - val_loss: 1.0999 - val_sparse_categorical_accuracy: 0.4888\n",
            "Epoch 64/200\n",
            "106/106 [==============================] - 49s 465ms/step - loss: 1.1473 - sparse_categorical_accuracy: 0.4311 - val_loss: 1.0969 - val_sparse_categorical_accuracy: 0.4888\n",
            "Epoch 65/200\n",
            "106/106 [==============================] - 49s 464ms/step - loss: 1.1401 - sparse_categorical_accuracy: 0.4393 - val_loss: 1.0851 - val_sparse_categorical_accuracy: 0.5077\n",
            "Epoch 66/200\n",
            "106/106 [==============================] - 49s 465ms/step - loss: 1.1311 - sparse_categorical_accuracy: 0.4473 - val_loss: 1.0782 - val_sparse_categorical_accuracy: 0.5053\n",
            "Epoch 67/200\n",
            "106/106 [==============================] - 49s 465ms/step - loss: 1.1236 - sparse_categorical_accuracy: 0.4539 - val_loss: 1.0768 - val_sparse_categorical_accuracy: 0.5118\n",
            "Epoch 68/200\n",
            "106/106 [==============================] - 49s 465ms/step - loss: 1.1133 - sparse_categorical_accuracy: 0.4645 - val_loss: 1.0656 - val_sparse_categorical_accuracy: 0.5089\n",
            "Epoch 69/200\n",
            "106/106 [==============================] - 49s 465ms/step - loss: 1.1045 - sparse_categorical_accuracy: 0.4641 - val_loss: 1.0708 - val_sparse_categorical_accuracy: 0.5071\n",
            "Epoch 70/200\n",
            "106/106 [==============================] - 49s 464ms/step - loss: 1.1036 - sparse_categorical_accuracy: 0.4676 - val_loss: 1.0511 - val_sparse_categorical_accuracy: 0.5189\n",
            "Epoch 71/200\n",
            "106/106 [==============================] - 49s 465ms/step - loss: 1.0991 - sparse_categorical_accuracy: 0.4663 - val_loss: 1.0512 - val_sparse_categorical_accuracy: 0.5219\n",
            "Epoch 72/200\n",
            "106/106 [==============================] - 49s 466ms/step - loss: 1.0878 - sparse_categorical_accuracy: 0.4777 - val_loss: 1.0427 - val_sparse_categorical_accuracy: 0.5278\n",
            "Epoch 73/200\n",
            "106/106 [==============================] - 49s 465ms/step - loss: 1.0899 - sparse_categorical_accuracy: 0.4704 - val_loss: 1.0357 - val_sparse_categorical_accuracy: 0.5319\n",
            "Epoch 74/200\n",
            "106/106 [==============================] - 50s 476ms/step - loss: 1.0743 - sparse_categorical_accuracy: 0.4799 - val_loss: 1.0321 - val_sparse_categorical_accuracy: 0.5248\n",
            "Epoch 75/200\n",
            "106/106 [==============================] - 49s 465ms/step - loss: 1.0739 - sparse_categorical_accuracy: 0.4812 - val_loss: 1.0271 - val_sparse_categorical_accuracy: 0.5296\n",
            "Epoch 76/200\n",
            "106/106 [==============================] - 49s 465ms/step - loss: 1.0644 - sparse_categorical_accuracy: 0.4873 - val_loss: 1.0201 - val_sparse_categorical_accuracy: 0.5343\n",
            "Epoch 77/200\n",
            "106/106 [==============================] - 50s 475ms/step - loss: 1.0600 - sparse_categorical_accuracy: 0.4877 - val_loss: 1.0149 - val_sparse_categorical_accuracy: 0.5349\n",
            "Epoch 78/200\n",
            "106/106 [==============================] - 49s 465ms/step - loss: 1.0489 - sparse_categorical_accuracy: 0.4997 - val_loss: 1.0083 - val_sparse_categorical_accuracy: 0.5414\n",
            "Epoch 79/200\n",
            "106/106 [==============================] - 49s 465ms/step - loss: 1.0497 - sparse_categorical_accuracy: 0.5003 - val_loss: 1.0062 - val_sparse_categorical_accuracy: 0.5408\n",
            "Epoch 80/200\n",
            "106/106 [==============================] - 50s 476ms/step - loss: 1.0304 - sparse_categorical_accuracy: 0.5077 - val_loss: 1.0090 - val_sparse_categorical_accuracy: 0.5455\n",
            "Epoch 81/200\n",
            "106/106 [==============================] - 49s 465ms/step - loss: 1.0351 - sparse_categorical_accuracy: 0.5064 - val_loss: 0.9933 - val_sparse_categorical_accuracy: 0.5431\n",
            "Epoch 82/200\n",
            "106/106 [==============================] - 49s 465ms/step - loss: 1.0286 - sparse_categorical_accuracy: 0.5072 - val_loss: 0.9897 - val_sparse_categorical_accuracy: 0.5538\n",
            "Epoch 83/200\n",
            "106/106 [==============================] - 49s 465ms/step - loss: 1.0289 - sparse_categorical_accuracy: 0.5052 - val_loss: 0.9826 - val_sparse_categorical_accuracy: 0.5668\n",
            "Epoch 84/200\n",
            "106/106 [==============================] - 49s 466ms/step - loss: 1.0105 - sparse_categorical_accuracy: 0.5102 - val_loss: 0.9773 - val_sparse_categorical_accuracy: 0.5615\n",
            "Epoch 85/200\n",
            "106/106 [==============================] - 49s 466ms/step - loss: 1.0084 - sparse_categorical_accuracy: 0.5139 - val_loss: 0.9726 - val_sparse_categorical_accuracy: 0.5538\n",
            "Epoch 86/200\n",
            "106/106 [==============================] - 49s 465ms/step - loss: 0.9916 - sparse_categorical_accuracy: 0.5236 - val_loss: 0.9653 - val_sparse_categorical_accuracy: 0.5632\n",
            "Epoch 87/200\n",
            "106/106 [==============================] - 49s 466ms/step - loss: 0.9859 - sparse_categorical_accuracy: 0.5229 - val_loss: 0.9602 - val_sparse_categorical_accuracy: 0.5668\n",
            "Epoch 88/200\n",
            "106/106 [==============================] - 49s 465ms/step - loss: 0.9984 - sparse_categorical_accuracy: 0.5160 - val_loss: 0.9601 - val_sparse_categorical_accuracy: 0.5668\n",
            "Epoch 89/200\n",
            "106/106 [==============================] - 49s 465ms/step - loss: 0.9964 - sparse_categorical_accuracy: 0.5259 - val_loss: 0.9556 - val_sparse_categorical_accuracy: 0.5762\n",
            "Epoch 90/200\n",
            "106/106 [==============================] - 49s 466ms/step - loss: 0.9758 - sparse_categorical_accuracy: 0.5318 - val_loss: 0.9499 - val_sparse_categorical_accuracy: 0.5703\n",
            "Epoch 91/200\n",
            "106/106 [==============================] - 49s 466ms/step - loss: 0.9724 - sparse_categorical_accuracy: 0.5358 - val_loss: 0.9426 - val_sparse_categorical_accuracy: 0.5768\n",
            "Epoch 92/200\n",
            "106/106 [==============================] - 49s 466ms/step - loss: 0.9770 - sparse_categorical_accuracy: 0.5324 - val_loss: 0.9416 - val_sparse_categorical_accuracy: 0.5780\n",
            "Epoch 93/200\n",
            "106/106 [==============================] - 49s 465ms/step - loss: 0.9666 - sparse_categorical_accuracy: 0.5344 - val_loss: 0.9397 - val_sparse_categorical_accuracy: 0.5798\n",
            "Epoch 94/200\n",
            "106/106 [==============================] - 49s 465ms/step - loss: 0.9531 - sparse_categorical_accuracy: 0.5433 - val_loss: 0.9343 - val_sparse_categorical_accuracy: 0.5851\n",
            "Epoch 95/200\n",
            "106/106 [==============================] - 49s 465ms/step - loss: 0.9447 - sparse_categorical_accuracy: 0.5480 - val_loss: 0.9288 - val_sparse_categorical_accuracy: 0.5887\n",
            "Epoch 96/200\n",
            "106/106 [==============================] - 49s 465ms/step - loss: 0.9503 - sparse_categorical_accuracy: 0.5517 - val_loss: 0.9205 - val_sparse_categorical_accuracy: 0.5940\n",
            "Epoch 97/200\n",
            "106/106 [==============================] - 49s 466ms/step - loss: 0.9427 - sparse_categorical_accuracy: 0.5527 - val_loss: 0.9166 - val_sparse_categorical_accuracy: 0.5892\n",
            "Epoch 98/200\n",
            "106/106 [==============================] - 49s 466ms/step - loss: 0.9345 - sparse_categorical_accuracy: 0.5474 - val_loss: 0.9148 - val_sparse_categorical_accuracy: 0.6005\n",
            "Epoch 99/200\n",
            "106/106 [==============================] - 49s 466ms/step - loss: 0.9349 - sparse_categorical_accuracy: 0.5541 - val_loss: 0.9174 - val_sparse_categorical_accuracy: 0.6011\n",
            "Epoch 100/200\n",
            "106/106 [==============================] - 49s 466ms/step - loss: 0.9320 - sparse_categorical_accuracy: 0.5576 - val_loss: 0.8975 - val_sparse_categorical_accuracy: 0.6082\n",
            "Epoch 101/200\n",
            "106/106 [==============================] - 49s 466ms/step - loss: 0.9148 - sparse_categorical_accuracy: 0.5689 - val_loss: 0.9102 - val_sparse_categorical_accuracy: 0.6011\n",
            "Epoch 102/200\n",
            "106/106 [==============================] - 49s 466ms/step - loss: 0.9113 - sparse_categorical_accuracy: 0.5687 - val_loss: 0.8888 - val_sparse_categorical_accuracy: 0.6070\n",
            "Epoch 103/200\n",
            "106/106 [==============================] - 49s 466ms/step - loss: 0.9106 - sparse_categorical_accuracy: 0.5696 - val_loss: 0.8856 - val_sparse_categorical_accuracy: 0.6141\n",
            "Epoch 104/200\n",
            "106/106 [==============================] - 49s 466ms/step - loss: 0.9008 - sparse_categorical_accuracy: 0.5655 - val_loss: 0.8794 - val_sparse_categorical_accuracy: 0.6087\n",
            "Epoch 105/200\n",
            "106/106 [==============================] - 49s 466ms/step - loss: 0.8928 - sparse_categorical_accuracy: 0.5730 - val_loss: 0.8824 - val_sparse_categorical_accuracy: 0.6093\n",
            "Epoch 106/200\n",
            "106/106 [==============================] - 49s 466ms/step - loss: 0.8953 - sparse_categorical_accuracy: 0.5773 - val_loss: 0.8698 - val_sparse_categorical_accuracy: 0.6265\n",
            "Epoch 107/200\n",
            "106/106 [==============================] - 49s 466ms/step - loss: 0.8821 - sparse_categorical_accuracy: 0.5876 - val_loss: 0.8681 - val_sparse_categorical_accuracy: 0.6206\n",
            "Epoch 108/200\n",
            "106/106 [==============================] - 49s 466ms/step - loss: 0.8877 - sparse_categorical_accuracy: 0.5819 - val_loss: 0.8645 - val_sparse_categorical_accuracy: 0.6259\n",
            "Epoch 109/200\n",
            "106/106 [==============================] - 49s 466ms/step - loss: 0.8617 - sparse_categorical_accuracy: 0.5885 - val_loss: 0.8517 - val_sparse_categorical_accuracy: 0.6389\n",
            "Epoch 110/200\n",
            "106/106 [==============================] - 49s 466ms/step - loss: 0.8688 - sparse_categorical_accuracy: 0.5860 - val_loss: 0.8581 - val_sparse_categorical_accuracy: 0.6342\n",
            "Epoch 111/200\n",
            "106/106 [==============================] - 49s 466ms/step - loss: 0.8655 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.8507 - val_sparse_categorical_accuracy: 0.6365\n",
            "Epoch 112/200\n",
            "106/106 [==============================] - 49s 466ms/step - loss: 0.8524 - sparse_categorical_accuracy: 0.5968 - val_loss: 0.8411 - val_sparse_categorical_accuracy: 0.6430\n",
            "Epoch 113/200\n",
            "106/106 [==============================] - 49s 466ms/step - loss: 0.8607 - sparse_categorical_accuracy: 0.5915 - val_loss: 0.8466 - val_sparse_categorical_accuracy: 0.6336\n",
            "Epoch 114/200\n",
            "106/106 [==============================] - 49s 466ms/step - loss: 0.8428 - sparse_categorical_accuracy: 0.6008 - val_loss: 0.8329 - val_sparse_categorical_accuracy: 0.6460\n",
            "Epoch 115/200\n",
            "106/106 [==============================] - 49s 466ms/step - loss: 0.8383 - sparse_categorical_accuracy: 0.6055 - val_loss: 0.8362 - val_sparse_categorical_accuracy: 0.6383\n",
            "Epoch 116/200\n",
            "106/106 [==============================] - 49s 465ms/step - loss: 0.8449 - sparse_categorical_accuracy: 0.5972 - val_loss: 0.8358 - val_sparse_categorical_accuracy: 0.6442\n",
            "Epoch 117/200\n",
            "106/106 [==============================] - 49s 466ms/step - loss: 0.8228 - sparse_categorical_accuracy: 0.6161 - val_loss: 0.8209 - val_sparse_categorical_accuracy: 0.6460\n",
            "Epoch 118/200\n",
            "106/106 [==============================] - 49s 466ms/step - loss: 0.8283 - sparse_categorical_accuracy: 0.6045 - val_loss: 0.8099 - val_sparse_categorical_accuracy: 0.6543\n",
            "Epoch 119/200\n",
            "106/106 [==============================] - 49s 466ms/step - loss: 0.8229 - sparse_categorical_accuracy: 0.6117 - val_loss: 0.8091 - val_sparse_categorical_accuracy: 0.6602\n",
            "Epoch 120/200\n",
            "106/106 [==============================] - 49s 466ms/step - loss: 0.8131 - sparse_categorical_accuracy: 0.6124 - val_loss: 0.8136 - val_sparse_categorical_accuracy: 0.6602\n",
            "Epoch 121/200\n",
            "106/106 [==============================] - 49s 466ms/step - loss: 0.8160 - sparse_categorical_accuracy: 0.6089 - val_loss: 0.8104 - val_sparse_categorical_accuracy: 0.6613\n",
            "Epoch 122/200\n",
            "106/106 [==============================] - 49s 466ms/step - loss: 0.8007 - sparse_categorical_accuracy: 0.6186 - val_loss: 0.7943 - val_sparse_categorical_accuracy: 0.6613\n",
            "Epoch 123/200\n",
            "106/106 [==============================] - 49s 467ms/step - loss: 0.7896 - sparse_categorical_accuracy: 0.6220 - val_loss: 0.7935 - val_sparse_categorical_accuracy: 0.6673\n",
            "Epoch 124/200\n",
            "106/106 [==============================] - 49s 466ms/step - loss: 0.7992 - sparse_categorical_accuracy: 0.6285 - val_loss: 0.7912 - val_sparse_categorical_accuracy: 0.6690\n",
            "Epoch 125/200\n",
            "106/106 [==============================] - 49s 467ms/step - loss: 0.7849 - sparse_categorical_accuracy: 0.6257 - val_loss: 0.7890 - val_sparse_categorical_accuracy: 0.6714\n",
            "Epoch 126/200\n",
            "106/106 [==============================] - 49s 467ms/step - loss: 0.7840 - sparse_categorical_accuracy: 0.6278 - val_loss: 0.7861 - val_sparse_categorical_accuracy: 0.6690\n",
            "Epoch 127/200\n",
            "106/106 [==============================] - 49s 467ms/step - loss: 0.7720 - sparse_categorical_accuracy: 0.6374 - val_loss: 0.7947 - val_sparse_categorical_accuracy: 0.6684\n",
            "Epoch 128/200\n",
            "106/106 [==============================] - 49s 467ms/step - loss: 0.7673 - sparse_categorical_accuracy: 0.6365 - val_loss: 0.7718 - val_sparse_categorical_accuracy: 0.6779\n",
            "Epoch 129/200\n",
            "106/106 [==============================] - 49s 467ms/step - loss: 0.7662 - sparse_categorical_accuracy: 0.6327 - val_loss: 0.7656 - val_sparse_categorical_accuracy: 0.6879\n",
            "Epoch 130/200\n",
            "106/106 [==============================] - 49s 466ms/step - loss: 0.7704 - sparse_categorical_accuracy: 0.6315 - val_loss: 0.7545 - val_sparse_categorical_accuracy: 0.6921\n",
            "Epoch 131/200\n",
            "106/106 [==============================] - 49s 467ms/step - loss: 0.7677 - sparse_categorical_accuracy: 0.6370 - val_loss: 0.7663 - val_sparse_categorical_accuracy: 0.6767\n",
            "Epoch 132/200\n",
            "106/106 [==============================] - 49s 467ms/step - loss: 0.7592 - sparse_categorical_accuracy: 0.6362 - val_loss: 0.7526 - val_sparse_categorical_accuracy: 0.6868\n",
            "Epoch 133/200\n",
            "106/106 [==============================] - 49s 467ms/step - loss: 0.7541 - sparse_categorical_accuracy: 0.6408 - val_loss: 0.7446 - val_sparse_categorical_accuracy: 0.6879\n",
            "Epoch 134/200\n",
            "106/106 [==============================] - 49s 467ms/step - loss: 0.7365 - sparse_categorical_accuracy: 0.6504 - val_loss: 0.7481 - val_sparse_categorical_accuracy: 0.6927\n",
            "Epoch 135/200\n",
            "106/106 [==============================] - 49s 467ms/step - loss: 0.7462 - sparse_categorical_accuracy: 0.6424 - val_loss: 0.7527 - val_sparse_categorical_accuracy: 0.6850\n",
            "Epoch 136/200\n",
            "106/106 [==============================] - 49s 467ms/step - loss: 0.7516 - sparse_categorical_accuracy: 0.6429 - val_loss: 0.7422 - val_sparse_categorical_accuracy: 0.6927\n",
            "Epoch 137/200\n",
            "106/106 [==============================] - 49s 467ms/step - loss: 0.7205 - sparse_categorical_accuracy: 0.6582 - val_loss: 0.7453 - val_sparse_categorical_accuracy: 0.6874\n",
            "Epoch 138/200\n",
            "106/106 [==============================] - 49s 467ms/step - loss: 0.7309 - sparse_categorical_accuracy: 0.6509 - val_loss: 0.7270 - val_sparse_categorical_accuracy: 0.7033\n",
            "Epoch 139/200\n",
            "106/106 [==============================] - 50s 468ms/step - loss: 0.7205 - sparse_categorical_accuracy: 0.6597 - val_loss: 0.7311 - val_sparse_categorical_accuracy: 0.6915\n",
            "Epoch 140/200\n",
            "106/106 [==============================] - 50s 468ms/step - loss: 0.7174 - sparse_categorical_accuracy: 0.6593 - val_loss: 0.7481 - val_sparse_categorical_accuracy: 0.6962\n",
            "Epoch 141/200\n",
            "106/106 [==============================] - 49s 467ms/step - loss: 0.7038 - sparse_categorical_accuracy: 0.6616 - val_loss: 0.7401 - val_sparse_categorical_accuracy: 0.6980\n",
            "Epoch 142/200\n",
            "106/106 [==============================] - 50s 468ms/step - loss: 0.7070 - sparse_categorical_accuracy: 0.6624 - val_loss: 0.7134 - val_sparse_categorical_accuracy: 0.7051\n",
            "Epoch 143/200\n",
            "106/106 [==============================] - 49s 467ms/step - loss: 0.7101 - sparse_categorical_accuracy: 0.6600 - val_loss: 0.7211 - val_sparse_categorical_accuracy: 0.7069\n",
            "Epoch 144/200\n",
            "106/106 [==============================] - 49s 467ms/step - loss: 0.7047 - sparse_categorical_accuracy: 0.6646 - val_loss: 0.7106 - val_sparse_categorical_accuracy: 0.7145\n",
            "Epoch 145/200\n",
            "106/106 [==============================] - 49s 467ms/step - loss: 0.6861 - sparse_categorical_accuracy: 0.6711 - val_loss: 0.7368 - val_sparse_categorical_accuracy: 0.7021\n",
            "Epoch 146/200\n",
            "106/106 [==============================] - 49s 467ms/step - loss: 0.7035 - sparse_categorical_accuracy: 0.6687 - val_loss: 0.7179 - val_sparse_categorical_accuracy: 0.7057\n",
            "Epoch 147/200\n",
            "106/106 [==============================] - 49s 467ms/step - loss: 0.6998 - sparse_categorical_accuracy: 0.6622 - val_loss: 0.7140 - val_sparse_categorical_accuracy: 0.7086\n",
            "Epoch 148/200\n",
            "106/106 [==============================] - 49s 467ms/step - loss: 0.6880 - sparse_categorical_accuracy: 0.6742 - val_loss: 0.7035 - val_sparse_categorical_accuracy: 0.7128\n",
            "Epoch 149/200\n",
            "106/106 [==============================] - 49s 467ms/step - loss: 0.6775 - sparse_categorical_accuracy: 0.6835 - val_loss: 0.7140 - val_sparse_categorical_accuracy: 0.7092\n",
            "Epoch 150/200\n",
            "106/106 [==============================] - 49s 467ms/step - loss: 0.6669 - sparse_categorical_accuracy: 0.6835 - val_loss: 0.7055 - val_sparse_categorical_accuracy: 0.7134\n",
            "Epoch 151/200\n",
            "106/106 [==============================] - 50s 468ms/step - loss: 0.6645 - sparse_categorical_accuracy: 0.6900 - val_loss: 0.6848 - val_sparse_categorical_accuracy: 0.7210\n",
            "Epoch 152/200\n",
            "106/106 [==============================] - 49s 467ms/step - loss: 0.6754 - sparse_categorical_accuracy: 0.6770 - val_loss: 0.6872 - val_sparse_categorical_accuracy: 0.7228\n",
            "Epoch 153/200\n",
            "106/106 [==============================] - 50s 468ms/step - loss: 0.6510 - sparse_categorical_accuracy: 0.6919 - val_loss: 0.6920 - val_sparse_categorical_accuracy: 0.7270\n",
            "Epoch 154/200\n",
            "106/106 [==============================] - 50s 468ms/step - loss: 0.6561 - sparse_categorical_accuracy: 0.6834 - val_loss: 0.6797 - val_sparse_categorical_accuracy: 0.7228\n",
            "Epoch 155/200\n",
            "106/106 [==============================] - 50s 467ms/step - loss: 0.6523 - sparse_categorical_accuracy: 0.6829 - val_loss: 0.6851 - val_sparse_categorical_accuracy: 0.7287\n",
            "Epoch 156/200\n",
            "106/106 [==============================] - 49s 467ms/step - loss: 0.6575 - sparse_categorical_accuracy: 0.6897 - val_loss: 0.6743 - val_sparse_categorical_accuracy: 0.7370\n",
            "Epoch 157/200\n",
            "106/106 [==============================] - 49s 467ms/step - loss: 0.6487 - sparse_categorical_accuracy: 0.6900 - val_loss: 0.6891 - val_sparse_categorical_accuracy: 0.7240\n",
            "Epoch 158/200\n",
            " 40/106 [==========>...................] - ETA: 28s - loss: 0.6353 - sparse_categorical_accuracy: 0.7090"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "id": "E5W7-Qi6vG_9",
        "outputId": "dc2cfa92-574f-41b8-9134-b2ec0ef670e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-acc519fcce62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['acc'], label='train')\n",
        "plt.plot(history.history['val_acc'], label='test')\n",
        "plt.legend();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "qS3hSLpYWYAa",
        "outputId": "c2123b03-85d2-4c91-f5e1-d7097a39793d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}
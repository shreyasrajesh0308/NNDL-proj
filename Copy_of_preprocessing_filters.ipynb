{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of preprocessing_filters.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shreyasrajesh0308/NNDL-proj/blob/main/Copy_of_preprocessing_filters.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Paper: "
      ],
      "metadata": {
        "id": "Wy-ORg0nyKtV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Data \n",
        "\n",
        "Load preprocessed data"
      ],
      "metadata": {
        "id": "5Fl4uJtrAqU0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Scu17GL9A7i5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcb6cb44-d3c0-45e9-de3b-6d4a1df267f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.wrappers.scikit_learn import KerasClassifier"
      ],
      "metadata": {
        "id": "2gXQ7pXTIqqT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_test = np.load(\"/content/drive/MyDrive/eeg_project/X_test.npy\")\n",
        "y_test = np.load(\"/content/drive/MyDrive/eeg_project/y_test.npy\")\n",
        "person_train_valid = np.load(\"/content/drive/MyDrive/eeg_project/person_train_valid.npy\")\n",
        "X_train_valid = np.load(\"/content/drive/MyDrive/eeg_project/X_train_valid.npy\")\n",
        "y_train_valid = np.load(\"/content/drive/MyDrive/eeg_project/y_train_valid.npy\")\n",
        "person_test = np.load(\"/content/drive/MyDrive/eeg_project/person_test.npy\")\n"
      ],
      "metadata": {
        "id": "foTd2q3JIreb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print ('Training/Valid data shape: {}'.format(X_train_valid.shape))\n",
        "print ('Test data shape: {}'.format(X_test.shape))\n",
        "print ('Training/Valid target shape: {}'.format(y_train_valid.shape))\n",
        "print ('Test target shape: {}'.format(y_test.shape))\n",
        "print ('Person train/valid shape: {}'.format(person_train_valid.shape))\n",
        "print ('Person test shape: {}'.format(person_test.shape))\n"
      ],
      "metadata": {
        "id": "g6VAQSVEUtIW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90098d0d-3226-4371-d32b-4c013bd9900a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training/Valid data shape: (2115, 22, 1000)\n",
            "Test data shape: (443, 22, 1000)\n",
            "Training/Valid target shape: (2115,)\n",
            "Test target shape: (443,)\n",
            "Person train/valid shape: (2115, 1)\n",
            "Person test shape: (443, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.unique(y_train_valid))\n",
        "print(np.unique(y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhxR60r5IzuR",
        "outputId": "9996568b-f882-42c8-ebe4-80f133468b1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[769 770 771 772]\n",
            "[769 770 771 772]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 4\n",
        "y_train_valid = y_train_valid-769\n",
        "y_test = y_test-769"
      ],
      "metadata": {
        "id": "U4K1wzmfI4Rb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_prep(X,y,sub_sample,average,noise):\n",
        "    \n",
        "    total_X = None\n",
        "    total_y = None\n",
        "    \n",
        "    # Trimming the data (sample,22,1000) -> (sample,22,500)\n",
        "    X = X[:,:,0:500]\n",
        "    print('Shape of X after trimming:',X.shape)\n",
        "    \n",
        "    # Maxpooling the data (sample,22,1000) -> (sample,22,500/sub_sample)\n",
        "    X_max = np.max(X.reshape(X.shape[0], X.shape[1], -1, sub_sample), axis=3)\n",
        "    \n",
        "    \n",
        "    total_X = X_max\n",
        "    total_y = y\n",
        "    print('Shape of X after maxpooling:',total_X.shape)\n",
        "    \n",
        "    # Averaging + noise \n",
        "    X_average = np.mean(X.reshape(X.shape[0], X.shape[1], -1, average),axis=3)\n",
        "    X_average = X_average + np.random.normal(0.0, 0.5, X_average.shape)\n",
        "    \n",
        "    total_X = np.vstack((total_X, X_average))\n",
        "    total_y = np.hstack((total_y, y))\n",
        "    print('Shape of X after averaging+noise and concatenating:',total_X.shape)\n",
        "    \n",
        "    # Subsampling\n",
        "    \n",
        "    for i in range(sub_sample):\n",
        "        \n",
        "        X_subsample = X[:, :, i::sub_sample] + \\\n",
        "                            (np.random.normal(0.0, 0.5, X[:, :,i::sub_sample].shape) if noise else 0.0)\n",
        "            \n",
        "        total_X = np.vstack((total_X, X_subsample))\n",
        "        total_y = np.hstack((total_y, y))\n",
        "        \n",
        "    \n",
        "    print('Shape of X after subsampling and concatenating:',total_X.shape)\n",
        "    return total_X,total_y\n",
        "\n",
        "\n",
        "X_train_valid_prep,y_train_valid_prep = data_prep(X_train_valid,y_train_valid,2,2,True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-ubjiWDpR_W",
        "outputId": "9e01d1a1-8505-4f6b-85a4-079cecc55f89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X after trimming: (2115, 22, 500)\n",
            "Shape of X after maxpooling: (2115, 22, 250)\n",
            "Shape of X after averaging+noise and concatenating: (4230, 22, 250)\n",
            "Shape of X after subsampling and concatenating: (8460, 22, 250)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def data_prep_test(X,y, sub_sample=2):\n",
        "    \n",
        "    total_X = None\n",
        "    total_y = None\n",
        "    \n",
        "    # Trimming the data (sample,22,1000) -> (sample,22,500)\n",
        "    X = X[:,:,0:500]\n",
        "    print('Shape of X after trimming:',X.shape)\n",
        "    \n",
        "    # Maxpooling the data (sample,22,1000) -> (sample,22,500/sub_sample)\n",
        "    X_max = np.max(X.reshape(X.shape[0], X.shape[1], -1, sub_sample), axis=3)\n",
        "    \n",
        "    \n",
        "    total_X = X_max\n",
        "    total_y = y\n",
        "    print('Shape of X after maxpooling:',total_X.shape)\n",
        "    return total_X,total_y\n",
        "\n",
        "\n",
        "X_test,y_test = data_prep_test(X_test, y_test,2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhtalewhtI6R",
        "outputId": "b034880d-f91c-4f58-c168-1767c60a900f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X after trimming: (443, 22, 500)\n",
            "Shape of X after maxpooling: (443, 22, 250)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def spatial_prep(X):\n",
        "  # new_X = []\n",
        "  # X = X.tolist()\n",
        "  X = np.swapaxes(X, 0, 1)\n",
        "\n",
        "  sh = (X.shape[1],X.shape[2])\n",
        "  new_X = np.array([[np.zeros(sh), np.zeros(sh), np.zeros(sh), X[0,:,:], np.zeros(sh), np.zeros(sh), np.zeros(sh)],\n",
        "                [np.zeros(sh), X[1,:,:], X[2,:,:], X[3,:,:], X[4,:,:], X[5,:,:], np.zeros(sh)],\n",
        "                [X[6,:,:],X[7,:,:],X[8,:,:],X[9,:,:],X[10,:,:],X[11,:,:],X[12,:,:]],\n",
        "                [np.zeros(sh), X[13,:,:],X[14,:,:],X[15,:,:],X[16,:,:],X[17,:,:], np.zeros(sh)],\n",
        "                [np.zeros(sh), np.zeros(sh), X[18,:,:],X[19,:,:],X[20,:,:], np.zeros(sh), np.zeros(sh)],\n",
        "                [np.zeros(sh), np.zeros(sh), np.zeros(sh), X[21,:,:], np.zeros(sh), np.zeros(sh), np.zeros(sh)]])\n",
        "\n",
        "  # for x_seq in X:\n",
        "  #   n = len(X)\n",
        "  #   # new_seq_X = np.array([np.array([np.zeros(n), np.zeros(n), np.zeros(n), np.array(x_seq[0]), np.zeros(n), np.zeros(n), np.zeros(n)]),\n",
        "  #   #              np.array([np.zeros(n), np.array(x_seq[1]), np.array(x_seq[2]), np.array(x_seq[3]), np.array(x_seq[4]), np.array(x_seq[5]), np.zeros(n)]),\n",
        "  #   #              np.array([np.array(x_seq[6]), np.array(x_seq[7]), np.array(x_seq[8]), np.array(x_seq[9]), np.array(x_seq[10]), np.array(x_seq[11]), np.array(x_seq[12])]),\n",
        "  #   #              np.array([np.zeros(n), np.array(x_seq[13]), np.array(x_seq[14]), np.array(x_seq[15]), np.array(x_seq[16]), np.array(x_seq[17]), np.zeros(n)]),\n",
        "  #   #              np.array([np.zeros(n), np.zeros(n), np.array(x_seq[18]), np.array(x_seq[19]), np.array(x_seq[20]), np.zeros(n), np.zeros(n)]),\n",
        "  #   #              np.array([np.zeros(n), np.zeros(n), np.zeros(n), np.array(x_seq[21]), np.zeros(n), np.zeros(n), np.zeros(n)])])\n",
        "  #   # new_X.append(new_seq_X)\n",
        "  #   new_seq_X = np.array([[[0]*n, [0]*n, [0]*n, x_seq[0], [0]*n, [0]*n, [0]*n ],\n",
        "  #                [[0]*n, x_seq[1], x_seq[2], x_seq[3], x_seq[4], x_seq[5], [0]*n ],\n",
        "  #                [x_seq[6], x_seq[7], x_seq[8], x_seq[9], x_seq[10], x_seq[11], x_seq[12]],\n",
        "  #                [[0]*n, x_seq[13], x_seq[14], x_seq[15], x_seq[16], x_seq[17], [0]*n],\n",
        "  #                [[0]*n, [0]*n, x_seq[18], x_seq[19], x_seq[20], [0]*n, [0]*n],\n",
        "  #                [[0]*n, [0]*n, [0]*n, x_seq[21], [0]*n, [0]*n, [0]*n]])\n",
        "  #   new_X.append(new_seq_X)\n",
        "\n",
        "  # new_X = np.array(new_X)\n",
        "  new_X = np.swapaxes(new_X, 0,2)\n",
        "  new_X = np.swapaxes(new_X, 1,2)\n",
        "  return new_X"
      ],
      "metadata": {
        "id": "-u8tro1jwuon"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_spatial_prep = spatial_prep(X_train_valid_prep)"
      ],
      "metadata": {
        "id": "flRuB5gPygqF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_spatial_test = spatial_prep(X_test)"
      ],
      "metadata": {
        "id": "spWmKQWT3qd1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_spatial_prep.shape, X_spatial_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3rD3lYUyumZ",
        "outputId": "6df4fcea-e459-425e-82c0-d4b8665b6e4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8460, 6, 7, 250) (443, 6, 7, 250)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_copy = X_train_valid_prep.copy()\n",
        "X_test_copy = X_test.copy()\n",
        "\n",
        "from scipy import signal\n",
        "\n",
        "n, wn = signal.buttord(wp=[8, 13], ws=[6, 18], fs=125, gpass=1, gstop=36)\n",
        "sos1 = signal.butter(n, wn, btype='bandpass', fs=125, output='sos')\n",
        "\n",
        "n, wn = signal.buttord(wp=[13, 30], ws=[8, 48], fs=125, gpass=1, gstop=36)\n",
        "sos2 = signal.butter(n, wn, btype='bandpass', fs=125, output='sos')\n",
        "\n",
        "X_train_valid_filtered_1 = signal.sosfiltfilt(sos1, X_train_valid_prep, axis=-1)\n",
        "X_train_valid_prep = signal.sosfiltfilt(sos2, X_train_valid_filtered_1, axis=-1)\n",
        "X_test_filtered_1 = signal.sosfiltfilt(sos1, X_test, axis=-1)\n",
        "X_test = signal.sosfiltfilt(sos2, X_test_filtered_1, axis=-1)"
      ],
      "metadata": {
        "id": "PZ-1BIQ5JDN_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(X_train_valid_prep[0][0], color = 'blue')\n",
        "plt.plot(X_train_copy[0][0], color = 'orange')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "mOUuYZ2VMd26",
        "outputId": "eecce03c-8787-418e-88cb-ecb10816d354"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f4ed45ba210>]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "y_train_valid_prep = keras.utils.to_categorical(y_train_valid_prep, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "metadata": {
        "id": "NZWq7ZCFq5z9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train_valid_prep.shape,y_train_valid_prep.shape, X_spatial_prep.shape, X_spatial_test.shape)\n",
        "print(X_test.shape, y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFZfw6CuqeBs",
        "outputId": "c81d588c-138b-48d2-825b-c992ab0fad54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8460, 22, 250) (8460, 4) (8460, 6, 7, 250) (443, 6, 7, 250)\n",
            "(443, 22, 250) (443, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_spatial_prep  = np.swapaxes(X_spatial_prep , 1,3)\n",
        "X_spatial_prep = np.swapaxes(X_spatial_prep , 2,3)\n",
        "X_spatial_test  = np.swapaxes(X_spatial_test , 1,3)\n",
        "X_spatial_test = np.swapaxes(X_spatial_test , 2,3)"
      ],
      "metadata": {
        "id": "b3_pN5eAY1bg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_spatial_prep = X_spatial_prep.reshape(*X_spatial_prep.shape, 1)\n",
        "X_spatial_test = X_spatial_test.reshape(*X_spatial_test.shape, 1)"
      ],
      "metadata": {
        "id": "FeiaaX6qX3-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train_valid_prep.shape,y_train_valid_prep.shape, X_spatial_prep.shape, X_spatial_test.shape)\n",
        "print(X_test.shape, y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1MC6IQn7YEF-",
        "outputId": "dad02cce-e1ce-4802-cd1d-ac7cb95ab70a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8460, 22, 250) (8460, 4) (8460, 250, 6, 7, 1) (443, 250, 6, 7, 1)\n",
            "(443, 22, 250) (443, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CNN + GRU model with all subjects"
      ],
      "metadata": {
        "id": "IxgOEM-3WIPG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Conv2D, BatchNormalization, Activation, Flatten, Dense, Dropout, LSTM, Input, TimeDistributed, Permute, Reshape, MaxPooling2D, GRU\n",
        "from keras import initializers, Model, optimizers, callbacks\n",
        "from keras import Sequential\n",
        "from keras import backend as K\n",
        "from keras.models import load_model\n",
        "from keras.callbacks import Callback\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score"
      ],
      "metadata": {
        "id": "GswnoLTxWgFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Complicated Model - the same as Zhang`s\n",
        "# input_shape = (250, 6, 7, 1)\n",
        "# lecun = initializers.lecun_normal(seed=42)\n",
        "\n",
        "# # TimeDistributed Wrapper\n",
        "# def timeDist(layer, prev_layer, name):\n",
        "#     return TimeDistributed(layer, name=name)(prev_layer)\n",
        "    \n",
        "# # Input layer\n",
        "# inputs = Input(shape=input_shape)\n",
        "\n",
        "# # Convolutional layers block\n",
        "# x = timeDist(Conv2D(32, (3,3), padding='same', \n",
        "#                     data_format='channels_last', kernel_initializer=lecun), inputs, name='CNN1')\n",
        "# x = BatchNormalization(name='batch1')(x)\n",
        "# x = Activation('elu', name='act1')(x)\n",
        "# x = timeDist(Conv2D(64, (3,3), padding='same', data_format='channels_last', kernel_initializer=lecun), x, name='CNN2')\n",
        "# x = BatchNormalization(name='batch2')(x)\n",
        "# x = Activation('elu', name='act2')(x)\n",
        "# x = timeDist(Conv2D(128, (3,3), padding='same', data_format='channels_last', kernel_initializer=lecun), x, name='CNN3')\n",
        "# x = BatchNormalization(name='batch3')(x)\n",
        "# x = Activation('elu', name='act3')(x)\n",
        "# x = timeDist(Flatten(), x, name='flatten')\n",
        "\n",
        "# # Fully connected layer block\n",
        "# y = Dense(64, kernel_initializer=lecun, name='FC')(x)\n",
        "# y = Dropout(0.5, name='dropout1')(y)\n",
        "# y = BatchNormalization(name='batch4')(y)\n",
        "# y = Activation(activation='elu')(y)\n",
        "\n",
        "# # Recurrent layers block\n",
        "# #z = LSTM(64, kernel_initializer=lecun, return_sequences=True, name='LSTM1')(y)\n",
        "# z = LSTM(64, kernel_initializer=lecun, name='LSTM2')(y)\n",
        "\n",
        "# # Fully connected layer block\n",
        "# h = Dense(128, kernel_initializer=lecun, activation='relu', name='FC2')(z)\n",
        "# h = Dropout(0.5, name='dropout2')(h)\n",
        "\n",
        "# # Output layer\n",
        "# outputs = Dense(4, activation='softmax')(h)\n",
        "\n",
        "# # Model compile\n",
        "# model = Model(inputs=inputs, outputs=outputs)\n",
        "# model.summary()\n",
        "\n",
        "lecun = initializers.lecun_normal(seed=42)\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Permute((2, 1), input_shape=(22, 250)))\n",
        "model.add(Reshape((250, 22, 1)))\n",
        "\n",
        "model.add(Conv2D(filters=25, kernel_size=(10,1), kernel_initializer = lecun, strides=1, data_format=\"channels_last\"))\n",
        "model.add(Conv2D(filters=25, kernel_size=(1,22), kernel_initializer = lecun ))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation(activation = 'elu'))\n",
        "model.add(MaxPooling2D(pool_size = (3,1), strides = (3,1)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Conv Pool Block 2\n",
        "model.add(Conv2D(filters = 50, kernel_size = (10,1), activation = 'elu', kernel_initializer = lecun))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation(activation = 'elu'))\n",
        "model.add(MaxPooling2D(pool_size = (3,1), strides = (3,1)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Permute((1, 3, 2)))\n",
        "model.add(Reshape((23, 50)))\n",
        "\n",
        "# GRU layers\n",
        "model.add(GRU(16, return_sequences=True))\n",
        "model.add(GRU(16, return_sequences=True))\n",
        "# model.add(GRU(16, return_sequences=True))\n",
        "# model.add(GRU(16, return_sequences=True))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Dense layers\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=4, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print(model.summary())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSm44W_mWdxt",
        "outputId": "70603954-0862-40aa-fa18-08cf6dee981b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " permute (Permute)           (None, 250, 22)           0         \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 250, 22, 1)        0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 241, 22, 25)       275       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 241, 1, 25)        13775     \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 241, 1, 25)       100       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " activation (Activation)     (None, 241, 1, 25)        0         \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 80, 1, 25)        0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 80, 1, 25)         0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 71, 1, 50)         12550     \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 71, 1, 50)        200       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 71, 1, 50)         0         \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 23, 1, 50)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 23, 1, 50)         0         \n",
            "                                                                 \n",
            " permute_1 (Permute)         (None, 23, 50, 1)         0         \n",
            "                                                                 \n",
            " reshape_1 (Reshape)         (None, 23, 50)            0         \n",
            "                                                                 \n",
            " gru (GRU)                   (None, 23, 16)            3264      \n",
            "                                                                 \n",
            " gru_1 (GRU)                 (None, 23, 16)            1632      \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 23, 16)            0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 368)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 4)                 1476      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 33,272\n",
            "Trainable params: 33,122\n",
            "Non-trainable params: 150\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "history = model.fit(X_train_valid_prep, y_train_valid_prep, batch_size=64, epochs=1000, shuffle=True,\n",
        "                    validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQNJ4-8OXRB0",
        "outputId": "718de7f4-bca7-4a4a-dbfc-02318c53d500"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "106/106 [==============================] - 18s 37ms/step - loss: 1.4364 - acc: 0.2575 - val_loss: 1.3936 - val_acc: 0.2689\n",
            "Epoch 2/1000\n",
            "106/106 [==============================] - 2s 22ms/step - loss: 1.3914 - acc: 0.2806 - val_loss: 1.3610 - val_acc: 0.2996\n",
            "Epoch 3/1000\n",
            "106/106 [==============================] - 2s 23ms/step - loss: 1.3723 - acc: 0.3019 - val_loss: 1.3416 - val_acc: 0.3375\n",
            "Epoch 4/1000\n",
            "106/106 [==============================] - 3s 24ms/step - loss: 1.3487 - acc: 0.3329 - val_loss: 1.3152 - val_acc: 0.3576\n",
            "Epoch 5/1000\n",
            "106/106 [==============================] - 3s 29ms/step - loss: 1.3247 - acc: 0.3508 - val_loss: 1.2950 - val_acc: 0.3552\n",
            "Epoch 6/1000\n",
            "106/106 [==============================] - 3s 26ms/step - loss: 1.3018 - acc: 0.3766 - val_loss: 1.2533 - val_acc: 0.4072\n",
            "Epoch 7/1000\n",
            "106/106 [==============================] - 3s 26ms/step - loss: 1.2760 - acc: 0.3952 - val_loss: 1.2580 - val_acc: 0.4125\n",
            "Epoch 8/1000\n",
            "106/106 [==============================] - 3s 26ms/step - loss: 1.2667 - acc: 0.4012 - val_loss: 1.2317 - val_acc: 0.4297\n",
            "Epoch 9/1000\n",
            "106/106 [==============================] - 3s 25ms/step - loss: 1.2476 - acc: 0.4143 - val_loss: 1.2106 - val_acc: 0.4309\n",
            "Epoch 10/1000\n",
            "106/106 [==============================] - 3s 26ms/step - loss: 1.2303 - acc: 0.4303 - val_loss: 1.1976 - val_acc: 0.4527\n",
            "Epoch 11/1000\n",
            "106/106 [==============================] - 3s 25ms/step - loss: 1.2187 - acc: 0.4310 - val_loss: 1.1889 - val_acc: 0.4515\n",
            "Epoch 12/1000\n",
            "106/106 [==============================] - 3s 25ms/step - loss: 1.2018 - acc: 0.4467 - val_loss: 1.2033 - val_acc: 0.4551\n",
            "Epoch 13/1000\n",
            "106/106 [==============================] - 3s 25ms/step - loss: 1.1865 - acc: 0.4545 - val_loss: 1.1667 - val_acc: 0.4704\n",
            "Epoch 14/1000\n",
            "106/106 [==============================] - 3s 25ms/step - loss: 1.1790 - acc: 0.4566 - val_loss: 1.1901 - val_acc: 0.4586\n",
            "Epoch 15/1000\n",
            "106/106 [==============================] - 3s 25ms/step - loss: 1.1690 - acc: 0.4600 - val_loss: 1.1454 - val_acc: 0.4775\n",
            "Epoch 16/1000\n",
            "106/106 [==============================] - 3s 25ms/step - loss: 1.1610 - acc: 0.4737 - val_loss: 1.1122 - val_acc: 0.4923\n",
            "Epoch 17/1000\n",
            "106/106 [==============================] - 3s 25ms/step - loss: 1.1401 - acc: 0.4907 - val_loss: 1.1331 - val_acc: 0.4752\n",
            "Epoch 18/1000\n",
            "106/106 [==============================] - 3s 25ms/step - loss: 1.1346 - acc: 0.4917 - val_loss: 1.0969 - val_acc: 0.5071\n",
            "Epoch 19/1000\n",
            "106/106 [==============================] - 3s 25ms/step - loss: 1.1299 - acc: 0.4936 - val_loss: 1.0681 - val_acc: 0.5396\n",
            "Epoch 20/1000\n",
            "106/106 [==============================] - 3s 26ms/step - loss: 1.1058 - acc: 0.5114 - val_loss: 1.0627 - val_acc: 0.5349\n",
            "Epoch 21/1000\n",
            "106/106 [==============================] - 3s 25ms/step - loss: 1.0988 - acc: 0.5058 - val_loss: 1.0586 - val_acc: 0.5390\n",
            "Epoch 22/1000\n",
            "106/106 [==============================] - 3s 25ms/step - loss: 1.0960 - acc: 0.5195 - val_loss: 1.0230 - val_acc: 0.5626\n",
            "Epoch 23/1000\n",
            "106/106 [==============================] - 3s 25ms/step - loss: 1.0844 - acc: 0.5177 - val_loss: 1.0397 - val_acc: 0.5449\n",
            "Epoch 24/1000\n",
            "106/106 [==============================] - 3s 25ms/step - loss: 1.0716 - acc: 0.5197 - val_loss: 1.0175 - val_acc: 0.5573\n",
            "Epoch 25/1000\n",
            "106/106 [==============================] - 3s 26ms/step - loss: 1.0755 - acc: 0.5154 - val_loss: 1.0158 - val_acc: 0.5668\n",
            "Epoch 26/1000\n",
            "106/106 [==============================] - 3s 25ms/step - loss: 1.0562 - acc: 0.5418 - val_loss: 1.0073 - val_acc: 0.5603\n",
            "Epoch 27/1000\n",
            "106/106 [==============================] - 3s 25ms/step - loss: 1.0482 - acc: 0.5417 - val_loss: 0.9746 - val_acc: 0.5857\n",
            "Epoch 28/1000\n",
            "106/106 [==============================] - 3s 25ms/step - loss: 1.0324 - acc: 0.5529 - val_loss: 1.0300 - val_acc: 0.5621\n",
            "Epoch 29/1000\n",
            "106/106 [==============================] - 3s 25ms/step - loss: 1.0305 - acc: 0.5477 - val_loss: 0.9595 - val_acc: 0.5910\n",
            "Epoch 30/1000\n",
            "106/106 [==============================] - 3s 25ms/step - loss: 1.0245 - acc: 0.5517 - val_loss: 0.9510 - val_acc: 0.5963\n",
            "Epoch 31/1000\n",
            "106/106 [==============================] - 3s 25ms/step - loss: 1.0145 - acc: 0.5581 - val_loss: 0.9470 - val_acc: 0.5833\n",
            "Epoch 32/1000\n",
            "106/106 [==============================] - 3s 25ms/step - loss: 1.0048 - acc: 0.5669 - val_loss: 0.9446 - val_acc: 0.5940\n",
            "Epoch 33/1000\n",
            "106/106 [==============================] - 3s 25ms/step - loss: 1.0023 - acc: 0.5647 - val_loss: 0.9396 - val_acc: 0.6005\n",
            "Epoch 34/1000\n",
            "106/106 [==============================] - 3s 26ms/step - loss: 0.9782 - acc: 0.5761 - val_loss: 0.9122 - val_acc: 0.6170\n",
            "Epoch 35/1000\n",
            "106/106 [==============================] - 3s 26ms/step - loss: 0.9839 - acc: 0.5714 - val_loss: 0.8888 - val_acc: 0.6206\n",
            "Epoch 36/1000\n",
            "106/106 [==============================] - 3s 26ms/step - loss: 0.9741 - acc: 0.5878 - val_loss: 0.8790 - val_acc: 0.6277\n",
            "Epoch 37/1000\n",
            "106/106 [==============================] - 3s 25ms/step - loss: 0.9627 - acc: 0.5853 - val_loss: 0.8601 - val_acc: 0.6288\n",
            "Epoch 38/1000\n",
            "106/106 [==============================] - 3s 26ms/step - loss: 0.9633 - acc: 0.5835 - val_loss: 0.8834 - val_acc: 0.6306\n",
            "Epoch 39/1000\n",
            "106/106 [==============================] - 3s 26ms/step - loss: 0.9526 - acc: 0.5963 - val_loss: 0.8737 - val_acc: 0.6324\n",
            "Epoch 40/1000\n",
            "106/106 [==============================] - 3s 26ms/step - loss: 0.9434 - acc: 0.6006 - val_loss: 0.8536 - val_acc: 0.6448\n",
            "Epoch 41/1000\n",
            "106/106 [==============================] - 3s 26ms/step - loss: 0.9520 - acc: 0.5919 - val_loss: 0.8422 - val_acc: 0.6507\n",
            "Epoch 42/1000\n",
            "106/106 [==============================] - 3s 25ms/step - loss: 0.9318 - acc: 0.6025 - val_loss: 0.8317 - val_acc: 0.6543\n",
            "Epoch 43/1000\n",
            "106/106 [==============================] - 3s 25ms/step - loss: 0.9273 - acc: 0.6113 - val_loss: 0.8267 - val_acc: 0.6537\n",
            "Epoch 44/1000\n",
            "106/106 [==============================] - 3s 25ms/step - loss: 0.9162 - acc: 0.6150 - val_loss: 0.8344 - val_acc: 0.6466\n",
            "Epoch 45/1000\n",
            "106/106 [==============================] - 3s 26ms/step - loss: 0.9255 - acc: 0.6064 - val_loss: 0.8149 - val_acc: 0.6566\n",
            "Epoch 46/1000\n",
            "106/106 [==============================] - 3s 26ms/step - loss: 0.9173 - acc: 0.6110 - val_loss: 0.7951 - val_acc: 0.6738\n",
            "Epoch 47/1000\n",
            "106/106 [==============================] - 3s 26ms/step - loss: 0.9008 - acc: 0.6175 - val_loss: 0.8087 - val_acc: 0.6767\n",
            "Epoch 48/1000\n",
            "106/106 [==============================] - 3s 26ms/step - loss: 0.9040 - acc: 0.6138 - val_loss: 0.7915 - val_acc: 0.6690\n",
            "Epoch 49/1000\n",
            "106/106 [==============================] - 3s 26ms/step - loss: 0.8920 - acc: 0.6280 - val_loss: 0.7860 - val_acc: 0.6738\n",
            "Epoch 50/1000\n",
            "106/106 [==============================] - 3s 26ms/step - loss: 0.8809 - acc: 0.6308 - val_loss: 0.7983 - val_acc: 0.6720\n",
            "Epoch 51/1000\n",
            "106/106 [==============================] - 3s 25ms/step - loss: 0.8850 - acc: 0.6330 - val_loss: 0.7752 - val_acc: 0.6874\n",
            "Epoch 52/1000\n",
            "106/106 [==============================] - 3s 25ms/step - loss: 0.8847 - acc: 0.6266 - val_loss: 0.7736 - val_acc: 0.6850\n",
            "Epoch 53/1000\n",
            "106/106 [==============================] - 3s 25ms/step - loss: 0.8659 - acc: 0.6319 - val_loss: 0.7784 - val_acc: 0.6761\n",
            "Epoch 54/1000\n",
            "106/106 [==============================] - 3s 25ms/step - loss: 0.8718 - acc: 0.6330 - val_loss: 0.7583 - val_acc: 0.6897\n",
            "Epoch 55/1000\n",
            "106/106 [==============================] - 3s 25ms/step - loss: 0.8562 - acc: 0.6432 - val_loss: 0.7428 - val_acc: 0.6868\n",
            "Epoch 56/1000\n",
            "106/106 [==============================] - 3s 25ms/step - loss: 0.8532 - acc: 0.6451 - val_loss: 0.7307 - val_acc: 0.7063\n",
            "Epoch 57/1000\n",
            "106/106 [==============================] - 3s 26ms/step - loss: 0.8417 - acc: 0.6461 - val_loss: 0.7581 - val_acc: 0.6791\n",
            "Epoch 58/1000\n",
            "106/106 [==============================] - 3s 25ms/step - loss: 0.8479 - acc: 0.6451 - val_loss: 0.7120 - val_acc: 0.7157\n",
            "Epoch 59/1000\n",
            "106/106 [==============================] - 3s 25ms/step - loss: 0.8430 - acc: 0.6445 - val_loss: 0.7462 - val_acc: 0.6962\n",
            "Epoch 60/1000\n",
            "106/106 [==============================] - 3s 25ms/step - loss: 0.8353 - acc: 0.6473 - val_loss: 0.7151 - val_acc: 0.7128\n",
            "Epoch 61/1000\n",
            "106/106 [==============================] - 3s 25ms/step - loss: 0.8258 - acc: 0.6596 - val_loss: 0.7016 - val_acc: 0.7228\n",
            "Epoch 62/1000\n",
            "106/106 [==============================] - 3s 26ms/step - loss: 0.8199 - acc: 0.6661 - val_loss: 0.7162 - val_acc: 0.7045\n",
            "Epoch 63/1000\n",
            "106/106 [==============================] - 3s 25ms/step - loss: 0.8241 - acc: 0.6597 - val_loss: 0.6881 - val_acc: 0.7305\n",
            "Epoch 64/1000\n",
            "106/106 [==============================] - 3s 25ms/step - loss: 0.8200 - acc: 0.6630 - val_loss: 0.7040 - val_acc: 0.7169\n",
            "Epoch 65/1000\n",
            "106/106 [==============================] - 3s 26ms/step - loss: 0.8123 - acc: 0.6608 - val_loss: 0.6923 - val_acc: 0.7234\n",
            "Epoch 66/1000\n",
            "106/106 [==============================] - 3s 25ms/step - loss: 0.8052 - acc: 0.6715 - val_loss: 0.6917 - val_acc: 0.7199\n",
            "Epoch 67/1000\n",
            "106/106 [==============================] - 3s 25ms/step - loss: 0.7963 - acc: 0.6749 - val_loss: 0.7158 - val_acc: 0.6980\n",
            "Epoch 68/1000\n",
            "106/106 [==============================] - 3s 26ms/step - loss: 0.8034 - acc: 0.6668 - val_loss: 0.6703 - val_acc: 0.7423\n",
            "Epoch 69/1000\n",
            "106/106 [==============================] - 3s 25ms/step - loss: 0.7864 - acc: 0.6779 - val_loss: 0.6715 - val_acc: 0.7299\n",
            "Epoch 70/1000\n",
            "106/106 [==============================] - 3s 26ms/step - loss: 0.8017 - acc: 0.6733 - val_loss: 0.6468 - val_acc: 0.7400\n",
            "Epoch 71/1000\n",
            "106/106 [==============================] - 3s 25ms/step - loss: 0.7977 - acc: 0.6764 - val_loss: 0.6747 - val_acc: 0.7258\n",
            "Epoch 72/1000\n",
            "106/106 [==============================] - 3s 26ms/step - loss: 0.7790 - acc: 0.6769 - val_loss: 0.6707 - val_acc: 0.7240\n",
            "Epoch 73/1000\n",
            "106/106 [==============================] - 3s 26ms/step - loss: 0.7663 - acc: 0.6913 - val_loss: 0.6619 - val_acc: 0.7405\n",
            "Epoch 74/1000\n",
            "106/106 [==============================] - 3s 25ms/step - loss: 0.7631 - acc: 0.6876 - val_loss: 0.6602 - val_acc: 0.7329\n",
            "Epoch 75/1000\n",
            "106/106 [==============================] - 3s 26ms/step - loss: 0.7737 - acc: 0.6837 - val_loss: 0.6378 - val_acc: 0.7453\n",
            "Epoch 76/1000\n",
            "106/106 [==============================] - 3s 26ms/step - loss: 0.7714 - acc: 0.6835 - val_loss: 0.6538 - val_acc: 0.7405\n",
            "Epoch 77/1000\n",
            "106/106 [==============================] - 3s 25ms/step - loss: 0.7591 - acc: 0.6910 - val_loss: 0.6457 - val_acc: 0.7323\n",
            "Epoch 78/1000\n",
            "106/106 [==============================] - 3s 26ms/step - loss: 0.7617 - acc: 0.6896 - val_loss: 0.6354 - val_acc: 0.7465\n",
            "Epoch 79/1000\n",
            "106/106 [==============================] - 3s 26ms/step - loss: 0.7597 - acc: 0.6891 - val_loss: 0.6217 - val_acc: 0.7506\n",
            "Epoch 80/1000\n",
            "106/106 [==============================] - 3s 25ms/step - loss: 0.7692 - acc: 0.6854 - val_loss: 0.6009 - val_acc: 0.7748\n",
            "Epoch 81/1000\n",
            "106/106 [==============================] - 3s 25ms/step - loss: 0.7447 - acc: 0.6971 - val_loss: 0.6217 - val_acc: 0.7624\n",
            "Epoch 82/1000\n",
            "106/106 [==============================] - 3s 26ms/step - loss: 0.7627 - acc: 0.6862 - val_loss: 0.6254 - val_acc: 0.7541\n",
            "Epoch 83/1000\n",
            "106/106 [==============================] - 3s 26ms/step - loss: 0.7591 - acc: 0.6909 - val_loss: 0.6187 - val_acc: 0.7506\n",
            "Epoch 84/1000\n",
            "106/106 [==============================] - 3s 25ms/step - loss: 0.7591 - acc: 0.6933 - val_loss: 0.6177 - val_acc: 0.7559\n",
            "Epoch 85/1000\n",
            "106/106 [==============================] - 3s 25ms/step - loss: 0.7349 - acc: 0.7007 - val_loss: 0.6045 - val_acc: 0.7494\n",
            "Epoch 86/1000\n",
            "106/106 [==============================] - 3s 26ms/step - loss: 0.7488 - acc: 0.6974 - val_loss: 0.5977 - val_acc: 0.7701\n",
            "Epoch 87/1000\n",
            "106/106 [==============================] - 3s 26ms/step - loss: 0.7449 - acc: 0.6941 - val_loss: 0.5676 - val_acc: 0.7807\n",
            "Epoch 88/1000\n",
            "106/106 [==============================] - 3s 26ms/step - loss: 0.7431 - acc: 0.6998 - val_loss: 0.5671 - val_acc: 0.7819\n",
            "Epoch 89/1000\n",
            "106/106 [==============================] - 3s 26ms/step - loss: 0.7197 - acc: 0.7032 - val_loss: 0.5862 - val_acc: 0.7618\n",
            "Epoch 90/1000\n",
            "106/106 [==============================] - 3s 25ms/step - loss: 0.7286 - acc: 0.6998 - val_loss: 0.5775 - val_acc: 0.7819\n",
            "Epoch 91/1000\n",
            "106/106 [==============================] - 3s 26ms/step - loss: 0.7092 - acc: 0.7120 - val_loss: 0.5708 - val_acc: 0.7754\n",
            "Epoch 92/1000\n",
            "106/106 [==============================] - 3s 26ms/step - loss: 0.7201 - acc: 0.7032 - val_loss: 0.5822 - val_acc: 0.7683\n",
            "Epoch 93/1000\n",
            "106/106 [==============================] - 3s 25ms/step - loss: 0.7239 - acc: 0.7063 - val_loss: 0.5701 - val_acc: 0.7778\n",
            "Epoch 94/1000\n",
            "106/106 [==============================] - 3s 25ms/step - loss: 0.7290 - acc: 0.7064 - val_loss: 0.5849 - val_acc: 0.7660\n",
            "Epoch 95/1000\n",
            "106/106 [==============================] - 3s 26ms/step - loss: 0.7224 - acc: 0.7131 - val_loss: 0.5827 - val_acc: 0.7736\n",
            "Epoch 96/1000\n",
            "106/106 [==============================] - 3s 26ms/step - loss: 0.7238 - acc: 0.7116 - val_loss: 0.5691 - val_acc: 0.7855\n",
            "Epoch 97/1000\n",
            "106/106 [==============================] - 3s 26ms/step - loss: 0.7006 - acc: 0.7145 - val_loss: 0.5618 - val_acc: 0.7902\n",
            "Epoch 98/1000\n",
            "106/106 [==============================] - 3s 26ms/step - loss: 0.7092 - acc: 0.7094 - val_loss: 0.5796 - val_acc: 0.7796\n",
            "Epoch 99/1000\n",
            "106/106 [==============================] - 3s 26ms/step - loss: 0.7032 - acc: 0.7169 - val_loss: 0.5822 - val_acc: 0.7618\n",
            "Epoch 100/1000\n",
            "106/106 [==============================] - 3s 26ms/step - loss: 0.7081 - acc: 0.7188 - val_loss: 0.5557 - val_acc: 0.7878\n",
            "Epoch 101/1000\n",
            "106/106 [==============================] - 3s 26ms/step - loss: 0.7053 - acc: 0.7222 - val_loss: 0.5934 - val_acc: 0.7636\n",
            "Epoch 102/1000\n",
            "106/106 [==============================] - 3s 26ms/step - loss: 0.6893 - acc: 0.7225 - val_loss: 0.5554 - val_acc: 0.7725\n",
            "Epoch 103/1000\n",
            "106/106 [==============================] - 3s 25ms/step - loss: 0.6991 - acc: 0.7176 - val_loss: 0.5600 - val_acc: 0.7931\n",
            "Epoch 104/1000\n",
            "106/106 [==============================] - 3s 26ms/step - loss: 0.6943 - acc: 0.7244 - val_loss: 0.5409 - val_acc: 0.7831\n",
            "Epoch 105/1000\n",
            "106/106 [==============================] - 3s 25ms/step - loss: 0.6888 - acc: 0.7224 - val_loss: 0.5299 - val_acc: 0.8079\n",
            "Epoch 106/1000\n",
            "106/106 [==============================] - 3s 26ms/step - loss: 0.6868 - acc: 0.7216 - val_loss: 0.5288 - val_acc: 0.7890\n",
            "Epoch 107/1000\n",
            "106/106 [==============================] - 3s 25ms/step - loss: 0.6713 - acc: 0.7267 - val_loss: 0.5131 - val_acc: 0.8050\n",
            "Epoch 108/1000\n",
            "106/106 [==============================] - 3s 26ms/step - loss: 0.6972 - acc: 0.7196 - val_loss: 0.5351 - val_acc: 0.7991\n",
            "Epoch 109/1000\n",
            "106/106 [==============================] - 3s 26ms/step - loss: 0.6834 - acc: 0.7175 - val_loss: 0.5416 - val_acc: 0.7843\n",
            "Epoch 110/1000\n",
            "106/106 [==============================] - 3s 26ms/step - loss: 0.6928 - acc: 0.7187 - val_loss: 0.5281 - val_acc: 0.8002\n",
            "Epoch 111/1000\n",
            "106/106 [==============================] - 3s 25ms/step - loss: 0.6639 - acc: 0.7373 - val_loss: 0.5134 - val_acc: 0.8073\n",
            "Epoch 112/1000\n",
            "106/106 [==============================] - 3s 26ms/step - loss: 0.6785 - acc: 0.7256 - val_loss: 0.5106 - val_acc: 0.8067\n",
            "Epoch 113/1000\n",
            "106/106 [==============================] - 3s 25ms/step - loss: 0.6671 - acc: 0.7292 - val_loss: 0.5225 - val_acc: 0.7920\n",
            "Epoch 114/1000\n",
            "106/106 [==============================] - 3s 25ms/step - loss: 0.6712 - acc: 0.7296 - val_loss: 0.5199 - val_acc: 0.8032\n",
            "Epoch 115/1000\n",
            "106/106 [==============================] - 3s 26ms/step - loss: 0.6775 - acc: 0.7246 - val_loss: 0.5150 - val_acc: 0.7955\n",
            "Epoch 116/1000\n",
            "106/106 [==============================] - 3s 26ms/step - loss: 0.6588 - acc: 0.7320 - val_loss: 0.5225 - val_acc: 0.8002\n",
            "Epoch 117/1000\n",
            "106/106 [==============================] - 3s 25ms/step - loss: 0.6753 - acc: 0.7283 - val_loss: 0.5143 - val_acc: 0.8014\n",
            "Epoch 118/1000\n",
            "106/106 [==============================] - 3s 26ms/step - loss: 0.6636 - acc: 0.7346 - val_loss: 0.4850 - val_acc: 0.8233\n",
            "Epoch 119/1000\n",
            "106/106 [==============================] - 3s 25ms/step - loss: 0.6628 - acc: 0.7374 - val_loss: 0.5004 - val_acc: 0.8174\n",
            "Epoch 120/1000\n",
            "106/106 [==============================] - 3s 25ms/step - loss: 0.6545 - acc: 0.7411 - val_loss: 0.5108 - val_acc: 0.8026\n",
            "Epoch 121/1000\n",
            "106/106 [==============================] - 3s 26ms/step - loss: 0.6532 - acc: 0.7413 - val_loss: 0.5044 - val_acc: 0.8091\n",
            "Epoch 122/1000\n",
            "106/106 [==============================] - 3s 26ms/step - loss: 0.6626 - acc: 0.7357 - val_loss: 0.4853 - val_acc: 0.8215\n",
            "Epoch 123/1000\n",
            "106/106 [==============================] - 3s 26ms/step - loss: 0.6621 - acc: 0.7386 - val_loss: 0.5655 - val_acc: 0.7713\n",
            "Epoch 124/1000\n",
            "106/106 [==============================] - 3s 26ms/step - loss: 0.6411 - acc: 0.7425 - val_loss: 0.4987 - val_acc: 0.8150\n",
            "Epoch 125/1000\n",
            "106/106 [==============================] - 3s 26ms/step - loss: 0.6502 - acc: 0.7434 - val_loss: 0.5136 - val_acc: 0.8103\n",
            "Epoch 126/1000\n",
            "106/106 [==============================] - 3s 25ms/step - loss: 0.6470 - acc: 0.7413 - val_loss: 0.4651 - val_acc: 0.8262\n",
            "Epoch 127/1000\n",
            "106/106 [==============================] - 3s 27ms/step - loss: 0.6429 - acc: 0.7376 - val_loss: 0.4705 - val_acc: 0.8191\n",
            "Epoch 128/1000\n",
            "106/106 [==============================] - 3s 26ms/step - loss: 0.6535 - acc: 0.7379 - val_loss: 0.4835 - val_acc: 0.8310\n",
            "Epoch 129/1000\n",
            "106/106 [==============================] - 3s 26ms/step - loss: 0.6366 - acc: 0.7441 - val_loss: 0.4817 - val_acc: 0.8233\n",
            "Epoch 130/1000\n",
            "106/106 [==============================] - 3s 26ms/step - loss: 0.6326 - acc: 0.7465 - val_loss: 0.4909 - val_acc: 0.8132\n",
            "Epoch 131/1000\n",
            "106/106 [==============================] - 3s 26ms/step - loss: 0.6423 - acc: 0.7422 - val_loss: 0.4696 - val_acc: 0.8286\n",
            "Epoch 132/1000\n",
            "106/106 [==============================] - 3s 26ms/step - loss: 0.6365 - acc: 0.7457 - val_loss: 0.4696 - val_acc: 0.8245\n",
            "Epoch 133/1000\n",
            "106/106 [==============================] - 3s 25ms/step - loss: 0.6321 - acc: 0.7519 - val_loss: 0.4774 - val_acc: 0.8162\n",
            "Epoch 134/1000\n",
            "106/106 [==============================] - 3s 26ms/step - loss: 0.6512 - acc: 0.7370 - val_loss: 0.4754 - val_acc: 0.8239\n",
            "Epoch 135/1000\n",
            "106/106 [==============================] - 3s 26ms/step - loss: 0.6379 - acc: 0.7510 - val_loss: 0.4717 - val_acc: 0.8197\n",
            "Epoch 136/1000\n",
            "106/106 [==============================] - 3s 26ms/step - loss: 0.6347 - acc: 0.7490 - val_loss: 0.4923 - val_acc: 0.8032\n",
            "Epoch 137/1000\n",
            "106/106 [==============================] - 3s 26ms/step - loss: 0.6312 - acc: 0.7499 - val_loss: 0.4877 - val_acc: 0.8191\n",
            "Epoch 138/1000\n",
            "106/106 [==============================] - 3s 26ms/step - loss: 0.6326 - acc: 0.7485 - val_loss: 0.4852 - val_acc: 0.8126\n",
            "Epoch 139/1000\n",
            "106/106 [==============================] - 3s 26ms/step - loss: 0.6322 - acc: 0.7484 - val_loss: 0.4950 - val_acc: 0.8103\n",
            "Epoch 140/1000\n",
            "106/106 [==============================] - 3s 27ms/step - loss: 0.6221 - acc: 0.7467 - val_loss: 0.5017 - val_acc: 0.8038\n",
            "Epoch 141/1000\n",
            "106/106 [==============================] - 3s 28ms/step - loss: 0.6213 - acc: 0.7466 - val_loss: 0.4900 - val_acc: 0.8150\n",
            "Epoch 142/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.6455 - acc: 0.7442 - val_loss: 0.4878 - val_acc: 0.8144\n",
            "Epoch 143/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.6173 - acc: 0.7499 - val_loss: 0.4652 - val_acc: 0.8292\n",
            "Epoch 144/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.6309 - acc: 0.7475 - val_loss: 0.4750 - val_acc: 0.8339\n",
            "Epoch 145/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.6166 - acc: 0.7527 - val_loss: 0.4743 - val_acc: 0.8168\n",
            "Epoch 146/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.5981 - acc: 0.7630 - val_loss: 0.4661 - val_acc: 0.8191\n",
            "Epoch 147/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.6199 - acc: 0.7593 - val_loss: 0.4587 - val_acc: 0.8357\n",
            "Epoch 148/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.6153 - acc: 0.7581 - val_loss: 0.4933 - val_acc: 0.8121\n",
            "Epoch 149/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.6006 - acc: 0.7609 - val_loss: 0.4522 - val_acc: 0.8363\n",
            "Epoch 150/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.6019 - acc: 0.7580 - val_loss: 0.4532 - val_acc: 0.8292\n",
            "Epoch 151/1000\n",
            "106/106 [==============================] - 3s 29ms/step - loss: 0.6042 - acc: 0.7596 - val_loss: 0.4473 - val_acc: 0.8227\n",
            "Epoch 152/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.6065 - acc: 0.7626 - val_loss: 0.4310 - val_acc: 0.8422\n",
            "Epoch 153/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.6169 - acc: 0.7596 - val_loss: 0.4230 - val_acc: 0.8522\n",
            "Epoch 154/1000\n",
            "106/106 [==============================] - 3s 29ms/step - loss: 0.6005 - acc: 0.7617 - val_loss: 0.4330 - val_acc: 0.8416\n",
            "Epoch 155/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.6057 - acc: 0.7558 - val_loss: 0.4651 - val_acc: 0.8251\n",
            "Epoch 156/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.6114 - acc: 0.7556 - val_loss: 0.4541 - val_acc: 0.8310\n",
            "Epoch 157/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.6034 - acc: 0.7639 - val_loss: 0.4215 - val_acc: 0.8457\n",
            "Epoch 158/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.5945 - acc: 0.7717 - val_loss: 0.4401 - val_acc: 0.8345\n",
            "Epoch 159/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.6014 - acc: 0.7663 - val_loss: 0.4350 - val_acc: 0.8381\n",
            "Epoch 160/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.6087 - acc: 0.7655 - val_loss: 0.4400 - val_acc: 0.8446\n",
            "Epoch 161/1000\n",
            "106/106 [==============================] - 3s 32ms/step - loss: 0.5835 - acc: 0.7699 - val_loss: 0.4361 - val_acc: 0.8381\n",
            "Epoch 162/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.5948 - acc: 0.7624 - val_loss: 0.4221 - val_acc: 0.8517\n",
            "Epoch 163/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.5877 - acc: 0.7694 - val_loss: 0.4216 - val_acc: 0.8487\n",
            "Epoch 164/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.5936 - acc: 0.7643 - val_loss: 0.4103 - val_acc: 0.8475\n",
            "Epoch 165/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.5871 - acc: 0.7728 - val_loss: 0.4192 - val_acc: 0.8404\n",
            "Epoch 166/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.5934 - acc: 0.7655 - val_loss: 0.4331 - val_acc: 0.8381\n",
            "Epoch 167/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.5857 - acc: 0.7697 - val_loss: 0.3926 - val_acc: 0.8652\n",
            "Epoch 168/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.5880 - acc: 0.7699 - val_loss: 0.4406 - val_acc: 0.8316\n",
            "Epoch 169/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.5797 - acc: 0.7688 - val_loss: 0.4029 - val_acc: 0.8493\n",
            "Epoch 170/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.5992 - acc: 0.7618 - val_loss: 0.3952 - val_acc: 0.8706\n",
            "Epoch 171/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.5823 - acc: 0.7711 - val_loss: 0.4322 - val_acc: 0.8404\n",
            "Epoch 172/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.5649 - acc: 0.7810 - val_loss: 0.4311 - val_acc: 0.8381\n",
            "Epoch 173/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.5839 - acc: 0.7670 - val_loss: 0.4131 - val_acc: 0.8475\n",
            "Epoch 174/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.5940 - acc: 0.7674 - val_loss: 0.4240 - val_acc: 0.8434\n",
            "Epoch 175/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.5662 - acc: 0.7782 - val_loss: 0.3968 - val_acc: 0.8576\n",
            "Epoch 176/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.5863 - acc: 0.7688 - val_loss: 0.4148 - val_acc: 0.8522\n",
            "Epoch 177/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.5810 - acc: 0.7742 - val_loss: 0.3923 - val_acc: 0.8641\n",
            "Epoch 178/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.5520 - acc: 0.7837 - val_loss: 0.4074 - val_acc: 0.8511\n",
            "Epoch 179/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.5862 - acc: 0.7722 - val_loss: 0.4132 - val_acc: 0.8475\n",
            "Epoch 180/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.5660 - acc: 0.7766 - val_loss: 0.3943 - val_acc: 0.8587\n",
            "Epoch 181/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.5644 - acc: 0.7841 - val_loss: 0.4075 - val_acc: 0.8534\n",
            "Epoch 182/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.5745 - acc: 0.7754 - val_loss: 0.4029 - val_acc: 0.8534\n",
            "Epoch 183/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.5509 - acc: 0.7853 - val_loss: 0.3916 - val_acc: 0.8664\n",
            "Epoch 184/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.5485 - acc: 0.7812 - val_loss: 0.3762 - val_acc: 0.8700\n",
            "Epoch 185/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.5577 - acc: 0.7790 - val_loss: 0.3981 - val_acc: 0.8446\n",
            "Epoch 186/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.5413 - acc: 0.7866 - val_loss: 0.3760 - val_acc: 0.8700\n",
            "Epoch 187/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.5625 - acc: 0.7759 - val_loss: 0.3912 - val_acc: 0.8635\n",
            "Epoch 188/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.5572 - acc: 0.7803 - val_loss: 0.3862 - val_acc: 0.8593\n",
            "Epoch 189/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.5590 - acc: 0.7832 - val_loss: 0.3868 - val_acc: 0.8629\n",
            "Epoch 190/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.5854 - acc: 0.7699 - val_loss: 0.3861 - val_acc: 0.8564\n",
            "Epoch 191/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.5540 - acc: 0.7852 - val_loss: 0.3945 - val_acc: 0.8629\n",
            "Epoch 192/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.5484 - acc: 0.7861 - val_loss: 0.3728 - val_acc: 0.8670\n",
            "Epoch 193/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.5509 - acc: 0.7871 - val_loss: 0.3925 - val_acc: 0.8617\n",
            "Epoch 194/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.5564 - acc: 0.7787 - val_loss: 0.3844 - val_acc: 0.8605\n",
            "Epoch 195/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.5588 - acc: 0.7772 - val_loss: 0.4117 - val_acc: 0.8481\n",
            "Epoch 196/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.5421 - acc: 0.7853 - val_loss: 0.3984 - val_acc: 0.8552\n",
            "Epoch 197/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.5387 - acc: 0.7908 - val_loss: 0.3753 - val_acc: 0.8658\n",
            "Epoch 198/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.5532 - acc: 0.7832 - val_loss: 0.3738 - val_acc: 0.8611\n",
            "Epoch 199/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.5461 - acc: 0.7825 - val_loss: 0.3802 - val_acc: 0.8670\n",
            "Epoch 200/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.5486 - acc: 0.7832 - val_loss: 0.3657 - val_acc: 0.8723\n",
            "Epoch 201/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.5606 - acc: 0.7790 - val_loss: 0.3580 - val_acc: 0.8759\n",
            "Epoch 202/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.5433 - acc: 0.7818 - val_loss: 0.3559 - val_acc: 0.8753\n",
            "Epoch 203/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.5434 - acc: 0.7880 - val_loss: 0.3639 - val_acc: 0.8676\n",
            "Epoch 204/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.5630 - acc: 0.7813 - val_loss: 0.3982 - val_acc: 0.8469\n",
            "Epoch 205/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.5339 - acc: 0.7903 - val_loss: 0.3512 - val_acc: 0.8794\n",
            "Epoch 206/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.5386 - acc: 0.7902 - val_loss: 0.3938 - val_acc: 0.8422\n",
            "Epoch 207/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.5692 - acc: 0.7747 - val_loss: 0.3723 - val_acc: 0.8635\n",
            "Epoch 208/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.5383 - acc: 0.7902 - val_loss: 0.3532 - val_acc: 0.8824\n",
            "Epoch 209/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.5324 - acc: 0.7920 - val_loss: 0.3543 - val_acc: 0.8735\n",
            "Epoch 210/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.5327 - acc: 0.7923 - val_loss: 0.3742 - val_acc: 0.8676\n",
            "Epoch 211/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.5506 - acc: 0.7863 - val_loss: 0.3565 - val_acc: 0.8806\n",
            "Epoch 212/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.5190 - acc: 0.7971 - val_loss: 0.3705 - val_acc: 0.8670\n",
            "Epoch 213/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.5407 - acc: 0.7893 - val_loss: 0.3563 - val_acc: 0.8794\n",
            "Epoch 214/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.5391 - acc: 0.7868 - val_loss: 0.3513 - val_acc: 0.8818\n",
            "Epoch 215/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.5472 - acc: 0.7928 - val_loss: 0.3503 - val_acc: 0.8706\n",
            "Epoch 216/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.5219 - acc: 0.7952 - val_loss: 0.3409 - val_acc: 0.8836\n",
            "Epoch 217/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.5513 - acc: 0.7835 - val_loss: 0.3480 - val_acc: 0.8806\n",
            "Epoch 218/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.5267 - acc: 0.7961 - val_loss: 0.3632 - val_acc: 0.8723\n",
            "Epoch 219/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.5227 - acc: 0.7970 - val_loss: 0.3440 - val_acc: 0.8806\n",
            "Epoch 220/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.5281 - acc: 0.7933 - val_loss: 0.3805 - val_acc: 0.8694\n",
            "Epoch 221/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.5200 - acc: 0.7942 - val_loss: 0.3361 - val_acc: 0.8753\n",
            "Epoch 222/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.5478 - acc: 0.7934 - val_loss: 0.3506 - val_acc: 0.8812\n",
            "Epoch 223/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.5349 - acc: 0.7926 - val_loss: 0.3562 - val_acc: 0.8747\n",
            "Epoch 224/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.5258 - acc: 0.7977 - val_loss: 0.3538 - val_acc: 0.8777\n",
            "Epoch 225/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.5417 - acc: 0.7863 - val_loss: 0.3569 - val_acc: 0.8706\n",
            "Epoch 226/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.5223 - acc: 0.7962 - val_loss: 0.3590 - val_acc: 0.8735\n",
            "Epoch 227/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.5321 - acc: 0.7841 - val_loss: 0.3777 - val_acc: 0.8617\n",
            "Epoch 228/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.5216 - acc: 0.7958 - val_loss: 0.3689 - val_acc: 0.8700\n",
            "Epoch 229/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.5423 - acc: 0.7834 - val_loss: 0.3451 - val_acc: 0.8783\n",
            "Epoch 230/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.5105 - acc: 0.8033 - val_loss: 0.3502 - val_acc: 0.8824\n",
            "Epoch 231/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.5368 - acc: 0.7917 - val_loss: 0.3416 - val_acc: 0.8777\n",
            "Epoch 232/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.5236 - acc: 0.7957 - val_loss: 0.3303 - val_acc: 0.8901\n",
            "Epoch 233/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.5218 - acc: 0.7931 - val_loss: 0.3318 - val_acc: 0.8865\n",
            "Epoch 234/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.5289 - acc: 0.7954 - val_loss: 0.3705 - val_acc: 0.8741\n",
            "Epoch 235/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.5145 - acc: 0.7995 - val_loss: 0.3660 - val_acc: 0.8794\n",
            "Epoch 236/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.5124 - acc: 0.7996 - val_loss: 0.3495 - val_acc: 0.8753\n",
            "Epoch 237/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.5186 - acc: 0.7985 - val_loss: 0.3216 - val_acc: 0.8889\n",
            "Epoch 238/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.5220 - acc: 0.7986 - val_loss: 0.3438 - val_acc: 0.8812\n",
            "Epoch 239/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.5217 - acc: 0.7960 - val_loss: 0.3508 - val_acc: 0.8712\n",
            "Epoch 240/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.5198 - acc: 0.8025 - val_loss: 0.3513 - val_acc: 0.8741\n",
            "Epoch 241/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.5183 - acc: 0.8002 - val_loss: 0.3242 - val_acc: 0.8978\n",
            "Epoch 242/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.5163 - acc: 0.8008 - val_loss: 0.3223 - val_acc: 0.8942\n",
            "Epoch 243/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.5296 - acc: 0.7933 - val_loss: 0.3631 - val_acc: 0.8682\n",
            "Epoch 244/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.5113 - acc: 0.7979 - val_loss: 0.3282 - val_acc: 0.8830\n",
            "Epoch 245/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.5143 - acc: 0.7973 - val_loss: 0.3373 - val_acc: 0.8800\n",
            "Epoch 246/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.5147 - acc: 0.7999 - val_loss: 0.3122 - val_acc: 0.8930\n",
            "Epoch 247/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.5160 - acc: 0.7954 - val_loss: 0.3196 - val_acc: 0.8960\n",
            "Epoch 248/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.5073 - acc: 0.8016 - val_loss: 0.3230 - val_acc: 0.8918\n",
            "Epoch 249/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.5114 - acc: 0.8079 - val_loss: 0.3121 - val_acc: 0.8972\n",
            "Epoch 250/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.5242 - acc: 0.7967 - val_loss: 0.3202 - val_acc: 0.8924\n",
            "Epoch 251/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.5152 - acc: 0.8002 - val_loss: 0.3412 - val_acc: 0.8741\n",
            "Epoch 252/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.5071 - acc: 0.8041 - val_loss: 0.3107 - val_acc: 0.9031\n",
            "Epoch 253/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.5074 - acc: 0.7983 - val_loss: 0.3383 - val_acc: 0.8788\n",
            "Epoch 254/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.5179 - acc: 0.7957 - val_loss: 0.3400 - val_acc: 0.8794\n",
            "Epoch 255/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.5174 - acc: 0.8007 - val_loss: 0.3273 - val_acc: 0.8842\n",
            "Epoch 256/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4978 - acc: 0.8061 - val_loss: 0.3136 - val_acc: 0.9001\n",
            "Epoch 257/1000\n",
            "106/106 [==============================] - 3s 32ms/step - loss: 0.5092 - acc: 0.7979 - val_loss: 0.3326 - val_acc: 0.8883\n",
            "Epoch 258/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.5192 - acc: 0.7960 - val_loss: 0.3106 - val_acc: 0.8954\n",
            "Epoch 259/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4995 - acc: 0.8100 - val_loss: 0.3046 - val_acc: 0.8966\n",
            "Epoch 260/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4995 - acc: 0.8095 - val_loss: 0.3123 - val_acc: 0.8901\n",
            "Epoch 261/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.5169 - acc: 0.8007 - val_loss: 0.3106 - val_acc: 0.8895\n",
            "Epoch 262/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4964 - acc: 0.8059 - val_loss: 0.3158 - val_acc: 0.8942\n",
            "Epoch 263/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.5155 - acc: 0.8016 - val_loss: 0.3170 - val_acc: 0.8966\n",
            "Epoch 264/1000\n",
            "106/106 [==============================] - 3s 32ms/step - loss: 0.5096 - acc: 0.8020 - val_loss: 0.2935 - val_acc: 0.8978\n",
            "Epoch 265/1000\n",
            "106/106 [==============================] - 3s 32ms/step - loss: 0.5010 - acc: 0.8041 - val_loss: 0.3253 - val_acc: 0.8788\n",
            "Epoch 266/1000\n",
            "106/106 [==============================] - 3s 32ms/step - loss: 0.4952 - acc: 0.8045 - val_loss: 0.3025 - val_acc: 0.9007\n",
            "Epoch 267/1000\n",
            "106/106 [==============================] - 3s 32ms/step - loss: 0.4978 - acc: 0.8097 - val_loss: 0.3248 - val_acc: 0.8812\n",
            "Epoch 268/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4995 - acc: 0.8053 - val_loss: 0.3100 - val_acc: 0.8865\n",
            "Epoch 269/1000\n",
            "106/106 [==============================] - 3s 32ms/step - loss: 0.4970 - acc: 0.8072 - val_loss: 0.3043 - val_acc: 0.8989\n",
            "Epoch 270/1000\n",
            "106/106 [==============================] - 3s 32ms/step - loss: 0.5173 - acc: 0.7996 - val_loss: 0.3084 - val_acc: 0.8948\n",
            "Epoch 271/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.5154 - acc: 0.8014 - val_loss: 0.3128 - val_acc: 0.8960\n",
            "Epoch 272/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4991 - acc: 0.8041 - val_loss: 0.3240 - val_acc: 0.8883\n",
            "Epoch 273/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4921 - acc: 0.8059 - val_loss: 0.3243 - val_acc: 0.8865\n",
            "Epoch 274/1000\n",
            "106/106 [==============================] - 3s 32ms/step - loss: 0.5074 - acc: 0.7992 - val_loss: 0.3184 - val_acc: 0.8918\n",
            "Epoch 275/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4924 - acc: 0.8064 - val_loss: 0.3009 - val_acc: 0.8936\n",
            "Epoch 276/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4869 - acc: 0.8104 - val_loss: 0.3243 - val_acc: 0.8818\n",
            "Epoch 277/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4841 - acc: 0.8162 - val_loss: 0.3149 - val_acc: 0.8972\n",
            "Epoch 278/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4993 - acc: 0.8067 - val_loss: 0.3347 - val_acc: 0.8783\n",
            "Epoch 279/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4863 - acc: 0.8067 - val_loss: 0.2988 - val_acc: 0.9025\n",
            "Epoch 280/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4948 - acc: 0.8088 - val_loss: 0.3014 - val_acc: 0.8978\n",
            "Epoch 281/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4942 - acc: 0.8073 - val_loss: 0.2944 - val_acc: 0.8966\n",
            "Epoch 282/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4786 - acc: 0.8125 - val_loss: 0.3275 - val_acc: 0.8848\n",
            "Epoch 283/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4944 - acc: 0.8078 - val_loss: 0.3150 - val_acc: 0.8954\n",
            "Epoch 284/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4928 - acc: 0.8118 - val_loss: 0.3091 - val_acc: 0.8948\n",
            "Epoch 285/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4814 - acc: 0.8169 - val_loss: 0.3168 - val_acc: 0.8948\n",
            "Epoch 286/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4914 - acc: 0.8138 - val_loss: 0.2987 - val_acc: 0.9108\n",
            "Epoch 287/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4824 - acc: 0.8138 - val_loss: 0.2941 - val_acc: 0.9025\n",
            "Epoch 288/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.4945 - acc: 0.8045 - val_loss: 0.2994 - val_acc: 0.9019\n",
            "Epoch 289/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.4806 - acc: 0.8144 - val_loss: 0.3108 - val_acc: 0.8913\n",
            "Epoch 290/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4896 - acc: 0.8112 - val_loss: 0.3359 - val_acc: 0.8777\n",
            "Epoch 291/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4934 - acc: 0.8119 - val_loss: 0.2763 - val_acc: 0.9131\n",
            "Epoch 292/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4786 - acc: 0.8150 - val_loss: 0.2956 - val_acc: 0.9043\n",
            "Epoch 293/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.4725 - acc: 0.8194 - val_loss: 0.2865 - val_acc: 0.9001\n",
            "Epoch 294/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.4837 - acc: 0.8110 - val_loss: 0.2970 - val_acc: 0.8966\n",
            "Epoch 295/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4859 - acc: 0.8162 - val_loss: 0.3177 - val_acc: 0.8918\n",
            "Epoch 296/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4804 - acc: 0.8186 - val_loss: 0.2939 - val_acc: 0.9031\n",
            "Epoch 297/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4829 - acc: 0.8180 - val_loss: 0.3186 - val_acc: 0.8812\n",
            "Epoch 298/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4862 - acc: 0.8110 - val_loss: 0.3056 - val_acc: 0.8966\n",
            "Epoch 299/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4832 - acc: 0.8115 - val_loss: 0.2805 - val_acc: 0.9043\n",
            "Epoch 300/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.5056 - acc: 0.8030 - val_loss: 0.3179 - val_acc: 0.8895\n",
            "Epoch 301/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4817 - acc: 0.8121 - val_loss: 0.2801 - val_acc: 0.9131\n",
            "Epoch 302/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4881 - acc: 0.8090 - val_loss: 0.2758 - val_acc: 0.9054\n",
            "Epoch 303/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.4843 - acc: 0.8119 - val_loss: 0.2745 - val_acc: 0.9084\n",
            "Epoch 304/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4892 - acc: 0.8121 - val_loss: 0.2991 - val_acc: 0.8972\n",
            "Epoch 305/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4805 - acc: 0.8125 - val_loss: 0.3074 - val_acc: 0.8936\n",
            "Epoch 306/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4772 - acc: 0.8153 - val_loss: 0.2976 - val_acc: 0.8983\n",
            "Epoch 307/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.4890 - acc: 0.8110 - val_loss: 0.3042 - val_acc: 0.9037\n",
            "Epoch 308/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4776 - acc: 0.8211 - val_loss: 0.2845 - val_acc: 0.9072\n",
            "Epoch 309/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4753 - acc: 0.8158 - val_loss: 0.3054 - val_acc: 0.8895\n",
            "Epoch 310/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4658 - acc: 0.8200 - val_loss: 0.3074 - val_acc: 0.8913\n",
            "Epoch 311/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.4692 - acc: 0.8160 - val_loss: 0.2767 - val_acc: 0.9108\n",
            "Epoch 312/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.4913 - acc: 0.8113 - val_loss: 0.2970 - val_acc: 0.8966\n",
            "Epoch 313/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.4739 - acc: 0.8174 - val_loss: 0.3109 - val_acc: 0.8812\n",
            "Epoch 314/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.4773 - acc: 0.8180 - val_loss: 0.3049 - val_acc: 0.8948\n",
            "Epoch 315/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.4809 - acc: 0.8113 - val_loss: 0.2870 - val_acc: 0.9013\n",
            "Epoch 316/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4729 - acc: 0.8199 - val_loss: 0.2979 - val_acc: 0.9025\n",
            "Epoch 317/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4550 - acc: 0.8265 - val_loss: 0.2942 - val_acc: 0.8983\n",
            "Epoch 318/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4669 - acc: 0.8177 - val_loss: 0.2849 - val_acc: 0.9048\n",
            "Epoch 319/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.4705 - acc: 0.8187 - val_loss: 0.2808 - val_acc: 0.9007\n",
            "Epoch 320/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.4739 - acc: 0.8160 - val_loss: 0.3000 - val_acc: 0.8942\n",
            "Epoch 321/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4652 - acc: 0.8194 - val_loss: 0.2942 - val_acc: 0.8972\n",
            "Epoch 322/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.4708 - acc: 0.8184 - val_loss: 0.2634 - val_acc: 0.9090\n",
            "Epoch 323/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.4693 - acc: 0.8160 - val_loss: 0.2757 - val_acc: 0.9078\n",
            "Epoch 324/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4835 - acc: 0.8132 - val_loss: 0.2780 - val_acc: 0.9054\n",
            "Epoch 325/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4746 - acc: 0.8174 - val_loss: 0.2758 - val_acc: 0.9084\n",
            "Epoch 326/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4790 - acc: 0.8175 - val_loss: 0.2761 - val_acc: 0.9060\n",
            "Epoch 327/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4676 - acc: 0.8160 - val_loss: 0.2756 - val_acc: 0.9090\n",
            "Epoch 328/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4626 - acc: 0.8214 - val_loss: 0.2753 - val_acc: 0.9048\n",
            "Epoch 329/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4871 - acc: 0.8101 - val_loss: 0.2658 - val_acc: 0.9102\n",
            "Epoch 330/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4700 - acc: 0.8189 - val_loss: 0.2791 - val_acc: 0.9072\n",
            "Epoch 331/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4795 - acc: 0.8146 - val_loss: 0.2721 - val_acc: 0.9102\n",
            "Epoch 332/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4640 - acc: 0.8221 - val_loss: 0.2882 - val_acc: 0.9019\n",
            "Epoch 333/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.4634 - acc: 0.8227 - val_loss: 0.2781 - val_acc: 0.9019\n",
            "Epoch 334/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4667 - acc: 0.8205 - val_loss: 0.2622 - val_acc: 0.9125\n",
            "Epoch 335/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4652 - acc: 0.8223 - val_loss: 0.2554 - val_acc: 0.9178\n",
            "Epoch 336/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4684 - acc: 0.8217 - val_loss: 0.2882 - val_acc: 0.8983\n",
            "Epoch 337/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4526 - acc: 0.8267 - val_loss: 0.2635 - val_acc: 0.9190\n",
            "Epoch 338/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4705 - acc: 0.8206 - val_loss: 0.2993 - val_acc: 0.8924\n",
            "Epoch 339/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4720 - acc: 0.8200 - val_loss: 0.2784 - val_acc: 0.8924\n",
            "Epoch 340/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4626 - acc: 0.8217 - val_loss: 0.2763 - val_acc: 0.9084\n",
            "Epoch 341/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4644 - acc: 0.8217 - val_loss: 0.2780 - val_acc: 0.8978\n",
            "Epoch 342/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4624 - acc: 0.8243 - val_loss: 0.2683 - val_acc: 0.9048\n",
            "Epoch 343/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4664 - acc: 0.8197 - val_loss: 0.2640 - val_acc: 0.9149\n",
            "Epoch 344/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4610 - acc: 0.8197 - val_loss: 0.2533 - val_acc: 0.9196\n",
            "Epoch 345/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4480 - acc: 0.8245 - val_loss: 0.2542 - val_acc: 0.9208\n",
            "Epoch 346/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4516 - acc: 0.8262 - val_loss: 0.2827 - val_acc: 0.9043\n",
            "Epoch 347/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4551 - acc: 0.8202 - val_loss: 0.2983 - val_acc: 0.8954\n",
            "Epoch 348/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4626 - acc: 0.8245 - val_loss: 0.2845 - val_acc: 0.9037\n",
            "Epoch 349/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4451 - acc: 0.8311 - val_loss: 0.2645 - val_acc: 0.9137\n",
            "Epoch 350/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4510 - acc: 0.8237 - val_loss: 0.2874 - val_acc: 0.9013\n",
            "Epoch 351/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4805 - acc: 0.8168 - val_loss: 0.2711 - val_acc: 0.9084\n",
            "Epoch 352/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4476 - acc: 0.8271 - val_loss: 0.2663 - val_acc: 0.9048\n",
            "Epoch 353/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4595 - acc: 0.8264 - val_loss: 0.2631 - val_acc: 0.9125\n",
            "Epoch 354/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4717 - acc: 0.8132 - val_loss: 0.2708 - val_acc: 0.9178\n",
            "Epoch 355/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4398 - acc: 0.8351 - val_loss: 0.2586 - val_acc: 0.9096\n",
            "Epoch 356/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4729 - acc: 0.8162 - val_loss: 0.2649 - val_acc: 0.9102\n",
            "Epoch 357/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4528 - acc: 0.8230 - val_loss: 0.2628 - val_acc: 0.9119\n",
            "Epoch 358/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.4687 - acc: 0.8233 - val_loss: 0.2630 - val_acc: 0.9108\n",
            "Epoch 359/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4542 - acc: 0.8233 - val_loss: 0.2751 - val_acc: 0.9031\n",
            "Epoch 360/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4576 - acc: 0.8258 - val_loss: 0.2656 - val_acc: 0.9119\n",
            "Epoch 361/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4605 - acc: 0.8255 - val_loss: 0.2481 - val_acc: 0.9184\n",
            "Epoch 362/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4666 - acc: 0.8227 - val_loss: 0.2499 - val_acc: 0.9066\n",
            "Epoch 363/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4461 - acc: 0.8271 - val_loss: 0.2581 - val_acc: 0.9131\n",
            "Epoch 364/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4621 - acc: 0.8208 - val_loss: 0.2520 - val_acc: 0.9125\n",
            "Epoch 365/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4527 - acc: 0.8295 - val_loss: 0.2503 - val_acc: 0.9161\n",
            "Epoch 366/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4421 - acc: 0.8302 - val_loss: 0.2909 - val_acc: 0.8978\n",
            "Epoch 367/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4558 - acc: 0.8243 - val_loss: 0.2622 - val_acc: 0.9155\n",
            "Epoch 368/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4596 - acc: 0.8215 - val_loss: 0.2680 - val_acc: 0.9113\n",
            "Epoch 369/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.4640 - acc: 0.8190 - val_loss: 0.2579 - val_acc: 0.9066\n",
            "Epoch 370/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4708 - acc: 0.8230 - val_loss: 0.2578 - val_acc: 0.9137\n",
            "Epoch 371/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4515 - acc: 0.8248 - val_loss: 0.2507 - val_acc: 0.9178\n",
            "Epoch 372/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4531 - acc: 0.8261 - val_loss: 0.2505 - val_acc: 0.9149\n",
            "Epoch 373/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4622 - acc: 0.8189 - val_loss: 0.2685 - val_acc: 0.9054\n",
            "Epoch 374/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4672 - acc: 0.8227 - val_loss: 0.2669 - val_acc: 0.9137\n",
            "Epoch 375/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4596 - acc: 0.8293 - val_loss: 0.2573 - val_acc: 0.9137\n",
            "Epoch 376/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4456 - acc: 0.8280 - val_loss: 0.2625 - val_acc: 0.9096\n",
            "Epoch 377/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.4505 - acc: 0.8310 - val_loss: 0.2730 - val_acc: 0.9019\n",
            "Epoch 378/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.4210 - acc: 0.8463 - val_loss: 0.2527 - val_acc: 0.9167\n",
            "Epoch 379/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.4496 - acc: 0.8292 - val_loss: 0.2526 - val_acc: 0.9178\n",
            "Epoch 380/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.4420 - acc: 0.8324 - val_loss: 0.2610 - val_acc: 0.9078\n",
            "Epoch 381/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.4491 - acc: 0.8283 - val_loss: 0.2439 - val_acc: 0.9196\n",
            "Epoch 382/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.4402 - acc: 0.8296 - val_loss: 0.2498 - val_acc: 0.9214\n",
            "Epoch 383/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4592 - acc: 0.8276 - val_loss: 0.2533 - val_acc: 0.9137\n",
            "Epoch 384/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.4527 - acc: 0.8248 - val_loss: 0.2667 - val_acc: 0.9149\n",
            "Epoch 385/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.4382 - acc: 0.8369 - val_loss: 0.2833 - val_acc: 0.8954\n",
            "Epoch 386/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.4474 - acc: 0.8357 - val_loss: 0.2512 - val_acc: 0.9190\n",
            "Epoch 387/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.4554 - acc: 0.8242 - val_loss: 0.2447 - val_acc: 0.9167\n",
            "Epoch 388/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.4538 - acc: 0.8258 - val_loss: 0.2445 - val_acc: 0.9184\n",
            "Epoch 389/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.4443 - acc: 0.8319 - val_loss: 0.2608 - val_acc: 0.9119\n",
            "Epoch 390/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.4690 - acc: 0.8220 - val_loss: 0.2670 - val_acc: 0.9125\n",
            "Epoch 391/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.4481 - acc: 0.8292 - val_loss: 0.2486 - val_acc: 0.9119\n",
            "Epoch 392/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.4521 - acc: 0.8299 - val_loss: 0.2414 - val_acc: 0.9255\n",
            "Epoch 393/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.4331 - acc: 0.8394 - val_loss: 0.2464 - val_acc: 0.9196\n",
            "Epoch 394/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.4643 - acc: 0.8252 - val_loss: 0.2530 - val_acc: 0.9167\n",
            "Epoch 395/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4484 - acc: 0.8288 - val_loss: 0.2388 - val_acc: 0.9167\n",
            "Epoch 396/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4593 - acc: 0.8184 - val_loss: 0.2604 - val_acc: 0.9102\n",
            "Epoch 397/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4429 - acc: 0.8317 - val_loss: 0.2392 - val_acc: 0.9226\n",
            "Epoch 398/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4403 - acc: 0.8314 - val_loss: 0.2433 - val_acc: 0.9184\n",
            "Epoch 399/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.4485 - acc: 0.8298 - val_loss: 0.2581 - val_acc: 0.9143\n",
            "Epoch 400/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4375 - acc: 0.8311 - val_loss: 0.2432 - val_acc: 0.9184\n",
            "Epoch 401/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4244 - acc: 0.8381 - val_loss: 0.2643 - val_acc: 0.9025\n",
            "Epoch 402/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4499 - acc: 0.8289 - val_loss: 0.2611 - val_acc: 0.9019\n",
            "Epoch 403/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4417 - acc: 0.8323 - val_loss: 0.2355 - val_acc: 0.9214\n",
            "Epoch 404/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4433 - acc: 0.8257 - val_loss: 0.2669 - val_acc: 0.9155\n",
            "Epoch 405/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4393 - acc: 0.8264 - val_loss: 0.2303 - val_acc: 0.9255\n",
            "Epoch 406/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4326 - acc: 0.8355 - val_loss: 0.2450 - val_acc: 0.9202\n",
            "Epoch 407/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4365 - acc: 0.8354 - val_loss: 0.2339 - val_acc: 0.9178\n",
            "Epoch 408/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4316 - acc: 0.8381 - val_loss: 0.2337 - val_acc: 0.9238\n",
            "Epoch 409/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.4346 - acc: 0.8348 - val_loss: 0.2521 - val_acc: 0.9208\n",
            "Epoch 410/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.4464 - acc: 0.8327 - val_loss: 0.2509 - val_acc: 0.9178\n",
            "Epoch 411/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4302 - acc: 0.8341 - val_loss: 0.2379 - val_acc: 0.9202\n",
            "Epoch 412/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4323 - acc: 0.8342 - val_loss: 0.2513 - val_acc: 0.9113\n",
            "Epoch 413/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4504 - acc: 0.8236 - val_loss: 0.2344 - val_acc: 0.9226\n",
            "Epoch 414/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4466 - acc: 0.8270 - val_loss: 0.2363 - val_acc: 0.9238\n",
            "Epoch 415/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.4413 - acc: 0.8295 - val_loss: 0.2473 - val_acc: 0.9155\n",
            "Epoch 416/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4231 - acc: 0.8335 - val_loss: 0.2438 - val_acc: 0.9167\n",
            "Epoch 417/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4352 - acc: 0.8354 - val_loss: 0.2479 - val_acc: 0.9161\n",
            "Epoch 418/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4445 - acc: 0.8305 - val_loss: 0.2375 - val_acc: 0.9208\n",
            "Epoch 419/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4218 - acc: 0.8385 - val_loss: 0.2337 - val_acc: 0.9208\n",
            "Epoch 420/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4255 - acc: 0.8376 - val_loss: 0.2333 - val_acc: 0.9196\n",
            "Epoch 421/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4350 - acc: 0.8376 - val_loss: 0.2427 - val_acc: 0.9196\n",
            "Epoch 422/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4202 - acc: 0.8381 - val_loss: 0.2582 - val_acc: 0.9102\n",
            "Epoch 423/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4497 - acc: 0.8299 - val_loss: 0.2298 - val_acc: 0.9243\n",
            "Epoch 424/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4340 - acc: 0.8302 - val_loss: 0.2346 - val_acc: 0.9149\n",
            "Epoch 425/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4326 - acc: 0.8378 - val_loss: 0.2347 - val_acc: 0.9220\n",
            "Epoch 426/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.4361 - acc: 0.8308 - val_loss: 0.2395 - val_acc: 0.9214\n",
            "Epoch 427/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4351 - acc: 0.8330 - val_loss: 0.2548 - val_acc: 0.9054\n",
            "Epoch 428/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4394 - acc: 0.8339 - val_loss: 0.2548 - val_acc: 0.9167\n",
            "Epoch 429/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4368 - acc: 0.8363 - val_loss: 0.2293 - val_acc: 0.9214\n",
            "Epoch 430/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4229 - acc: 0.8410 - val_loss: 0.2222 - val_acc: 0.9249\n",
            "Epoch 431/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4226 - acc: 0.8395 - val_loss: 0.2542 - val_acc: 0.9066\n",
            "Epoch 432/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4515 - acc: 0.8277 - val_loss: 0.2303 - val_acc: 0.9249\n",
            "Epoch 433/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.4260 - acc: 0.8354 - val_loss: 0.2476 - val_acc: 0.9143\n",
            "Epoch 434/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.4411 - acc: 0.8341 - val_loss: 0.2504 - val_acc: 0.9161\n",
            "Epoch 435/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4240 - acc: 0.8416 - val_loss: 0.2495 - val_acc: 0.9137\n",
            "Epoch 436/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4310 - acc: 0.8350 - val_loss: 0.2308 - val_acc: 0.9226\n",
            "Epoch 437/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.4221 - acc: 0.8385 - val_loss: 0.2357 - val_acc: 0.9173\n",
            "Epoch 438/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4409 - acc: 0.8301 - val_loss: 0.2263 - val_acc: 0.9214\n",
            "Epoch 439/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4335 - acc: 0.8360 - val_loss: 0.2283 - val_acc: 0.9238\n",
            "Epoch 440/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4286 - acc: 0.8364 - val_loss: 0.2502 - val_acc: 0.9113\n",
            "Epoch 441/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4318 - acc: 0.8327 - val_loss: 0.2470 - val_acc: 0.9167\n",
            "Epoch 442/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4263 - acc: 0.8416 - val_loss: 0.2269 - val_acc: 0.9226\n",
            "Epoch 443/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4396 - acc: 0.8355 - val_loss: 0.2339 - val_acc: 0.9161\n",
            "Epoch 444/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4239 - acc: 0.8403 - val_loss: 0.2503 - val_acc: 0.9131\n",
            "Epoch 445/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4261 - acc: 0.8406 - val_loss: 0.2378 - val_acc: 0.9267\n",
            "Epoch 446/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4300 - acc: 0.8363 - val_loss: 0.2353 - val_acc: 0.9143\n",
            "Epoch 447/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4515 - acc: 0.8280 - val_loss: 0.2527 - val_acc: 0.9161\n",
            "Epoch 448/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.4087 - acc: 0.8410 - val_loss: 0.2399 - val_acc: 0.9190\n",
            "Epoch 449/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.4076 - acc: 0.8446 - val_loss: 0.2337 - val_acc: 0.9143\n",
            "Epoch 450/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4297 - acc: 0.8355 - val_loss: 0.2381 - val_acc: 0.9173\n",
            "Epoch 451/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4107 - acc: 0.8438 - val_loss: 0.2450 - val_acc: 0.9220\n",
            "Epoch 452/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4305 - acc: 0.8361 - val_loss: 0.2256 - val_acc: 0.9220\n",
            "Epoch 453/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4297 - acc: 0.8401 - val_loss: 0.2279 - val_acc: 0.9232\n",
            "Epoch 454/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.4154 - acc: 0.8426 - val_loss: 0.2415 - val_acc: 0.9238\n",
            "Epoch 455/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4232 - acc: 0.8400 - val_loss: 0.2304 - val_acc: 0.9255\n",
            "Epoch 456/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4287 - acc: 0.8366 - val_loss: 0.2526 - val_acc: 0.9137\n",
            "Epoch 457/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4244 - acc: 0.8391 - val_loss: 0.2436 - val_acc: 0.9137\n",
            "Epoch 458/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.4185 - acc: 0.8358 - val_loss: 0.2357 - val_acc: 0.9184\n",
            "Epoch 459/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4253 - acc: 0.8397 - val_loss: 0.2361 - val_acc: 0.9108\n",
            "Epoch 460/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4159 - acc: 0.8372 - val_loss: 0.2549 - val_acc: 0.9084\n",
            "Epoch 461/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4299 - acc: 0.8381 - val_loss: 0.2243 - val_acc: 0.9303\n",
            "Epoch 462/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4296 - acc: 0.8355 - val_loss: 0.2249 - val_acc: 0.9184\n",
            "Epoch 463/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4225 - acc: 0.8400 - val_loss: 0.2249 - val_acc: 0.9226\n",
            "Epoch 464/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4273 - acc: 0.8375 - val_loss: 0.2381 - val_acc: 0.9214\n",
            "Epoch 465/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4032 - acc: 0.8487 - val_loss: 0.2273 - val_acc: 0.9208\n",
            "Epoch 466/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4173 - acc: 0.8407 - val_loss: 0.2309 - val_acc: 0.9178\n",
            "Epoch 467/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4151 - acc: 0.8450 - val_loss: 0.2196 - val_acc: 0.9297\n",
            "Epoch 468/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4250 - acc: 0.8389 - val_loss: 0.2251 - val_acc: 0.9238\n",
            "Epoch 469/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.4076 - acc: 0.8477 - val_loss: 0.2369 - val_acc: 0.9190\n",
            "Epoch 470/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4212 - acc: 0.8404 - val_loss: 0.2306 - val_acc: 0.9243\n",
            "Epoch 471/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4172 - acc: 0.8409 - val_loss: 0.2336 - val_acc: 0.9184\n",
            "Epoch 472/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4269 - acc: 0.8395 - val_loss: 0.2354 - val_acc: 0.9184\n",
            "Epoch 473/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4233 - acc: 0.8428 - val_loss: 0.2232 - val_acc: 0.9202\n",
            "Epoch 474/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4262 - acc: 0.8360 - val_loss: 0.2114 - val_acc: 0.9279\n",
            "Epoch 475/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4200 - acc: 0.8412 - val_loss: 0.2221 - val_acc: 0.9267\n",
            "Epoch 476/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4056 - acc: 0.8440 - val_loss: 0.2470 - val_acc: 0.9131\n",
            "Epoch 477/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4199 - acc: 0.8358 - val_loss: 0.2452 - val_acc: 0.9131\n",
            "Epoch 478/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3990 - acc: 0.8497 - val_loss: 0.2216 - val_acc: 0.9309\n",
            "Epoch 479/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4258 - acc: 0.8413 - val_loss: 0.2052 - val_acc: 0.9385\n",
            "Epoch 480/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4073 - acc: 0.8478 - val_loss: 0.2158 - val_acc: 0.9297\n",
            "Epoch 481/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4228 - acc: 0.8375 - val_loss: 0.2380 - val_acc: 0.9119\n",
            "Epoch 482/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4102 - acc: 0.8460 - val_loss: 0.2242 - val_acc: 0.9285\n",
            "Epoch 483/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.4008 - acc: 0.8528 - val_loss: 0.2127 - val_acc: 0.9350\n",
            "Epoch 484/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4159 - acc: 0.8407 - val_loss: 0.2089 - val_acc: 0.9291\n",
            "Epoch 485/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4180 - acc: 0.8404 - val_loss: 0.2374 - val_acc: 0.9178\n",
            "Epoch 486/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4171 - acc: 0.8382 - val_loss: 0.2388 - val_acc: 0.9255\n",
            "Epoch 487/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.4245 - acc: 0.8398 - val_loss: 0.2242 - val_acc: 0.9249\n",
            "Epoch 488/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4175 - acc: 0.8389 - val_loss: 0.2123 - val_acc: 0.9350\n",
            "Epoch 489/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4155 - acc: 0.8468 - val_loss: 0.2485 - val_acc: 0.9143\n",
            "Epoch 490/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4227 - acc: 0.8406 - val_loss: 0.2171 - val_acc: 0.9303\n",
            "Epoch 491/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3973 - acc: 0.8524 - val_loss: 0.2207 - val_acc: 0.9279\n",
            "Epoch 492/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4286 - acc: 0.8415 - val_loss: 0.2330 - val_acc: 0.9238\n",
            "Epoch 493/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3965 - acc: 0.8483 - val_loss: 0.2087 - val_acc: 0.9314\n",
            "Epoch 494/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3964 - acc: 0.8469 - val_loss: 0.2158 - val_acc: 0.9273\n",
            "Epoch 495/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4113 - acc: 0.8422 - val_loss: 0.2319 - val_acc: 0.9202\n",
            "Epoch 496/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4159 - acc: 0.8429 - val_loss: 0.2096 - val_acc: 0.9291\n",
            "Epoch 497/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4226 - acc: 0.8426 - val_loss: 0.2109 - val_acc: 0.9368\n",
            "Epoch 498/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4041 - acc: 0.8496 - val_loss: 0.2146 - val_acc: 0.9249\n",
            "Epoch 499/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4118 - acc: 0.8421 - val_loss: 0.2163 - val_acc: 0.9279\n",
            "Epoch 500/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4125 - acc: 0.8388 - val_loss: 0.2261 - val_acc: 0.9279\n",
            "Epoch 501/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4017 - acc: 0.8438 - val_loss: 0.2092 - val_acc: 0.9291\n",
            "Epoch 502/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.4102 - acc: 0.8428 - val_loss: 0.2019 - val_acc: 0.9356\n",
            "Epoch 503/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4151 - acc: 0.8493 - val_loss: 0.2120 - val_acc: 0.9356\n",
            "Epoch 504/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4007 - acc: 0.8481 - val_loss: 0.2044 - val_acc: 0.9338\n",
            "Epoch 505/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4060 - acc: 0.8449 - val_loss: 0.2242 - val_acc: 0.9249\n",
            "Epoch 506/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4049 - acc: 0.8463 - val_loss: 0.2077 - val_acc: 0.9285\n",
            "Epoch 507/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4147 - acc: 0.8443 - val_loss: 0.2064 - val_acc: 0.9344\n",
            "Epoch 508/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4096 - acc: 0.8421 - val_loss: 0.2175 - val_acc: 0.9297\n",
            "Epoch 509/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4121 - acc: 0.8443 - val_loss: 0.2242 - val_acc: 0.9238\n",
            "Epoch 510/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4094 - acc: 0.8466 - val_loss: 0.2411 - val_acc: 0.9161\n",
            "Epoch 511/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4026 - acc: 0.8466 - val_loss: 0.2198 - val_acc: 0.9220\n",
            "Epoch 512/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3991 - acc: 0.8457 - val_loss: 0.1995 - val_acc: 0.9368\n",
            "Epoch 513/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4104 - acc: 0.8404 - val_loss: 0.2150 - val_acc: 0.9279\n",
            "Epoch 514/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.4197 - acc: 0.8441 - val_loss: 0.2306 - val_acc: 0.9167\n",
            "Epoch 515/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3904 - acc: 0.8524 - val_loss: 0.2009 - val_acc: 0.9332\n",
            "Epoch 516/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4035 - acc: 0.8486 - val_loss: 0.2163 - val_acc: 0.9214\n",
            "Epoch 517/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.4038 - acc: 0.8486 - val_loss: 0.2079 - val_acc: 0.9285\n",
            "Epoch 518/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.4011 - acc: 0.8490 - val_loss: 0.2076 - val_acc: 0.9238\n",
            "Epoch 519/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.4139 - acc: 0.8466 - val_loss: 0.2002 - val_acc: 0.9344\n",
            "Epoch 520/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3949 - acc: 0.8536 - val_loss: 0.2408 - val_acc: 0.9143\n",
            "Epoch 521/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4063 - acc: 0.8438 - val_loss: 0.2077 - val_acc: 0.9249\n",
            "Epoch 522/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4118 - acc: 0.8435 - val_loss: 0.2248 - val_acc: 0.9243\n",
            "Epoch 523/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4008 - acc: 0.8465 - val_loss: 0.2118 - val_acc: 0.9291\n",
            "Epoch 524/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3996 - acc: 0.8497 - val_loss: 0.2320 - val_acc: 0.9161\n",
            "Epoch 525/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4121 - acc: 0.8460 - val_loss: 0.2114 - val_acc: 0.9309\n",
            "Epoch 526/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3957 - acc: 0.8515 - val_loss: 0.2234 - val_acc: 0.9214\n",
            "Epoch 527/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4160 - acc: 0.8418 - val_loss: 0.2143 - val_acc: 0.9232\n",
            "Epoch 528/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3966 - acc: 0.8480 - val_loss: 0.2107 - val_acc: 0.9303\n",
            "Epoch 529/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4056 - acc: 0.8494 - val_loss: 0.2220 - val_acc: 0.9243\n",
            "Epoch 530/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4223 - acc: 0.8403 - val_loss: 0.2064 - val_acc: 0.9326\n",
            "Epoch 531/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3951 - acc: 0.8500 - val_loss: 0.2092 - val_acc: 0.9368\n",
            "Epoch 532/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.4090 - acc: 0.8465 - val_loss: 0.2121 - val_acc: 0.9326\n",
            "Epoch 533/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3869 - acc: 0.8549 - val_loss: 0.2338 - val_acc: 0.9190\n",
            "Epoch 534/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3954 - acc: 0.8475 - val_loss: 0.2071 - val_acc: 0.9332\n",
            "Epoch 535/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4043 - acc: 0.8450 - val_loss: 0.2010 - val_acc: 0.9326\n",
            "Epoch 536/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4051 - acc: 0.8477 - val_loss: 0.2137 - val_acc: 0.9255\n",
            "Epoch 537/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4155 - acc: 0.8437 - val_loss: 0.2277 - val_acc: 0.9190\n",
            "Epoch 538/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.4058 - acc: 0.8493 - val_loss: 0.2373 - val_acc: 0.9178\n",
            "Epoch 539/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4011 - acc: 0.8505 - val_loss: 0.2150 - val_acc: 0.9303\n",
            "Epoch 540/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3811 - acc: 0.8574 - val_loss: 0.2155 - val_acc: 0.9285\n",
            "Epoch 541/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3809 - acc: 0.8565 - val_loss: 0.2092 - val_acc: 0.9303\n",
            "Epoch 542/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3992 - acc: 0.8486 - val_loss: 0.1966 - val_acc: 0.9350\n",
            "Epoch 543/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3866 - acc: 0.8546 - val_loss: 0.2194 - val_acc: 0.9232\n",
            "Epoch 544/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4061 - acc: 0.8487 - val_loss: 0.2028 - val_acc: 0.9326\n",
            "Epoch 545/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4013 - acc: 0.8486 - val_loss: 0.2063 - val_acc: 0.9291\n",
            "Epoch 546/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3909 - acc: 0.8528 - val_loss: 0.1985 - val_acc: 0.9391\n",
            "Epoch 547/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4043 - acc: 0.8475 - val_loss: 0.2035 - val_acc: 0.9326\n",
            "Epoch 548/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4115 - acc: 0.8447 - val_loss: 0.2232 - val_acc: 0.9249\n",
            "Epoch 549/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3831 - acc: 0.8580 - val_loss: 0.2064 - val_acc: 0.9297\n",
            "Epoch 550/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4107 - acc: 0.8441 - val_loss: 0.2114 - val_acc: 0.9291\n",
            "Epoch 551/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.4023 - acc: 0.8459 - val_loss: 0.2047 - val_acc: 0.9320\n",
            "Epoch 552/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3935 - acc: 0.8511 - val_loss: 0.2006 - val_acc: 0.9391\n",
            "Epoch 553/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3995 - acc: 0.8466 - val_loss: 0.1996 - val_acc: 0.9291\n",
            "Epoch 554/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3874 - acc: 0.8517 - val_loss: 0.2060 - val_acc: 0.9309\n",
            "Epoch 555/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3911 - acc: 0.8520 - val_loss: 0.2029 - val_acc: 0.9374\n",
            "Epoch 556/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4034 - acc: 0.8462 - val_loss: 0.2115 - val_acc: 0.9279\n",
            "Epoch 557/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3886 - acc: 0.8548 - val_loss: 0.2051 - val_acc: 0.9303\n",
            "Epoch 558/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4133 - acc: 0.8432 - val_loss: 0.2046 - val_acc: 0.9403\n",
            "Epoch 559/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.4036 - acc: 0.8493 - val_loss: 0.2130 - val_acc: 0.9255\n",
            "Epoch 560/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3941 - acc: 0.8509 - val_loss: 0.2051 - val_acc: 0.9309\n",
            "Epoch 561/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4048 - acc: 0.8466 - val_loss: 0.1952 - val_acc: 0.9368\n",
            "Epoch 562/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3855 - acc: 0.8527 - val_loss: 0.2029 - val_acc: 0.9261\n",
            "Epoch 563/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4022 - acc: 0.8530 - val_loss: 0.2004 - val_acc: 0.9350\n",
            "Epoch 564/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3988 - acc: 0.8471 - val_loss: 0.2097 - val_acc: 0.9291\n",
            "Epoch 565/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3959 - acc: 0.8490 - val_loss: 0.1912 - val_acc: 0.9368\n",
            "Epoch 566/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4015 - acc: 0.8539 - val_loss: 0.2072 - val_acc: 0.9291\n",
            "Epoch 567/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3948 - acc: 0.8477 - val_loss: 0.2037 - val_acc: 0.9374\n",
            "Epoch 568/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3999 - acc: 0.8481 - val_loss: 0.2126 - val_acc: 0.9297\n",
            "Epoch 569/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3843 - acc: 0.8562 - val_loss: 0.2023 - val_acc: 0.9338\n",
            "Epoch 570/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4068 - acc: 0.8478 - val_loss: 0.2025 - val_acc: 0.9344\n",
            "Epoch 571/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3856 - acc: 0.8518 - val_loss: 0.2114 - val_acc: 0.9208\n",
            "Epoch 572/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4048 - acc: 0.8505 - val_loss: 0.1941 - val_acc: 0.9309\n",
            "Epoch 573/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3997 - acc: 0.8521 - val_loss: 0.2025 - val_acc: 0.9314\n",
            "Epoch 574/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3905 - acc: 0.8546 - val_loss: 0.2028 - val_acc: 0.9314\n",
            "Epoch 575/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.4024 - acc: 0.8528 - val_loss: 0.1967 - val_acc: 0.9332\n",
            "Epoch 576/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3895 - acc: 0.8543 - val_loss: 0.2087 - val_acc: 0.9309\n",
            "Epoch 577/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.4025 - acc: 0.8539 - val_loss: 0.2071 - val_acc: 0.9320\n",
            "Epoch 578/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3933 - acc: 0.8505 - val_loss: 0.1900 - val_acc: 0.9468\n",
            "Epoch 579/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4075 - acc: 0.8505 - val_loss: 0.2205 - val_acc: 0.9238\n",
            "Epoch 580/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3981 - acc: 0.8478 - val_loss: 0.2141 - val_acc: 0.9238\n",
            "Epoch 581/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3986 - acc: 0.8490 - val_loss: 0.1966 - val_acc: 0.9326\n",
            "Epoch 582/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3991 - acc: 0.8494 - val_loss: 0.2154 - val_acc: 0.9255\n",
            "Epoch 583/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3794 - acc: 0.8585 - val_loss: 0.2049 - val_acc: 0.9314\n",
            "Epoch 584/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3888 - acc: 0.8548 - val_loss: 0.2057 - val_acc: 0.9267\n",
            "Epoch 585/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3853 - acc: 0.8527 - val_loss: 0.2061 - val_acc: 0.9261\n",
            "Epoch 586/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3822 - acc: 0.8567 - val_loss: 0.1938 - val_acc: 0.9409\n",
            "Epoch 587/1000\n",
            "106/106 [==============================] - 3s 32ms/step - loss: 0.3938 - acc: 0.8531 - val_loss: 0.2101 - val_acc: 0.9303\n",
            "Epoch 588/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3920 - acc: 0.8484 - val_loss: 0.1999 - val_acc: 0.9356\n",
            "Epoch 589/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3882 - acc: 0.8527 - val_loss: 0.1971 - val_acc: 0.9344\n",
            "Epoch 590/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3913 - acc: 0.8517 - val_loss: 0.2038 - val_acc: 0.9309\n",
            "Epoch 591/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3788 - acc: 0.8551 - val_loss: 0.2120 - val_acc: 0.9255\n",
            "Epoch 592/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3888 - acc: 0.8568 - val_loss: 0.1997 - val_acc: 0.9267\n",
            "Epoch 593/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3837 - acc: 0.8549 - val_loss: 0.1990 - val_acc: 0.9320\n",
            "Epoch 594/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3939 - acc: 0.8512 - val_loss: 0.2257 - val_acc: 0.9167\n",
            "Epoch 595/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3919 - acc: 0.8549 - val_loss: 0.2088 - val_acc: 0.9297\n",
            "Epoch 596/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4208 - acc: 0.8392 - val_loss: 0.2151 - val_acc: 0.9273\n",
            "Epoch 597/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3797 - acc: 0.8605 - val_loss: 0.1919 - val_acc: 0.9314\n",
            "Epoch 598/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3852 - acc: 0.8546 - val_loss: 0.2116 - val_acc: 0.9320\n",
            "Epoch 599/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3799 - acc: 0.8604 - val_loss: 0.2264 - val_acc: 0.9173\n",
            "Epoch 600/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3943 - acc: 0.8556 - val_loss: 0.2114 - val_acc: 0.9267\n",
            "Epoch 601/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3888 - acc: 0.8543 - val_loss: 0.2108 - val_acc: 0.9249\n",
            "Epoch 602/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3876 - acc: 0.8521 - val_loss: 0.2019 - val_acc: 0.9350\n",
            "Epoch 603/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3825 - acc: 0.8520 - val_loss: 0.2245 - val_acc: 0.9149\n",
            "Epoch 604/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3938 - acc: 0.8475 - val_loss: 0.1993 - val_acc: 0.9267\n",
            "Epoch 605/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3870 - acc: 0.8565 - val_loss: 0.2068 - val_acc: 0.9267\n",
            "Epoch 606/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4098 - acc: 0.8435 - val_loss: 0.2069 - val_acc: 0.9291\n",
            "Epoch 607/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.4000 - acc: 0.8491 - val_loss: 0.2195 - val_acc: 0.9243\n",
            "Epoch 608/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3985 - acc: 0.8493 - val_loss: 0.2147 - val_acc: 0.9285\n",
            "Epoch 609/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4012 - acc: 0.8508 - val_loss: 0.1932 - val_acc: 0.9433\n",
            "Epoch 610/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3882 - acc: 0.8558 - val_loss: 0.2045 - val_acc: 0.9314\n",
            "Epoch 611/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3765 - acc: 0.8574 - val_loss: 0.2128 - val_acc: 0.9238\n",
            "Epoch 612/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.4029 - acc: 0.8459 - val_loss: 0.2141 - val_acc: 0.9243\n",
            "Epoch 613/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3874 - acc: 0.8593 - val_loss: 0.1978 - val_acc: 0.9344\n",
            "Epoch 614/1000\n",
            "106/106 [==============================] - 3s 32ms/step - loss: 0.3951 - acc: 0.8494 - val_loss: 0.2051 - val_acc: 0.9273\n",
            "Epoch 615/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3956 - acc: 0.8472 - val_loss: 0.1989 - val_acc: 0.9338\n",
            "Epoch 616/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3756 - acc: 0.8604 - val_loss: 0.1926 - val_acc: 0.9374\n",
            "Epoch 617/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3785 - acc: 0.8590 - val_loss: 0.1960 - val_acc: 0.9362\n",
            "Epoch 618/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3854 - acc: 0.8546 - val_loss: 0.1928 - val_acc: 0.9350\n",
            "Epoch 619/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3942 - acc: 0.8500 - val_loss: 0.1791 - val_acc: 0.9444\n",
            "Epoch 620/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3905 - acc: 0.8545 - val_loss: 0.2066 - val_acc: 0.9291\n",
            "Epoch 621/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3889 - acc: 0.8494 - val_loss: 0.2028 - val_acc: 0.9338\n",
            "Epoch 622/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3769 - acc: 0.8545 - val_loss: 0.2003 - val_acc: 0.9309\n",
            "Epoch 623/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3914 - acc: 0.8551 - val_loss: 0.2089 - val_acc: 0.9261\n",
            "Epoch 624/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3837 - acc: 0.8555 - val_loss: 0.1884 - val_acc: 0.9350\n",
            "Epoch 625/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3720 - acc: 0.8524 - val_loss: 0.1888 - val_acc: 0.9356\n",
            "Epoch 626/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3784 - acc: 0.8559 - val_loss: 0.1922 - val_acc: 0.9344\n",
            "Epoch 627/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3787 - acc: 0.8540 - val_loss: 0.1879 - val_acc: 0.9314\n",
            "Epoch 628/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3839 - acc: 0.8531 - val_loss: 0.1979 - val_acc: 0.9267\n",
            "Epoch 629/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.4055 - acc: 0.8460 - val_loss: 0.1970 - val_acc: 0.9368\n",
            "Epoch 630/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3828 - acc: 0.8562 - val_loss: 0.1958 - val_acc: 0.9314\n",
            "Epoch 631/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3700 - acc: 0.8576 - val_loss: 0.1860 - val_acc: 0.9368\n",
            "Epoch 632/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3846 - acc: 0.8545 - val_loss: 0.1860 - val_acc: 0.9350\n",
            "Epoch 633/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3853 - acc: 0.8558 - val_loss: 0.1886 - val_acc: 0.9338\n",
            "Epoch 634/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.4055 - acc: 0.8428 - val_loss: 0.2041 - val_acc: 0.9344\n",
            "Epoch 635/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3714 - acc: 0.8558 - val_loss: 0.2072 - val_acc: 0.9297\n",
            "Epoch 636/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3805 - acc: 0.8556 - val_loss: 0.1999 - val_acc: 0.9273\n",
            "Epoch 637/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3803 - acc: 0.8568 - val_loss: 0.1950 - val_acc: 0.9273\n",
            "Epoch 638/1000\n",
            "106/106 [==============================] - 3s 32ms/step - loss: 0.3594 - acc: 0.8645 - val_loss: 0.1864 - val_acc: 0.9421\n",
            "Epoch 639/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3768 - acc: 0.8536 - val_loss: 0.1897 - val_acc: 0.9379\n",
            "Epoch 640/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3962 - acc: 0.8502 - val_loss: 0.2180 - val_acc: 0.9249\n",
            "Epoch 641/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3793 - acc: 0.8589 - val_loss: 0.1842 - val_acc: 0.9409\n",
            "Epoch 642/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3880 - acc: 0.8531 - val_loss: 0.1868 - val_acc: 0.9421\n",
            "Epoch 643/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3931 - acc: 0.8512 - val_loss: 0.1884 - val_acc: 0.9362\n",
            "Epoch 644/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3847 - acc: 0.8521 - val_loss: 0.1777 - val_acc: 0.9486\n",
            "Epoch 645/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3704 - acc: 0.8661 - val_loss: 0.2107 - val_acc: 0.9249\n",
            "Epoch 646/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3771 - acc: 0.8521 - val_loss: 0.2086 - val_acc: 0.9338\n",
            "Epoch 647/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3780 - acc: 0.8568 - val_loss: 0.1976 - val_acc: 0.9338\n",
            "Epoch 648/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3832 - acc: 0.8562 - val_loss: 0.2074 - val_acc: 0.9255\n",
            "Epoch 649/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3871 - acc: 0.8545 - val_loss: 0.2036 - val_acc: 0.9320\n",
            "Epoch 650/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3905 - acc: 0.8540 - val_loss: 0.1842 - val_acc: 0.9421\n",
            "Epoch 651/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3745 - acc: 0.8598 - val_loss: 0.1941 - val_acc: 0.9261\n",
            "Epoch 652/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3746 - acc: 0.8613 - val_loss: 0.1853 - val_acc: 0.9385\n",
            "Epoch 653/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3786 - acc: 0.8558 - val_loss: 0.1955 - val_acc: 0.9338\n",
            "Epoch 654/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3784 - acc: 0.8596 - val_loss: 0.1876 - val_acc: 0.9427\n",
            "Epoch 655/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3919 - acc: 0.8521 - val_loss: 0.1972 - val_acc: 0.9314\n",
            "Epoch 656/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3979 - acc: 0.8497 - val_loss: 0.2009 - val_acc: 0.9320\n",
            "Epoch 657/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3799 - acc: 0.8559 - val_loss: 0.1937 - val_acc: 0.9350\n",
            "Epoch 658/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3591 - acc: 0.8633 - val_loss: 0.1832 - val_acc: 0.9397\n",
            "Epoch 659/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3758 - acc: 0.8568 - val_loss: 0.1994 - val_acc: 0.9320\n",
            "Epoch 660/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3768 - acc: 0.8595 - val_loss: 0.1933 - val_acc: 0.9350\n",
            "Epoch 661/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3754 - acc: 0.8543 - val_loss: 0.1818 - val_acc: 0.9379\n",
            "Epoch 662/1000\n",
            "106/106 [==============================] - 3s 32ms/step - loss: 0.3828 - acc: 0.8552 - val_loss: 0.1853 - val_acc: 0.9385\n",
            "Epoch 663/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3817 - acc: 0.8556 - val_loss: 0.2006 - val_acc: 0.9267\n",
            "Epoch 664/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3775 - acc: 0.8558 - val_loss: 0.1934 - val_acc: 0.9421\n",
            "Epoch 665/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3770 - acc: 0.8564 - val_loss: 0.1916 - val_acc: 0.9356\n",
            "Epoch 666/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3848 - acc: 0.8583 - val_loss: 0.2049 - val_acc: 0.9285\n",
            "Epoch 667/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3772 - acc: 0.8564 - val_loss: 0.1884 - val_acc: 0.9368\n",
            "Epoch 668/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3862 - acc: 0.8537 - val_loss: 0.1872 - val_acc: 0.9427\n",
            "Epoch 669/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3772 - acc: 0.8580 - val_loss: 0.2093 - val_acc: 0.9255\n",
            "Epoch 670/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3862 - acc: 0.8580 - val_loss: 0.2262 - val_acc: 0.9214\n",
            "Epoch 671/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3728 - acc: 0.8579 - val_loss: 0.1886 - val_acc: 0.9403\n",
            "Epoch 672/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3770 - acc: 0.8613 - val_loss: 0.1895 - val_acc: 0.9344\n",
            "Epoch 673/1000\n",
            "106/106 [==============================] - 3s 32ms/step - loss: 0.3639 - acc: 0.8645 - val_loss: 0.1859 - val_acc: 0.9415\n",
            "Epoch 674/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3683 - acc: 0.8616 - val_loss: 0.1897 - val_acc: 0.9356\n",
            "Epoch 675/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3911 - acc: 0.8548 - val_loss: 0.1890 - val_acc: 0.9356\n",
            "Epoch 676/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3639 - acc: 0.8686 - val_loss: 0.2037 - val_acc: 0.9344\n",
            "Epoch 677/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3733 - acc: 0.8570 - val_loss: 0.1745 - val_acc: 0.9427\n",
            "Epoch 678/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3589 - acc: 0.8667 - val_loss: 0.1924 - val_acc: 0.9350\n",
            "Epoch 679/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3803 - acc: 0.8582 - val_loss: 0.1851 - val_acc: 0.9409\n",
            "Epoch 680/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3603 - acc: 0.8608 - val_loss: 0.1885 - val_acc: 0.9397\n",
            "Epoch 681/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3803 - acc: 0.8614 - val_loss: 0.1988 - val_acc: 0.9267\n",
            "Epoch 682/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3920 - acc: 0.8534 - val_loss: 0.2182 - val_acc: 0.9226\n",
            "Epoch 683/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3672 - acc: 0.8657 - val_loss: 0.1973 - val_acc: 0.9379\n",
            "Epoch 684/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3766 - acc: 0.8565 - val_loss: 0.1959 - val_acc: 0.9285\n",
            "Epoch 685/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3742 - acc: 0.8530 - val_loss: 0.1903 - val_acc: 0.9409\n",
            "Epoch 686/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3791 - acc: 0.8543 - val_loss: 0.1950 - val_acc: 0.9332\n",
            "Epoch 687/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3806 - acc: 0.8571 - val_loss: 0.1743 - val_acc: 0.9456\n",
            "Epoch 688/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3537 - acc: 0.8654 - val_loss: 0.1933 - val_acc: 0.9344\n",
            "Epoch 689/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3693 - acc: 0.8596 - val_loss: 0.1869 - val_acc: 0.9379\n",
            "Epoch 690/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3805 - acc: 0.8573 - val_loss: 0.2058 - val_acc: 0.9291\n",
            "Epoch 691/1000\n",
            "106/106 [==============================] - 3s 32ms/step - loss: 0.3694 - acc: 0.8627 - val_loss: 0.1789 - val_acc: 0.9427\n",
            "Epoch 692/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3698 - acc: 0.8593 - val_loss: 0.1843 - val_acc: 0.9397\n",
            "Epoch 693/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3701 - acc: 0.8605 - val_loss: 0.1858 - val_acc: 0.9344\n",
            "Epoch 694/1000\n",
            "106/106 [==============================] - 3s 32ms/step - loss: 0.3708 - acc: 0.8611 - val_loss: 0.1921 - val_acc: 0.9379\n",
            "Epoch 695/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3637 - acc: 0.8623 - val_loss: 0.1811 - val_acc: 0.9397\n",
            "Epoch 696/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3916 - acc: 0.8521 - val_loss: 0.1841 - val_acc: 0.9397\n",
            "Epoch 697/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3725 - acc: 0.8573 - val_loss: 0.1760 - val_acc: 0.9450\n",
            "Epoch 698/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3559 - acc: 0.8636 - val_loss: 0.1761 - val_acc: 0.9415\n",
            "Epoch 699/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3596 - acc: 0.8661 - val_loss: 0.1814 - val_acc: 0.9415\n",
            "Epoch 700/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3765 - acc: 0.8599 - val_loss: 0.1798 - val_acc: 0.9439\n",
            "Epoch 701/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3729 - acc: 0.8593 - val_loss: 0.1958 - val_acc: 0.9309\n",
            "Epoch 702/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3532 - acc: 0.8676 - val_loss: 0.2008 - val_acc: 0.9332\n",
            "Epoch 703/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3734 - acc: 0.8583 - val_loss: 0.1803 - val_acc: 0.9397\n",
            "Epoch 704/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3761 - acc: 0.8607 - val_loss: 0.1890 - val_acc: 0.9368\n",
            "Epoch 705/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3636 - acc: 0.8602 - val_loss: 0.1941 - val_acc: 0.9303\n",
            "Epoch 706/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3647 - acc: 0.8650 - val_loss: 0.1956 - val_acc: 0.9291\n",
            "Epoch 707/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3912 - acc: 0.8494 - val_loss: 0.1860 - val_acc: 0.9356\n",
            "Epoch 708/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3825 - acc: 0.8568 - val_loss: 0.2049 - val_acc: 0.9350\n",
            "Epoch 709/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3713 - acc: 0.8611 - val_loss: 0.1803 - val_acc: 0.9403\n",
            "Epoch 710/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3688 - acc: 0.8636 - val_loss: 0.1860 - val_acc: 0.9314\n",
            "Epoch 711/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3628 - acc: 0.8608 - val_loss: 0.1891 - val_acc: 0.9368\n",
            "Epoch 712/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3811 - acc: 0.8582 - val_loss: 0.1924 - val_acc: 0.9344\n",
            "Epoch 713/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3747 - acc: 0.8610 - val_loss: 0.1826 - val_acc: 0.9368\n",
            "Epoch 714/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3685 - acc: 0.8638 - val_loss: 0.2135 - val_acc: 0.9208\n",
            "Epoch 715/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3691 - acc: 0.8633 - val_loss: 0.1933 - val_acc: 0.9374\n",
            "Epoch 716/1000\n",
            "106/106 [==============================] - 3s 32ms/step - loss: 0.3814 - acc: 0.8583 - val_loss: 0.2027 - val_acc: 0.9243\n",
            "Epoch 717/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3588 - acc: 0.8654 - val_loss: 0.1893 - val_acc: 0.9320\n",
            "Epoch 718/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3701 - acc: 0.8626 - val_loss: 0.1937 - val_acc: 0.9391\n",
            "Epoch 719/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3849 - acc: 0.8553 - val_loss: 0.1822 - val_acc: 0.9439\n",
            "Epoch 720/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3698 - acc: 0.8604 - val_loss: 0.1898 - val_acc: 0.9350\n",
            "Epoch 721/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3589 - acc: 0.8626 - val_loss: 0.1687 - val_acc: 0.9433\n",
            "Epoch 722/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3674 - acc: 0.8617 - val_loss: 0.1917 - val_acc: 0.9309\n",
            "Epoch 723/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3680 - acc: 0.8652 - val_loss: 0.1868 - val_acc: 0.9374\n",
            "Epoch 724/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3598 - acc: 0.8632 - val_loss: 0.1830 - val_acc: 0.9385\n",
            "Epoch 725/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3609 - acc: 0.8661 - val_loss: 0.1905 - val_acc: 0.9350\n",
            "Epoch 726/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3672 - acc: 0.8661 - val_loss: 0.1891 - val_acc: 0.9344\n",
            "Epoch 727/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3740 - acc: 0.8592 - val_loss: 0.1711 - val_acc: 0.9409\n",
            "Epoch 728/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3682 - acc: 0.8616 - val_loss: 0.1947 - val_acc: 0.9320\n",
            "Epoch 729/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3589 - acc: 0.8639 - val_loss: 0.1773 - val_acc: 0.9415\n",
            "Epoch 730/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3675 - acc: 0.8571 - val_loss: 0.1839 - val_acc: 0.9320\n",
            "Epoch 731/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3735 - acc: 0.8573 - val_loss: 0.1869 - val_acc: 0.9391\n",
            "Epoch 732/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3763 - acc: 0.8590 - val_loss: 0.1713 - val_acc: 0.9498\n",
            "Epoch 733/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3555 - acc: 0.8691 - val_loss: 0.1995 - val_acc: 0.9350\n",
            "Epoch 734/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3632 - acc: 0.8642 - val_loss: 0.1696 - val_acc: 0.9474\n",
            "Epoch 735/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3849 - acc: 0.8559 - val_loss: 0.1911 - val_acc: 0.9309\n",
            "Epoch 736/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3837 - acc: 0.8548 - val_loss: 0.2072 - val_acc: 0.9279\n",
            "Epoch 737/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3631 - acc: 0.8688 - val_loss: 0.1888 - val_acc: 0.9356\n",
            "Epoch 738/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3594 - acc: 0.8604 - val_loss: 0.2087 - val_acc: 0.9267\n",
            "Epoch 739/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3731 - acc: 0.8614 - val_loss: 0.1999 - val_acc: 0.9297\n",
            "Epoch 740/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3758 - acc: 0.8596 - val_loss: 0.1748 - val_acc: 0.9439\n",
            "Epoch 741/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3760 - acc: 0.8596 - val_loss: 0.1695 - val_acc: 0.9456\n",
            "Epoch 742/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3570 - acc: 0.8672 - val_loss: 0.1692 - val_acc: 0.9474\n",
            "Epoch 743/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3669 - acc: 0.8650 - val_loss: 0.1756 - val_acc: 0.9456\n",
            "Epoch 744/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3697 - acc: 0.8608 - val_loss: 0.1907 - val_acc: 0.9344\n",
            "Epoch 745/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3536 - acc: 0.8663 - val_loss: 0.1729 - val_acc: 0.9444\n",
            "Epoch 746/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3703 - acc: 0.8651 - val_loss: 0.1866 - val_acc: 0.9344\n",
            "Epoch 747/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3590 - acc: 0.8672 - val_loss: 0.1664 - val_acc: 0.9462\n",
            "Epoch 748/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3562 - acc: 0.8704 - val_loss: 0.1805 - val_acc: 0.9362\n",
            "Epoch 749/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3734 - acc: 0.8564 - val_loss: 0.1703 - val_acc: 0.9486\n",
            "Epoch 750/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3714 - acc: 0.8610 - val_loss: 0.1647 - val_acc: 0.9551\n",
            "Epoch 751/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3570 - acc: 0.8681 - val_loss: 0.1742 - val_acc: 0.9504\n",
            "Epoch 752/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3633 - acc: 0.8629 - val_loss: 0.2051 - val_acc: 0.9273\n",
            "Epoch 753/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3712 - acc: 0.8592 - val_loss: 0.1714 - val_acc: 0.9492\n",
            "Epoch 754/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3587 - acc: 0.8641 - val_loss: 0.1695 - val_acc: 0.9468\n",
            "Epoch 755/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3694 - acc: 0.8605 - val_loss: 0.1875 - val_acc: 0.9385\n",
            "Epoch 756/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3541 - acc: 0.8654 - val_loss: 0.1853 - val_acc: 0.9297\n",
            "Epoch 757/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3535 - acc: 0.8675 - val_loss: 0.1689 - val_acc: 0.9456\n",
            "Epoch 758/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3647 - acc: 0.8670 - val_loss: 0.1823 - val_acc: 0.9403\n",
            "Epoch 759/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3699 - acc: 0.8620 - val_loss: 0.1937 - val_acc: 0.9255\n",
            "Epoch 760/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3706 - acc: 0.8601 - val_loss: 0.1950 - val_acc: 0.9273\n",
            "Epoch 761/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3679 - acc: 0.8638 - val_loss: 0.1701 - val_acc: 0.9450\n",
            "Epoch 762/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3546 - acc: 0.8672 - val_loss: 0.1800 - val_acc: 0.9391\n",
            "Epoch 763/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3751 - acc: 0.8611 - val_loss: 0.1942 - val_acc: 0.9291\n",
            "Epoch 764/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3745 - acc: 0.8598 - val_loss: 0.1704 - val_acc: 0.9403\n",
            "Epoch 765/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3617 - acc: 0.8626 - val_loss: 0.1850 - val_acc: 0.9397\n",
            "Epoch 766/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3791 - acc: 0.8577 - val_loss: 0.1665 - val_acc: 0.9409\n",
            "Epoch 767/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3532 - acc: 0.8678 - val_loss: 0.1744 - val_acc: 0.9397\n",
            "Epoch 768/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3538 - acc: 0.8694 - val_loss: 0.1930 - val_acc: 0.9362\n",
            "Epoch 769/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3754 - acc: 0.8605 - val_loss: 0.1612 - val_acc: 0.9439\n",
            "Epoch 770/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3561 - acc: 0.8642 - val_loss: 0.1632 - val_acc: 0.9439\n",
            "Epoch 771/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3764 - acc: 0.8608 - val_loss: 0.1633 - val_acc: 0.9450\n",
            "Epoch 772/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3659 - acc: 0.8651 - val_loss: 0.1752 - val_acc: 0.9409\n",
            "Epoch 773/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3696 - acc: 0.8617 - val_loss: 0.1872 - val_acc: 0.9374\n",
            "Epoch 774/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3536 - acc: 0.8703 - val_loss: 0.1893 - val_acc: 0.9368\n",
            "Epoch 775/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3508 - acc: 0.8692 - val_loss: 0.1617 - val_acc: 0.9492\n",
            "Epoch 776/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3589 - acc: 0.8647 - val_loss: 0.1640 - val_acc: 0.9462\n",
            "Epoch 777/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3573 - acc: 0.8641 - val_loss: 0.1801 - val_acc: 0.9391\n",
            "Epoch 778/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3622 - acc: 0.8604 - val_loss: 0.1631 - val_acc: 0.9433\n",
            "Epoch 779/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3666 - acc: 0.8595 - val_loss: 0.1886 - val_acc: 0.9303\n",
            "Epoch 780/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3599 - acc: 0.8650 - val_loss: 0.1703 - val_acc: 0.9433\n",
            "Epoch 781/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3533 - acc: 0.8692 - val_loss: 0.1738 - val_acc: 0.9450\n",
            "Epoch 782/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3545 - acc: 0.8623 - val_loss: 0.1749 - val_acc: 0.9444\n",
            "Epoch 783/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3443 - acc: 0.8757 - val_loss: 0.1790 - val_acc: 0.9391\n",
            "Epoch 784/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3649 - acc: 0.8624 - val_loss: 0.1714 - val_acc: 0.9439\n",
            "Epoch 785/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3597 - acc: 0.8648 - val_loss: 0.1650 - val_acc: 0.9474\n",
            "Epoch 786/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3536 - acc: 0.8678 - val_loss: 0.1773 - val_acc: 0.9403\n",
            "Epoch 787/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3558 - acc: 0.8621 - val_loss: 0.1931 - val_acc: 0.9356\n",
            "Epoch 788/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3687 - acc: 0.8576 - val_loss: 0.1664 - val_acc: 0.9427\n",
            "Epoch 789/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3707 - acc: 0.8556 - val_loss: 0.1771 - val_acc: 0.9326\n",
            "Epoch 790/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3491 - acc: 0.8716 - val_loss: 0.1716 - val_acc: 0.9462\n",
            "Epoch 791/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3708 - acc: 0.8574 - val_loss: 0.1790 - val_acc: 0.9444\n",
            "Epoch 792/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3378 - acc: 0.8746 - val_loss: 0.1793 - val_acc: 0.9409\n",
            "Epoch 793/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3529 - acc: 0.8685 - val_loss: 0.1698 - val_acc: 0.9498\n",
            "Epoch 794/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3589 - acc: 0.8641 - val_loss: 0.1693 - val_acc: 0.9427\n",
            "Epoch 795/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3546 - acc: 0.8669 - val_loss: 0.1827 - val_acc: 0.9385\n",
            "Epoch 796/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3539 - acc: 0.8648 - val_loss: 0.1741 - val_acc: 0.9415\n",
            "Epoch 797/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3492 - acc: 0.8678 - val_loss: 0.1622 - val_acc: 0.9557\n",
            "Epoch 798/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3622 - acc: 0.8664 - val_loss: 0.1861 - val_acc: 0.9374\n",
            "Epoch 799/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3552 - acc: 0.8648 - val_loss: 0.1801 - val_acc: 0.9421\n",
            "Epoch 800/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3454 - acc: 0.8719 - val_loss: 0.1984 - val_acc: 0.9309\n",
            "Epoch 801/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3544 - acc: 0.8681 - val_loss: 0.1573 - val_acc: 0.9462\n",
            "Epoch 802/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3734 - acc: 0.8618 - val_loss: 0.1740 - val_acc: 0.9403\n",
            "Epoch 803/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3638 - acc: 0.8650 - val_loss: 0.1679 - val_acc: 0.9456\n",
            "Epoch 804/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3556 - acc: 0.8691 - val_loss: 0.1664 - val_acc: 0.9468\n",
            "Epoch 805/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3365 - acc: 0.8737 - val_loss: 0.1809 - val_acc: 0.9362\n",
            "Epoch 806/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3667 - acc: 0.8617 - val_loss: 0.1677 - val_acc: 0.9433\n",
            "Epoch 807/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3596 - acc: 0.8638 - val_loss: 0.1722 - val_acc: 0.9421\n",
            "Epoch 808/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3549 - acc: 0.8670 - val_loss: 0.1581 - val_acc: 0.9474\n",
            "Epoch 809/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3601 - acc: 0.8652 - val_loss: 0.1589 - val_acc: 0.9456\n",
            "Epoch 810/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3483 - acc: 0.8691 - val_loss: 0.1581 - val_acc: 0.9480\n",
            "Epoch 811/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3558 - acc: 0.8689 - val_loss: 0.1520 - val_acc: 0.9539\n",
            "Epoch 812/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3511 - acc: 0.8667 - val_loss: 0.1616 - val_acc: 0.9456\n",
            "Epoch 813/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3665 - acc: 0.8645 - val_loss: 0.1708 - val_acc: 0.9421\n",
            "Epoch 814/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3437 - acc: 0.8706 - val_loss: 0.1771 - val_acc: 0.9379\n",
            "Epoch 815/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3513 - acc: 0.8698 - val_loss: 0.1958 - val_acc: 0.9320\n",
            "Epoch 816/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3529 - acc: 0.8673 - val_loss: 0.1583 - val_acc: 0.9509\n",
            "Epoch 817/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3722 - acc: 0.8599 - val_loss: 0.1749 - val_acc: 0.9397\n",
            "Epoch 818/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3622 - acc: 0.8618 - val_loss: 0.1775 - val_acc: 0.9362\n",
            "Epoch 819/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3536 - acc: 0.8716 - val_loss: 0.1832 - val_acc: 0.9309\n",
            "Epoch 820/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3732 - acc: 0.8605 - val_loss: 0.1823 - val_acc: 0.9338\n",
            "Epoch 821/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3456 - acc: 0.8720 - val_loss: 0.1586 - val_acc: 0.9468\n",
            "Epoch 822/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3656 - acc: 0.8632 - val_loss: 0.1750 - val_acc: 0.9421\n",
            "Epoch 823/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3467 - acc: 0.8703 - val_loss: 0.1696 - val_acc: 0.9450\n",
            "Epoch 824/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3547 - acc: 0.8596 - val_loss: 0.1870 - val_acc: 0.9338\n",
            "Epoch 825/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3556 - acc: 0.8673 - val_loss: 0.1665 - val_acc: 0.9444\n",
            "Epoch 826/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3575 - acc: 0.8638 - val_loss: 0.1863 - val_acc: 0.9415\n",
            "Epoch 827/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3714 - acc: 0.8564 - val_loss: 0.1777 - val_acc: 0.9427\n",
            "Epoch 828/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3496 - acc: 0.8669 - val_loss: 0.1897 - val_acc: 0.9379\n",
            "Epoch 829/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3442 - acc: 0.8768 - val_loss: 0.1790 - val_acc: 0.9391\n",
            "Epoch 830/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3536 - acc: 0.8681 - val_loss: 0.1753 - val_acc: 0.9409\n",
            "Epoch 831/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3562 - acc: 0.8655 - val_loss: 0.1728 - val_acc: 0.9439\n",
            "Epoch 832/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3637 - acc: 0.8664 - val_loss: 0.1671 - val_acc: 0.9450\n",
            "Epoch 833/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3589 - acc: 0.8661 - val_loss: 0.1687 - val_acc: 0.9427\n",
            "Epoch 834/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3542 - acc: 0.8685 - val_loss: 0.1970 - val_acc: 0.9297\n",
            "Epoch 835/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3490 - acc: 0.8666 - val_loss: 0.1722 - val_acc: 0.9397\n",
            "Epoch 836/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3403 - acc: 0.8746 - val_loss: 0.1595 - val_acc: 0.9504\n",
            "Epoch 837/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3463 - acc: 0.8710 - val_loss: 0.1650 - val_acc: 0.9362\n",
            "Epoch 838/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3498 - acc: 0.8685 - val_loss: 0.1574 - val_acc: 0.9480\n",
            "Epoch 839/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3627 - acc: 0.8676 - val_loss: 0.1727 - val_acc: 0.9474\n",
            "Epoch 840/1000\n",
            "106/106 [==============================] - 3s 32ms/step - loss: 0.3451 - acc: 0.8713 - val_loss: 0.1962 - val_acc: 0.9255\n",
            "Epoch 841/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3615 - acc: 0.8596 - val_loss: 0.1783 - val_acc: 0.9397\n",
            "Epoch 842/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3536 - acc: 0.8654 - val_loss: 0.1771 - val_acc: 0.9385\n",
            "Epoch 843/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3372 - acc: 0.8750 - val_loss: 0.1615 - val_acc: 0.9492\n",
            "Epoch 844/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3510 - acc: 0.8712 - val_loss: 0.1697 - val_acc: 0.9409\n",
            "Epoch 845/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3505 - acc: 0.8675 - val_loss: 0.1674 - val_acc: 0.9409\n",
            "Epoch 846/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3460 - acc: 0.8713 - val_loss: 0.1780 - val_acc: 0.9374\n",
            "Epoch 847/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3380 - acc: 0.8740 - val_loss: 0.1719 - val_acc: 0.9409\n",
            "Epoch 848/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3639 - acc: 0.8654 - val_loss: 0.1814 - val_acc: 0.9397\n",
            "Epoch 849/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3385 - acc: 0.8722 - val_loss: 0.1636 - val_acc: 0.9462\n",
            "Epoch 850/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3468 - acc: 0.8664 - val_loss: 0.1741 - val_acc: 0.9409\n",
            "Epoch 851/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3458 - acc: 0.8704 - val_loss: 0.1609 - val_acc: 0.9456\n",
            "Epoch 852/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3404 - acc: 0.8673 - val_loss: 0.1647 - val_acc: 0.9474\n",
            "Epoch 853/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3653 - acc: 0.8645 - val_loss: 0.1668 - val_acc: 0.9456\n",
            "Epoch 854/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3558 - acc: 0.8633 - val_loss: 0.1803 - val_acc: 0.9385\n",
            "Epoch 855/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3522 - acc: 0.8694 - val_loss: 0.1529 - val_acc: 0.9480\n",
            "Epoch 856/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3488 - acc: 0.8679 - val_loss: 0.1617 - val_acc: 0.9480\n",
            "Epoch 857/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3587 - acc: 0.8647 - val_loss: 0.1712 - val_acc: 0.9427\n",
            "Epoch 858/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3547 - acc: 0.8669 - val_loss: 0.1605 - val_acc: 0.9468\n",
            "Epoch 859/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3646 - acc: 0.8614 - val_loss: 0.1672 - val_acc: 0.9444\n",
            "Epoch 860/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3461 - acc: 0.8700 - val_loss: 0.1667 - val_acc: 0.9450\n",
            "Epoch 861/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3586 - acc: 0.8695 - val_loss: 0.1877 - val_acc: 0.9326\n",
            "Epoch 862/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3675 - acc: 0.8635 - val_loss: 0.1626 - val_acc: 0.9480\n",
            "Epoch 863/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3531 - acc: 0.8660 - val_loss: 0.1835 - val_acc: 0.9362\n",
            "Epoch 864/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3393 - acc: 0.8738 - val_loss: 0.1717 - val_acc: 0.9433\n",
            "Epoch 865/1000\n",
            "106/106 [==============================] - 3s 32ms/step - loss: 0.3540 - acc: 0.8695 - val_loss: 0.1656 - val_acc: 0.9486\n",
            "Epoch 866/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3563 - acc: 0.8720 - val_loss: 0.1793 - val_acc: 0.9391\n",
            "Epoch 867/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3651 - acc: 0.8642 - val_loss: 0.1658 - val_acc: 0.9492\n",
            "Epoch 868/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3593 - acc: 0.8675 - val_loss: 0.1808 - val_acc: 0.9368\n",
            "Epoch 869/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3479 - acc: 0.8698 - val_loss: 0.1940 - val_acc: 0.9362\n",
            "Epoch 870/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3517 - acc: 0.8651 - val_loss: 0.1755 - val_acc: 0.9391\n",
            "Epoch 871/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3476 - acc: 0.8684 - val_loss: 0.1733 - val_acc: 0.9415\n",
            "Epoch 872/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3460 - acc: 0.8676 - val_loss: 0.1755 - val_acc: 0.9409\n",
            "Epoch 873/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3478 - acc: 0.8731 - val_loss: 0.1773 - val_acc: 0.9415\n",
            "Epoch 874/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3463 - acc: 0.8735 - val_loss: 0.1634 - val_acc: 0.9486\n",
            "Epoch 875/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3452 - acc: 0.8747 - val_loss: 0.1660 - val_acc: 0.9421\n",
            "Epoch 876/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3419 - acc: 0.8728 - val_loss: 0.1764 - val_acc: 0.9379\n",
            "Epoch 877/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3399 - acc: 0.8731 - val_loss: 0.1556 - val_acc: 0.9486\n",
            "Epoch 878/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3557 - acc: 0.8709 - val_loss: 0.1813 - val_acc: 0.9356\n",
            "Epoch 879/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3569 - acc: 0.8666 - val_loss: 0.1692 - val_acc: 0.9427\n",
            "Epoch 880/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3488 - acc: 0.8684 - val_loss: 0.1692 - val_acc: 0.9421\n",
            "Epoch 881/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3462 - acc: 0.8703 - val_loss: 0.1668 - val_acc: 0.9385\n",
            "Epoch 882/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3400 - acc: 0.8743 - val_loss: 0.1749 - val_acc: 0.9350\n",
            "Epoch 883/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3482 - acc: 0.8709 - val_loss: 0.1503 - val_acc: 0.9533\n",
            "Epoch 884/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3462 - acc: 0.8712 - val_loss: 0.1618 - val_acc: 0.9456\n",
            "Epoch 885/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3629 - acc: 0.8630 - val_loss: 0.1845 - val_acc: 0.9368\n",
            "Epoch 886/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3521 - acc: 0.8694 - val_loss: 0.1876 - val_acc: 0.9374\n",
            "Epoch 887/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3489 - acc: 0.8692 - val_loss: 0.1618 - val_acc: 0.9486\n",
            "Epoch 888/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3451 - acc: 0.8670 - val_loss: 0.1479 - val_acc: 0.9551\n",
            "Epoch 889/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3476 - acc: 0.8676 - val_loss: 0.1596 - val_acc: 0.9456\n",
            "Epoch 890/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3419 - acc: 0.8681 - val_loss: 0.1635 - val_acc: 0.9409\n",
            "Epoch 891/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3501 - acc: 0.8713 - val_loss: 0.1506 - val_acc: 0.9533\n",
            "Epoch 892/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3426 - acc: 0.8698 - val_loss: 0.1501 - val_acc: 0.9515\n",
            "Epoch 893/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3425 - acc: 0.8684 - val_loss: 0.1663 - val_acc: 0.9450\n",
            "Epoch 894/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3463 - acc: 0.8710 - val_loss: 0.1648 - val_acc: 0.9509\n",
            "Epoch 895/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3705 - acc: 0.8636 - val_loss: 0.1744 - val_acc: 0.9468\n",
            "Epoch 896/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3629 - acc: 0.8651 - val_loss: 0.1726 - val_acc: 0.9439\n",
            "Epoch 897/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3387 - acc: 0.8725 - val_loss: 0.1614 - val_acc: 0.9450\n",
            "Epoch 898/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3449 - acc: 0.8673 - val_loss: 0.1581 - val_acc: 0.9515\n",
            "Epoch 899/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3397 - acc: 0.8692 - val_loss: 0.1629 - val_acc: 0.9462\n",
            "Epoch 900/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3517 - acc: 0.8676 - val_loss: 0.1716 - val_acc: 0.9427\n",
            "Epoch 901/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3354 - acc: 0.8738 - val_loss: 0.1856 - val_acc: 0.9397\n",
            "Epoch 902/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3519 - acc: 0.8681 - val_loss: 0.1727 - val_acc: 0.9379\n",
            "Epoch 903/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3344 - acc: 0.8747 - val_loss: 0.1644 - val_acc: 0.9427\n",
            "Epoch 904/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3384 - acc: 0.8775 - val_loss: 0.1547 - val_acc: 0.9509\n",
            "Epoch 905/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3399 - acc: 0.8706 - val_loss: 0.1719 - val_acc: 0.9379\n",
            "Epoch 906/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3581 - acc: 0.8670 - val_loss: 0.1660 - val_acc: 0.9462\n",
            "Epoch 907/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3518 - acc: 0.8676 - val_loss: 0.1591 - val_acc: 0.9450\n",
            "Epoch 908/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3498 - acc: 0.8681 - val_loss: 0.1561 - val_acc: 0.9468\n",
            "Epoch 909/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3517 - acc: 0.8713 - val_loss: 0.1582 - val_acc: 0.9468\n",
            "Epoch 910/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3427 - acc: 0.8744 - val_loss: 0.1742 - val_acc: 0.9427\n",
            "Epoch 911/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3497 - acc: 0.8672 - val_loss: 0.1651 - val_acc: 0.9486\n",
            "Epoch 912/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3327 - acc: 0.8777 - val_loss: 0.1567 - val_acc: 0.9498\n",
            "Epoch 913/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3391 - acc: 0.8760 - val_loss: 0.1635 - val_acc: 0.9474\n",
            "Epoch 914/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3351 - acc: 0.8722 - val_loss: 0.1629 - val_acc: 0.9474\n",
            "Epoch 915/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3223 - acc: 0.8799 - val_loss: 0.1554 - val_acc: 0.9515\n",
            "Epoch 916/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3381 - acc: 0.8701 - val_loss: 0.1735 - val_acc: 0.9379\n",
            "Epoch 917/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3325 - acc: 0.8740 - val_loss: 0.1474 - val_acc: 0.9492\n",
            "Epoch 918/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3425 - acc: 0.8728 - val_loss: 0.1482 - val_acc: 0.9486\n",
            "Epoch 919/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3383 - acc: 0.8728 - val_loss: 0.1608 - val_acc: 0.9444\n",
            "Epoch 920/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3421 - acc: 0.8735 - val_loss: 0.1598 - val_acc: 0.9480\n",
            "Epoch 921/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3580 - acc: 0.8655 - val_loss: 0.1625 - val_acc: 0.9427\n",
            "Epoch 922/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3441 - acc: 0.8720 - val_loss: 0.1802 - val_acc: 0.9362\n",
            "Epoch 923/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3302 - acc: 0.8756 - val_loss: 0.1619 - val_acc: 0.9509\n",
            "Epoch 924/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3371 - acc: 0.8759 - val_loss: 0.1856 - val_acc: 0.9397\n",
            "Epoch 925/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3351 - acc: 0.8735 - val_loss: 0.1691 - val_acc: 0.9391\n",
            "Epoch 926/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3439 - acc: 0.8754 - val_loss: 0.1733 - val_acc: 0.9421\n",
            "Epoch 927/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3481 - acc: 0.8688 - val_loss: 0.1606 - val_acc: 0.9462\n",
            "Epoch 928/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3396 - acc: 0.8707 - val_loss: 0.1559 - val_acc: 0.9527\n",
            "Epoch 929/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3423 - acc: 0.8700 - val_loss: 0.1560 - val_acc: 0.9486\n",
            "Epoch 930/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3541 - acc: 0.8722 - val_loss: 0.1469 - val_acc: 0.9557\n",
            "Epoch 931/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3235 - acc: 0.8800 - val_loss: 0.1594 - val_acc: 0.9468\n",
            "Epoch 932/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3365 - acc: 0.8777 - val_loss: 0.1601 - val_acc: 0.9427\n",
            "Epoch 933/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3312 - acc: 0.8717 - val_loss: 0.1795 - val_acc: 0.9379\n",
            "Epoch 934/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3385 - acc: 0.8747 - val_loss: 0.1856 - val_acc: 0.9326\n",
            "Epoch 935/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3416 - acc: 0.8707 - val_loss: 0.1614 - val_acc: 0.9450\n",
            "Epoch 936/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3498 - acc: 0.8648 - val_loss: 0.1750 - val_acc: 0.9433\n",
            "Epoch 937/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3320 - acc: 0.8740 - val_loss: 0.1580 - val_acc: 0.9563\n",
            "Epoch 938/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3337 - acc: 0.8719 - val_loss: 0.1587 - val_acc: 0.9474\n",
            "Epoch 939/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3472 - acc: 0.8737 - val_loss: 0.1501 - val_acc: 0.9527\n",
            "Epoch 940/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3421 - acc: 0.8706 - val_loss: 0.1567 - val_acc: 0.9480\n",
            "Epoch 941/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3444 - acc: 0.8740 - val_loss: 0.1814 - val_acc: 0.9344\n",
            "Epoch 942/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3323 - acc: 0.8731 - val_loss: 0.1697 - val_acc: 0.9409\n",
            "Epoch 943/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3482 - acc: 0.8716 - val_loss: 0.1563 - val_acc: 0.9533\n",
            "Epoch 944/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3304 - acc: 0.8762 - val_loss: 0.1866 - val_acc: 0.9320\n",
            "Epoch 945/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3526 - acc: 0.8664 - val_loss: 0.1563 - val_acc: 0.9498\n",
            "Epoch 946/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3252 - acc: 0.8774 - val_loss: 0.1732 - val_acc: 0.9379\n",
            "Epoch 947/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3520 - acc: 0.8684 - val_loss: 0.1705 - val_acc: 0.9403\n",
            "Epoch 948/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3430 - acc: 0.8725 - val_loss: 0.1617 - val_acc: 0.9521\n",
            "Epoch 949/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3430 - acc: 0.8713 - val_loss: 0.1647 - val_acc: 0.9492\n",
            "Epoch 950/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3433 - acc: 0.8735 - val_loss: 0.1525 - val_acc: 0.9515\n",
            "Epoch 951/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3274 - acc: 0.8765 - val_loss: 0.1477 - val_acc: 0.9504\n",
            "Epoch 952/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3498 - acc: 0.8701 - val_loss: 0.1592 - val_acc: 0.9468\n",
            "Epoch 953/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3453 - acc: 0.8692 - val_loss: 0.1519 - val_acc: 0.9480\n",
            "Epoch 954/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3372 - acc: 0.8763 - val_loss: 0.1722 - val_acc: 0.9385\n",
            "Epoch 955/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3520 - acc: 0.8703 - val_loss: 0.1694 - val_acc: 0.9415\n",
            "Epoch 956/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3491 - acc: 0.8692 - val_loss: 0.1622 - val_acc: 0.9450\n",
            "Epoch 957/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3437 - acc: 0.8707 - val_loss: 0.1592 - val_acc: 0.9509\n",
            "Epoch 958/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3434 - acc: 0.8725 - val_loss: 0.1571 - val_acc: 0.9509\n",
            "Epoch 959/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3288 - acc: 0.8781 - val_loss: 0.1458 - val_acc: 0.9563\n",
            "Epoch 960/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3480 - acc: 0.8667 - val_loss: 0.1474 - val_acc: 0.9557\n",
            "Epoch 961/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3368 - acc: 0.8728 - val_loss: 0.1577 - val_acc: 0.9439\n",
            "Epoch 962/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3411 - acc: 0.8734 - val_loss: 0.1772 - val_acc: 0.9356\n",
            "Epoch 963/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3442 - acc: 0.8704 - val_loss: 0.1496 - val_acc: 0.9521\n",
            "Epoch 964/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3446 - acc: 0.8709 - val_loss: 0.1651 - val_acc: 0.9421\n",
            "Epoch 965/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3213 - acc: 0.8840 - val_loss: 0.1564 - val_acc: 0.9504\n",
            "Epoch 966/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3331 - acc: 0.8756 - val_loss: 0.1555 - val_acc: 0.9486\n",
            "Epoch 967/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3362 - acc: 0.8728 - val_loss: 0.1585 - val_acc: 0.9444\n",
            "Epoch 968/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3470 - acc: 0.8691 - val_loss: 0.1794 - val_acc: 0.9332\n",
            "Epoch 969/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3432 - acc: 0.8763 - val_loss: 0.1617 - val_acc: 0.9492\n",
            "Epoch 970/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3514 - acc: 0.8672 - val_loss: 0.1535 - val_acc: 0.9480\n",
            "Epoch 971/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3247 - acc: 0.8784 - val_loss: 0.1630 - val_acc: 0.9415\n",
            "Epoch 972/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3380 - acc: 0.8746 - val_loss: 0.1401 - val_acc: 0.9598\n",
            "Epoch 973/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3321 - acc: 0.8791 - val_loss: 0.1708 - val_acc: 0.9403\n",
            "Epoch 974/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3311 - acc: 0.8746 - val_loss: 0.1688 - val_acc: 0.9421\n",
            "Epoch 975/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3349 - acc: 0.8735 - val_loss: 0.1524 - val_acc: 0.9486\n",
            "Epoch 976/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3349 - acc: 0.8753 - val_loss: 0.1752 - val_acc: 0.9450\n",
            "Epoch 977/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3292 - acc: 0.8787 - val_loss: 0.1585 - val_acc: 0.9474\n",
            "Epoch 978/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3287 - acc: 0.8771 - val_loss: 0.1447 - val_acc: 0.9545\n",
            "Epoch 979/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3391 - acc: 0.8769 - val_loss: 0.1652 - val_acc: 0.9439\n",
            "Epoch 980/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3340 - acc: 0.8753 - val_loss: 0.1728 - val_acc: 0.9374\n",
            "Epoch 981/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3385 - acc: 0.8744 - val_loss: 0.1597 - val_acc: 0.9456\n",
            "Epoch 982/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3488 - acc: 0.8704 - val_loss: 0.1591 - val_acc: 0.9480\n",
            "Epoch 983/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3360 - acc: 0.8723 - val_loss: 0.1612 - val_acc: 0.9468\n",
            "Epoch 984/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3324 - acc: 0.8722 - val_loss: 0.1585 - val_acc: 0.9456\n",
            "Epoch 985/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3411 - acc: 0.8726 - val_loss: 0.1644 - val_acc: 0.9521\n",
            "Epoch 986/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3355 - acc: 0.8769 - val_loss: 0.1631 - val_acc: 0.9444\n",
            "Epoch 987/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3411 - acc: 0.8728 - val_loss: 0.1569 - val_acc: 0.9509\n",
            "Epoch 988/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3362 - acc: 0.8784 - val_loss: 0.1490 - val_acc: 0.9498\n",
            "Epoch 989/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3337 - acc: 0.8695 - val_loss: 0.1609 - val_acc: 0.9403\n",
            "Epoch 990/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3421 - acc: 0.8706 - val_loss: 0.1691 - val_acc: 0.9415\n",
            "Epoch 991/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3425 - acc: 0.8759 - val_loss: 0.1603 - val_acc: 0.9468\n",
            "Epoch 992/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3304 - acc: 0.8753 - val_loss: 0.1708 - val_acc: 0.9374\n",
            "Epoch 993/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3454 - acc: 0.8715 - val_loss: 0.1580 - val_acc: 0.9504\n",
            "Epoch 994/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3300 - acc: 0.8731 - val_loss: 0.1740 - val_acc: 0.9421\n",
            "Epoch 995/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3397 - acc: 0.8682 - val_loss: 0.1668 - val_acc: 0.9403\n",
            "Epoch 996/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3361 - acc: 0.8754 - val_loss: 0.1460 - val_acc: 0.9574\n",
            "Epoch 997/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3322 - acc: 0.8756 - val_loss: 0.1566 - val_acc: 0.9480\n",
            "Epoch 998/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3314 - acc: 0.8747 - val_loss: 0.1522 - val_acc: 0.9521\n",
            "Epoch 999/1000\n",
            "106/106 [==============================] - 3s 31ms/step - loss: 0.3437 - acc: 0.8753 - val_loss: 0.1759 - val_acc: 0.9409\n",
            "Epoch 1000/1000\n",
            "106/106 [==============================] - 3s 30ms/step - loss: 0.3441 - acc: 0.8709 - val_loss: 0.1570 - val_acc: 0.9492\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5W7-Qi6vG_9",
        "outputId": "a04a0c79-a4b2-4a80-8084-221cbf7c45b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14/14 [==============================] - 0s 21ms/step - loss: 2.2855 - acc: 0.4470\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.285513162612915, 0.44695258140563965]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['acc'], label='train')\n",
        "plt.plot(history.history['val_acc'], label='test')\n",
        "plt.legend();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "qS3hSLpYWYAa",
        "outputId": "c2475b5b-bab5-4f7a-a6cd-bf3106ccd4db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}